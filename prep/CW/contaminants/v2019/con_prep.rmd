---
title: "Contaminants - Clean Water Subgoal"
output:
  html_document:
    toc: true
    toc_depth: 4
    code_folding: hide
---

<br>

```{r preamble prep including spatial functions and files, message = FALSE}
loc <- here::here("prep", "CW", "contaminants")

source(here::here("R", "setup.R"))
knitr::opts_chunk$set(message = FALSE, warning = FALSE, results = "hide", fig.width = 9.5)

bkgd_path <- here::here("supplement", "goal_summaries", "con_summary.Rmd")
data_path <- here::here("data", "CW", "contaminants", version_year, "con_data.rmd")
refs_path <- file.path(loc, "con_references.Rmd")

source(here::here("R", "spatial.R"))
regions_shape()
buffer_sf <- st_read(
  file.path(dirname(dir_B), "Shapefiles", "BHI_shapefile_25km_buffer"), 
  "BHI_shapefile_25km_buffer"
)
bhi_rgns_simple <- rmapshaper::ms_simplify(input = BHI_rgns_shp) %>% sf::st_as_sf()
```

<br>

## 1. Background

```{r Background, child = bkgd_path, results = "asis", echo = FALSE}
```

<br/>

## 2. Data

```{r Data, child = data_path, results = "asis", echo = FALSE}
```

<br/>

## 3. Prep: Wrangling, Evaluation, and Gapfilling

```{r function to load datasets created in con_data, echo = TRUE, results = "hide", message = FALSE}
read_clean_df <- function(filename){
  read_csv(
    file.path(dirname(data_path), "intermediate", filename),
    ## ensure column types are read correctly...
    col_types = cols(
      bulk_id = col_character(),
      qflag = col_character(),
      `LIPIDWT%` = col_number(),
      `DRYWT%` = col_number(),
      `EXLIP%` = col_number(),
      WTMEA = col_number(),
      sub_samp_id = col_number()
    )
  )
}
```

---

**Station Impact Codes**

*Note: as of `BHI2.0` the original station library has been replaced by a new web application*

[Site monitoring purpose](https://vocab.ices.dk/?ref=42) `monit_purpose` vocabulary reference for codes.

Some sites have had the site type recorded in the ICES station dictionary ([see ICES vocabulary reference for codes](https://vocab.ices.dk/?ref=177). It is pertinent to know which sites are catagorized as:  

1. **RH** = WFD R(HZ) - Representative of general conditions in terms of hazardous substances  
2. **B** = WFD B - Baseline/Reference station  
3. **Any of the codes containing "I"** (Starting with IH or IP) which refers to a specific type of impact at the site.  
4. **RP** = WFD R(PHY) - Representative of general conditions for nutrients/organic matter 

It appears that only Swedish sites have this information entered. Given only Swedish sites have this information recorded, it seems difficult to use this information to include or exclude sites.  

From the station dictionary definitions:

- All_Biota_Data: Data type (DTYPE) CF - all parameters - contaminants and biological effects of contaminants including disease in biota  
- Contaminant_parameters_in_biota: Data type (DTYPE) CF - Contaminant parameter groups  

---

<br>

### 3.1 PCB Indicator

#### 3.1.1 Match BHI Regions

**Use Lat/Long to Match BHI Regions**
```{r assign BHI regions to PCB data, echo = TRUE, message = FALSE, warning = FALSE}
## use 'read_clean_df' function from above to read cleaned data with correct data types for columns
## use 'join_rgns_info' helper function defined in R/spatial.R
pcb_bio <- join_rgns_info(
  read_clean_df("pcb_bio_cleaned.csv"),
  latlon_vars = c("latitude", "longitude"),
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles"),
  return_spatial = FALSE,
  buffer_shp = buffer_sf
)
pcb_sed <- join_rgns_info(
  read_clean_df("pcb_sed_cleaned.csv"),
  latlon_vars = c("latitude", "longitude"),
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles"),
  return_spatial = TRUE
)
```
<br>

#### 3.1.2 Filter PCBs to ICES6 Set and Join Station Impact

The PCBs indicator uses only the ICES6 congeners: CB28, CB52, CB101, CB138, CB153, CB180.  Additionally, only herring are used from the biota dataset, as they are fairly equally spatially distributed across the baltic sea, while many other species are predominantly in the south.

```{r filter pcb data}
pcb_bio <- pcb_bio %>% 
  filter(!is.na(value_wet_wgt)) %>% 
  filter(str_detect(species, pattern = "Clupea harengus")) %>%
  filter(variable %in% c("CB28", "CB52", "CB101", "CB138", "CB153", "CB180")) %>% 
  ## check that rows are distinct: nrow(pcb_bio_sf) == nrow(distinct(pcb_bio_sf))...
  select(
    variable, value_wet_wgt, detect_lim_wet_wgt, quant_lim_wet_wgt,
    species, num_indiv_subsample, monit_program, monit_purpose, monit_year,
    sub_samp_ref,
    qflagged, qflag, 
    country, Subbasin, HELCOM_ID, BHI_ID, latitude, longitude, station,
    date, year, month, day
  )
```

<br>

#### 3.1.3 Evaluate flagged data, Station Impact, & sampling patterns

<br>

**What do the `qflags` indicate? Quantification limits, Flags Codes**

- **<** = less than  

- **>** = greather than  

- **D** = reported value is less than the detection limit (detect_lim)  

- **Q** = reported value is less than the limit of quantification (quant_lim)  

- **~** separates multiple flags  

<br>

```{r what do the qflags indicate, results = "show"}
## what do the qflags actually indicate?
chk_pcb_bio_qflags <- pcb_bio %>% 
  select_at(vars(matches("qflag|value|quant|detect"))) %>% 
  filter(qflagged) %>% 
  mutate(qflag = str_split(qflag, "~")) %>% 
  tidyr::unnest(qflag) %>%
  mutate(
    ## from guess-check-plot, it appears the following is mostly correct, with minimal inconsistencies...
    ## < and Q flags indicates less than or equal to quantification limit, 
    ## D flag indicates less than detection limit
    chk = case_when(
      qflag == "D" ~ value_wet_wgt < detect_lim_wet_wgt,
      qflag == "Q" ~ value_wet_wgt <= quant_lim_wet_wgt,
      qflag == "<" ~ value_wet_wgt <= quant_lim_wet_wgt
    )
  )
## from guess-check-plot, it appears the following is mostly correct, with minimal inconsistencies...
## < and Q flags indicates less than or equal to quantification limit, 
## D flag indicates less than detection limit
ggplot(chk_pcb_bio_qflags) +
  geom_bar(aes(chk, fill = chk), position = position_dodge()) +
  scale_fill_manual(values = c("firebrick", "paleturquoise3"), na.value = "whitesmoke") +
  facet_wrap(~qflag, nrow = 1, scales = "free") +
  labs(
    x = "\nConc. value â‰¤ Quantification Limit ('<' and 'Q'), Conc. value < Detection Limit ('D')", 
    y = NULL, 
    fill = NULL
  )  +
  theme_dark()
```

<br>

**Compare two approaches to deal with flagged data, for BHI regions vs Basin**

0. Remove the flagged observations or adjust values using detect_lim/2; detect_lim values not always provided, so instead, apply transformation to the reported data value
1. Start with mean ICES6 conc. by date and location (our unique observations) 
2. Take mean of all unique obs. for past 10 years in either BHI region or basin. If by basin, give basin score to all regions within basin.  
3. Compare by-basin and by-BHI region results for status and for trend  
4. Assess number of data points contributing  

<br>

```{r function to adjust qflagged data and summarize by basins or regions}
## percentage data with qflags... esp by year in most recent years...
qflag_adjust <- function(dataset, approach = "Adjusted", basins_or_rgns = "subbasins"){
  
  grpcols <- c(
    "country", "Subbasin", "HELCOM_ID", "BHI_ID", "latitude", "longitude",
    "date", "year", "month", "day", 
    "station", "report_institute", "monit_program", "monit_purpose", 
    "sub_samp_ref", "sub_samp_id", "samp_ref", "num_indiv_subsample", "bulk_id"
  )
  if(!"sub_samp_ref" %in% names(dataset)){
    id_cols <- setdiff(id_cols, "sub_samp_ref")
  }
  
  if(approach == "NoQflag"){
    dataset <- filter(dataset, !qflagged)
  }
  
  ## adjust for qflags
  ## NOTE if all qflagged are removed, all adjusted values equal original values
  ## sum congeners by date and location
  ## remove cases where not all congeners are observed
  data_Qadjust_means <- 
    
    
  tmp <- dataset %>% 
    mutate(value_adj = ifelse(qflagged, value_wet_wgt/2, value_wet_wgt)) %>% 
    tidyr::pivot_wider(
      id_cols = c(
        country, Subbasin, HELCOM_ID, BHI_ID, station, 
        latitude, longitude, 
        date, year, month, day
      ),
      names_from = variable, 
      values_from = value_adj,
      values_fn = list(value_adj = mean)
    ) %>%
    ## sum will be NA if any one congener is NA; 
    ## sum and filter resulting NAs to remove cases where not all congeners are observed
    mutate(ices6_sum = (CB28 + CB52 + CB101 + CB138 + CB153 + CB180)) %>% 
    filter(!is.na(ices6_sum))
  
  ## remove unique ids and take mean by location + date
  data_Qadjust_means <- data_Qadjust_means %>% "???????????"

  
  ## mean of all unique obs. for past 10 years
  ## Here 'observation' refers to a time and location, where one or more congeners were measured simulaneously
  
  ## Two alternative approaches for summarizing the data:
  ## Adjusted: sum the adjusted values, for the 6 ICES congeners
  ## NoQflag: sum only observation with no qflagged values
  
  ## calculate the sum of the ICES6 congeners values for each date and location. 
  ## for observations averaged, also calculate mean, min, and max number of congeners in each of the observations, 
  ## and also numbers of observations for each date and location....
  
}
```

**Map and Plot congeners by Basin**

**Congeners by Basin** 

If the data have any qflag, apply LOD/2. However, LOD (eg. detect_lim column) value is not always provided and values are in original units. Instead, apply transformation to the reported data value...

```{r pcb qflag adjustment congeners by basin, results = "show", fig.height = 12, fig.width = 9.5}
ggplot(
  mutate(
    pcb_bio_sf %>% 
      mutate(value_adj = ifelse(qflagged, value_wet_wgt/2, value_wet_wgt)) %>% 
      group_by(date, variable, Subbasin) %>% 
      mutate(countObs = n(), meanAdjww = mean(value_adj, na.rm = TRUE)) %>% 
      ungroup(), 
    value_adj = ifelse(qflagged, value_wet_wgt/2, NA), 
    value_LODadj = ifelse(qflagged, detect_lim_wet_wgt/2, NA)
  )) +
  geom_line(aes(date, meanAdjww, color = countObs), alpha = 0.4, size = 0.7) + 
  geom_point(
    aes(date, value_wet_wgt, color = countObs), 
    show.legend = FALSE,
    size = 0.9, 
    alpha = 0.4
  ) +
  geom_point(
    aes(date, value_adj),
    color = "red", 
    shape = 4,
    size = 1, 
    alpha = 0.8
  ) +
  facet_wrap(
    c("variable", "Subbasin"), 
    labeller = label_wrap_gen(width = 35, multi_line = FALSE), 
    scales = "free_y", 
    nrow = 13
  ) +
  scale_color_distiller(palette = "GnBu", direction = -1) +
  # scale_color_gradient(low = "grey80", high = "grey20") +
  labs(x = NULL, y = "Congener Concentration (ug/kg wet weight) measured in Clupea harengus") +
  theme_dark()
```

<br>

**Spatial distributions of PCB sampling Locations**

```{r pcb}
map_df <- left_join(
  select(bhi_rgns_simple, HELCOM_ID),
  pcb_bio_sf %>% 
    ungroup() %>%
    filter(year == 2014) %>% 
    group_by(Subbasin, HELCOM_ID, year) %>% 
    summarize(ObservCount = n()) %>% 
    st_drop_geometry(),
  by = "HELCOM_ID"
)
ggplot(map_df) + 
  geom_sf(aes(fill = ObservCount), color = "burlywood", size = 0.1) +
  scale_fill_gradient(low = "navy", high = "skyblue", na.value = "grey") +
  geom_sf(data = filter(pcb_bio_sf, year == 2014), color = "firebrick", shape = 1) +
  theme_dark() +
  theme(legend.position = c(0.2, 0.8))
```

<br>

**The code chunk below simply makes visualization code immediately above into a reusable function, to use in evaluating the four remaining input datasets.** It can create the following visualizations: (1) spatial distribution of sampling locations 'map', (2) `qflag` adjustment 'plot' and (3) plotly 'widget' with congener concentration values by subbasin.

```{r contaminants rawdata visualizations function}
## try running with dataset = pcb_bio_sf, bhi_rgn_shp = bhi_rgns_simple, and yr = 2014
viz_cwcon_initial <- function(dataset, bhi_rgn_shp, plottype = c("map", "plot"), yr){
  
  result <- list()
  
  ## make spatial distribution of sampling locations map
  if("map" %in% plottype){
    result[["map"]] <- ggplot(
      left_join(
        select(bhi_rgn_shp, HELCOM_ID),
        dataset %>% 
          ungroup() %>%
          st_drop_geometry() %>% 
          filter(year == yr) %>% 
          group_by(Subbasin, HELCOM_ID) %>% 
          summarize(ObservCount = n()),
        by = "HELCOM_ID"
      )) + 
      geom_sf(aes(fill = ObservCount), color = "burlywood", size = 0.1) +
      scale_fill_gradient(low = "navy", high = "skyblue", na.value = "grey") +
      geom_sf(data = filter(dataset, year == yr), color = "firebrick", shape = 1) +
      theme_light() +
      theme(legend.position = c(0.2, 0.8))
  }
  ## make qflag adjustment plot
  if("plot" %in% plottype){
    result[["plot"]] <- ggplot(
      mutate(
        dataset, 
        value_adj = ifelse(qflagged, value_wet_wgt/2, NA)
      )) +
      geom_point(
        aes(date, value_wet_wgt, shape = qflagged), 
        color = "steelblue", size = 0.6, alpha = 0.5, 
        show.legend = FALSE
      ) +
      geom_point(
        aes(date, value_adj),
        color = "firebrick", size = 0.4, alpha = 0.6
      ) +
      facet_wrap(
        c("variable", "Subbasin"), 
        labeller = label_wrap_gen(width = 35, multi_line = FALSE), 
        scales = "free_y", nrow = 13
      )
  }
  return(result)
}
```

<br>

#### 3.1.4 Status and trend options and calculation

```{r investigate approaches to qflags and summarizing by region vs basin}

eval_cwcon_indicators <- function(datalayer, yrs = 2010:2019, threshold = 75, 
                                  statusapproach = "Adjusted", trendapproach = "", trend_lag = 5,){

  
  result[["basin_status"]] <- datalayer %>% 
    filter() %>% 
    group_by() %>% 
    summarize(
      meanVal = , # mean value....
      numObs = , # number of data points contributing to status/trend score
      mean_nCong, 
      minvCong, 
      max_nCong
    ) %>% 
    ## keep sums only for samples with all 6 PCBs observed!
    filter()
  
  basin_status <- datalayer %>% 
    group_by(Subbains, HELCOM_ID, year) %>% 
    summarize(ices6_meansum = mean(ices6_meansum, na.rm = TRUE)) %>% 
    ungroup() %>% 
    mutate(
      health_threshold = threshold,
      ices6ratio = ices6_meansum/health_threshold,
      status = 1/ices6ratio
    ) %>% 
    ## if above one set to one
    mutate(status = pmin(1, status)) %>% 
    select(Subbasin, HELCOM_ID, year, status, ices6_meansum)
  
    
  # result[["bhirgn_status"]] <-
  
  ## three approaches to calculating trend: mixed-effects, linear model
  
  ## calculate trend with zscore of data  
  result[["basin_trend"]] <- result$basin_status %>% 
    mutate(zscore = (ices6_meansum - mean(ices6_meansum))/sd(ices6_meansum)) %>% 
    filter(year %in% yrs) %>%
    group_by(Subbasin) %>% 
    ## regression model to get trend from raw observations
    do(trend_mdl = lm(zscore ~ year, data = .)) %>%  
    ## alternative: mixed-effects model
    ## error for fitting the zscore data an issue if only 1 factor...
    # do({if(distinct(., lat) %>% nrow() > 1){
    #   trend_mdl = lmer(zscore ~ year + (1|lat), data = .)
    # } else {
    #   trend_mdl = lm(zscore ~ year, data = .)
    # }})
    summarize(
      trend_score = coef(trend_mdl)["year"]*trend_lag,
      numyrs = n()
    ) %>% 
    ungroup() %>% 
    ## number of years of status observations: basins should have all five
    ## basins for which no status was calculated will be excluded
    filter(Subbasin %in% filter(result$basin_status, !is.na(status))$Subbasin, numyrs == 5)
  
  
  result[["bhirgn_trend"]] <- datalayer %>% 
    mutate(obs = ) %>% 
    filter(year %in% yrs) %>%
    group_by(Subbasin) %>% 
    do(trend_mdl = lm(ices6_meansum ~ year, data = .)) %>% 
    summarize(
      trend_score = coef(trend_mdl)["year"]*trend_lag,
      numyrs = n()
    ) %>% 
    ungroup() %>% 
    ## number of years of status observations: basins should have all five
    ## basins for which no status was calculated will be excluded
    filter(Subbasin %in% filter(result$basin_status, !is.na(status))$Subbasin, numyrs == 5) %>% 
    ## assign BHI region the basin score
    left_join()
  
  return(result)
}
```

<br>

```{r evaluate pcb biota indicator status and trend}
## using adjusted values where data was flagged
pcbs_bio_eval_adj <- eval_cwcon_indicators(
  pcb_bio_sf,
  yrs = 2010:2019, 
  approach = "Adjusted"
)
dim(pcbs_bio_eval_adj$bhirgn_status)
summary(pcbs_bio_eval_adj$bhirgn_status)

## using only sets of observations that had no flags
pcbs_bio_eval_noQ <- eval_cwcon_indicators(
  pcb_bio_sf,
  basin_col = "HELCOM_ID", 
  bhi_col = "BHI_ID",
  yrs = 2010:2019, 
  approach = "NoQflag"
)
dim(pcbs_bio_eval_noQ$bhirgn_status)
summary(pcbs_bio_eval_noQ$bhirgn_status)

## comparing the two approaches, for data aggregated by BHI regions, and by Subbasins
ggplot(bind_rows(
    pcbs_bio_eval_adj$basin_status %>% mutate(approach = "Adjusted_Basin"),
    pcbs_bio_eval_adj$bhirgn_status %>% mutate(approach = "Adjusted_BHI"),
    pcbs_bio_eval_noQ$basin_status %>% mutate(approach = "NoQflag_Basin"),
    pcbs_bio_eval_noQ$bhirgn_status %>% mutate(approach = "NoQflag_BHI")
  )) +
  geom_col(aes(date, ices6_meansum, color = approach), position = position_dodge()) +
  geom_hline(yintercept = 75) +
  facet_wrap(~BHI_ID, scales = "free_y")

DT::datatable(full_join(
  pcbs_bio_eval_adj$basin_status %>% 
    arrange(year) %>% 
    group_by(Subbasin) %>% 
    summarise(lastyr_adjusted <- last(year)),
  pcbs_bio_eval_noQ$basin_status %>% 
    arrange(year) %>% 
    group_by(Subbasin) %>% 
    summarise(lastyr_noQflag <- last(year)),
  by = "Subbasin"
))
```



<!-- #### 4.5.4 Calculate Status -->
<!-- Xices6 = 1/ (Mean_ICES6_region / Reference_pt  ) * penalty_factor -->
<!-- Reference_pt = health_threshold=  75ug/kg -->

<!-- Scale between 0 and 1.  If value is below 75, score = 1 -->

```{r pcb trend calculation}
## ten year period for data used in calculating linear model, mean by basin (also count number observations)
## assign bhi regions their correspoinding basin means





```


*Conclusions:*

<!-- - Including the qflag-adjusted values lowers the mean concentration by date and location -->
<!-- - Including qflag-adjusted values also provides more observations in the Kattegat, The Quark, and W. Gotland Basin  -->
<!-- - Outlier in Eastern Gotland Basin is from Polish observations 2014. Have checked unit conversions etc, have found not error. -->

<!-- - When aggregating by BHI regions, more observations for Regions 1, 11,26,35,36,39,41,42 when including qflagged values -->

<!-- - Use data including qflag-adjusted (this could lower values)   -->
<!-- - Use 5 year mean ICES6 concentration  -->

<br>

```{r save useful intermediate datasets and pcbs contaminants layer}
write_csv(
  pcbs_shiny,
  here::here("data", "CW", "contaminants", version_year, "intermediate", "cw_con_shinydata.csv")
)
write_csv(
  pcbs_final,
  file.path(dir_layers, bhi_version, sprintf("cw_con_ices6_bhi%s.csv", assess_year))
)
```


The following pieces of code from data prep `BHI1.0` will be integrated into `functions.R`, to reduce numbers of steps in the more labor-intensive data preparation steps...

```{r calculation of ices6 status and trend}

```

<br>


#### 3.1.5 Methods discussion

**Status formula, ICES6 PCBs Biota**
$X_{\mbox{ICES6}} = \frac{1}{\mbox{mean_ICES6_region/reference_point} \times \mbox{penalty_factor}}$

$\mbox{reference_point} = 75ug/kg \times \mbox{health_threshold}$

Scale between 0 and 1.  If value is below 75, $\mbox{score} = 1$

**Only herring (not other species) used from biota dataset, because herring are most equally spatially spaced across the baltic sea, whereas others are mostly in the south**

<br>

**Notes on Status Calculation**

- Using data including qflag-adjusted (this could lower values for trend)  
- Using 5 year mean ICES6 concentration  
- Scale all observations relative to the human health threshold? **Why Scale?** If values are all below the threshold would not want an increase trend in observed values to suggest that the future status will be worse?? 
- **Need to have mixed-effects to account for different stations?**

<br>

**Trend Considerations**

1. Work on mixed effect model for trends?  
2. Need to think about the interpretation of the data treatment. (a) If use raw observations, then normalize (zscore data), then fit trend, if get increase or decrease but all values are below the threshold, does it make sense to apply a change in the trend to the status?  Would we really think the future status will be lower?  (b) If take all raw observations, calculate "status" as done for the mean value, then fit trend, is this more true to the idea that variation below the human health threshold should not affect the trajectory of the future status?  
3. Need to think if simple linear regression is okay, or if need to account for site?  

<br>

**`BHI1.0` discussions with Anna Sobek **

1. Indicator choice: We agreed that *ICES6 is the best* option  
2. Decision about use of qflagg-adjusted data: *use qflagged data with the adjustement* of (congener conc/2)  
3. Decision about spatial scale of the data: decide best approach is to *calculate for each basin*  
4. Trend decision: best approach is first convert individual observations to a "status" relative to the human health threshold, then fit linear model by basin for *10 year period*. (**TREND CHECK:** Does the trend value need to be rescaled to between -1 and 1? Does not exceed now but need to consider if method broadly works?)  

<!-- **`BHI2.0` discussions with Anna Sobek ** -->


---

<br>

### 3.2 PFOS Indicator
#### 3.2.1 Match BHI Regions

**Use Lat/Long to Match BHI Regions**
```{r assign BHI regions to PFOS data, echo = TRUE, message = FALSE, warning = FALSE}
## use 'join_rgns_info' helper function defined in spatial.R
pfos_bio_sf <- join_rgns_info(
  pfos_bio_clean_df, 
  latlon_vars = c("latitude", "longitude"),
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles"),
  return_spatial = TRUE
)
```

<br>

#### 3.2.2 Evaluate flagged data & sampling patterns

Using the function defined above at the end of **section 3.1.3** to evaluate flagged data and sampling patterns for PFOS in biota data:

```{r pfos input data initial data visualizations}
## create visualizations, view/show the results with e.g. pfos_eval$map...
pfos_eval <- make_cwcon_viz(pfos_bio_sf, bhi_rgn_shp = bhi_rgns_simple, plottype = c("map", "plot", "widget"), yr = 2014)
```

<br>

#### 3.2.3 Status and trend options and calculation

```{r check pfos calculation and approach}

```

<br>

```{r save pfos contaminants layers}
write_csv(
  pfos_final,
  file.path(dir_layers, bhi_version, sprintf("cw_con_pfos_bhi%s.csv", assess_year))
)
```

<br>

The following pieces of code from data prep `BHI1.0` will be integrated into `functions.R`, to reduce numbers of steps in the more labor-intensive data preparation steps...

```{r calculation of pfos status and trend}
# pfos_status_layer <- pfos_status_rgn %>%
#   dplyr::rename(score = pfos_status)%>%
#   mutate(score = score*100,
#          dimension = "status")%>%
#   select(rgn_id,dimension,score)%>%
#   arrange(rgn_id)

# pfos_trend_basin <- pfos_trend_data %>% 
#   group_by(basin) %>% 
#   do(trend_mdl = lm(pfos_obs_status~year, data=.)) %>%  ## regression model to get trend from raw observations
#   summarize(
#     basin = basin,
#     trend_score = coef(trend_mdl)['year']*5 ## number of years for future status
#   ) %>% 
#   ungroup()
# pfos_trend_layer <- pfos_trend_rgn %>%
#   dplyr::rename(score = trend_score)%>%
#   mutate(dimension = "trend")%>%
#   select(rgn_id,dimension,score)%>%
#   arrange(rgn_id)
```

#### 3.2.4 Methods discussion


**Trend Calculation**

Calculate the trend over five-year data period using unique date/location observations (mean of site samples) transformed to status values. Trend calculated per basin.

$X_{basin} = \mbox{slope }\times \mbox{year } + \mbox{intercept }$

$\mbox{Trend} = 5 \times \mbox{slope }$


---

<br>

### 3.3 Dioxin Indicator
#### 3.3.1 Match BHI Regions and Join with Dioxin-like PCBs

**Use Lat/Long to Match BHI Regions**

```{r assign BHI regions to Dioxin data, echo = TRUE, message = FALSE, warning = FALSE}
## use 'join_rgns_info' helper function defined in spatial.R
dioxin_bio_sf <- join_rgns_info(
  dioxin_bio_clean_df,
  latlon_vars = c("latitude", "longitude"),
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles"),
  return_spatial = TRUE
)
dioxin_sed_sf <- join_rgns_info(
  dioxin_sed_clean_df,
  latlon_vars = c("latitude", "longitude"),
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles"),
  return_spatial = TRUE
)
```
<br>

**Assess if Dioxins and dioxin-like PCBs share `sub_sample_ref`**
Were dioxins and PCBs measured from the same samples such that a total TEQ value per sample can be calculated?

**Use TEF conversion factor to convert to TEQ**
Dioxins and dioxin-like PCBs still separate objects here.

```{r convert to TEQ}

```

**Filter PCB to keep only dioxin-like PCBs and convert units**

```{r convert dioxin like PCBs ug to pg per gram}

```

<br>

#### 3.3.2 Evaluate flagged data & sampling patterns

**Adjust Qflagged values**
Use $LOD/2$ approach to adjust values. Because we do not have the LOD in all cases, use: $adjustedValue = value / 2$

**Filter to keep only years where exists quality data**

<br>

#### 3.3.3 Indicator options and calculation

**Calculate the mean TEQ value by basin using just years 2009-2013 (?)**
<br>

**Total TEQ (pg/g) Dioxin**

Calculate the sum of the mean dioxin and the mean dioxin-like PCB TEQ value for each date and location. For observations averaged, also calculate mean, min, and max number of congeners in each of the observations, and also numbers of observations for each date and location.

Horizontal line is the EU human health threshold (6.5 TEQ pg/g ww) (equivalent to suggested HELCOM level of 0.0065 TEQ ug/kg ww)

<br>

#### 3.3.4 Methods discussion

**Dioxin status value**

$X_{TEQstatus} = \frac{1}{\mbox{dioxin + } \mbox{dioxin-like pcb teq value / teq threshold }}$


<br/>

## 4. Contaminant Indicator

```{r read in indicator layers and join into single object}
con_status <- bind_rows(
  read_csv() %>% mutate(ind = "bioPCB"),
  read_csv() %>% mutate(ind = "bioDioxin"),
  read_csv() %>% mutate(ind = "bioPFOS"),
  read_csv(),
  read_csv(),
  read_csv()
)
con_trend <- bind_rows(
  read_csv(),
  read_csv(),
  read_csv(),
  read_csv(),
  read_csv(),
  read_csv()
)
```

### 4.1 Plotting Indicators for Comparison

### 4.2 Number of Indicators per BHI Region and Subbasin

### 4.3 Trends by BHI Region

```{r plot basin trends for all indicators}
ggplot(trends_dataframe)+
  geom_point(aes(Subbasin, trend_score), size = 2.5) +
  labs(x = "Subbasin", y = "Trend score")
```


<br/>

## 5. Visualizing Data Layers

### 5.1 Timeseries Plots

```{r }

```

<br>

### 5.2 Contaminants by BHI Regions and by Subbasins

```{r}

```

<br/>

### 5.3 Contaminants data layers Map

```{r}

```

<br/>

---

<br>

## 6. Considerations for `BHI3.0`

---

<br>

## 7. References

<br>

```{r References, child = refs_path, results = "asis", echo = FALSE}
```

<br>
