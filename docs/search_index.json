[
["index.html", "Baltic Health Index Data Preparation 2019 Introduction", " Baltic Health Index Data Preparation 2019 Ellie Campbell, Andrea De Cervo, Thorsten Blenckner 2020-04-20 Introduction The bhi-prep repository includes all scripts, lookup tables, and links to data sources used in preparing data layers for BHI2.0 – Ocean Health Index Assessment for the Baltic Sea, 2019 assessment. This book presents one chapter per goal/subgoal, each containing all the information relevant that goal, as documented in the repository. For more information about the Baltic Health Index see: https://github.com/OHI-Science/bhi For more information about the Ocean Health Index see: http://ohi-science.org "],
["contaminants-clean-water-subgoal.html", "Chapter 1 Contaminants - Clean Water Subgoal 1. Background 2. Data 3. Wrangling, Evaluation, and Gapfilling 4. Visualizing Contaminants Data Layers 5. Considerations for BHI3.0 6. References", " Chapter 1 Contaminants - Clean Water Subgoal 1. Background 1.1 Goal Description The Contaminant sub-goal of the Clean Water goal captures the degree to which local waters are unpolluted by contaminants. This sub-goal scores highest when the contamination level is below a threshold, which is defined by the Marine Framework Directive. For the BHI three contaminants indicators are proposed, describing different aspects of toxicity: dioxin and dioxin like compounds, polychlorinated biphenyl compounds (PCBs), and perfluorooctanesulfonic acid (PFOS). In addition, a penalty factor has been applied to account for the fact that current monitoring programs do not cover all the registered and harmful contaminants. 1.2 Model &amp; Data All contaminant data were downloaded from the open-accessible ICES database (see below). ICES Database for Contaminants in Biota (PCBs, Dioxins, PFOS, and Concerning Substances) ICES Database for Contaminants in Sediment (PCBs, Dioxins, and Concerning Substances) Reference codes for PCB Congeners Reference codes for Dioxin Congeners Table to calculate the Concerning Substances indicator (penalty factor): European Chemical Agency Candidate List of substances of very high concern for Authorisation 1.3 Reference points 1.3.1 PCB Concentration Indicator Biota Non-dioxin like PCBs: sum of congeners (28, 52, 101, 138, 153, 180). Target is set at the threshold of 75 ug/kg ww (wet weight) fish muscle. This is similar to the ICES-7 except that PCB 118 is excluded, since it is metabolized by mammals. 75 ng/g wet weight is the EU threshold for fish muscle. See Section 5 Annex, 5.3. This threshold was also agreed upon as GES boundary at the meeting of the Working Group on the State of the Environment and Nature Conservation April 11-15, 2016. Recevied the draft report from Elisabeth Nyberg. 1.3.2 TEQ values for Dioxins and Dioxin-like PCBs in Biota Dioxin and dioxin-like compounds. Target is set at 0.0065 TEQ ug/kg ww fish, crustaceans or molluscs (source of target: EQS biota human health). Secondary GES boundary: CB-118 24 ug/kg lw fish liver or muscle (source: EAC). This threshold was agreed upon as GES indicator at the meeting of the Working Group on the State of the Environment and Nature Conservation April 11-15, 2016. Recevied the draft report from Elisabeth Nyberg. This is consistent with the EU human health thresholds for dioxin and dioxin-like compounds - 6.5 pg/g TEQ values from the World Health Organization 2005 1.3.3 PFOS Indicator According to HELCOM PFOS core indicator document, p.3, the “GES boundary is set to 9.1 μg/kg wet weight (or 9.1 ng/g ww) with the protection goal of human health”. “The GES boundary is an environmental quality standard (EQS), derived at EU level as a substance included on the list of priority substances under the Water Framework Directive (European Commission 2000, 2013). GES, in accordance with the MSFD is defined as ‘concentrations of contaminants at levels not giving rise to pollution effects’. EQS are derived from ecotoxicological studies to protect freshwater and marine ecosystems from potential adverse effects of chemicals, as well as adverse effects on human health via drinking water and food from aquatic environments. Quality Standards (QS) are derived for different protection goals, i.e.: pelagic and benthic communities, top-predators in these ecosystems, and human health. The most stringent of these QS is the basis for the EQS. The EQS boundary for PFOS is based on the QS set for biota to protect human health (9.1 μg/ kg fish ww), defined for edible parts in fish. For harmonization purposes the EC Guidance Document No. 32 on biota monitoring (the implementation of EQS biota) under the WFD was developed (European Commission 2014). This guidance document recommends that the results from the monitoring should be standardized to represent fish at a trophic level of 4, which is an estimate of the general trophic level in commercial fish in Europe. The recommendation to obtain PFOS data in fish at a trophic level of 4 is to adjust the values from monitoring in accordance with trophic magnification factors and trophic level.” \\(-\\) HELCOM PFOS core indicator document, p.8 HELCOM core indicator report uses liver PFOS concentrations converted to muscle equivalent values as in Faxneld et al. 2014b. 1.3.4 TEQ values for PCBs in Sediment Only a few environmental quality standards (EQS) are to date defined in the Baltic Sea for marine surface sediments. The Norwegian threshold values are often used when a comparison with ecotoxicological effects is needed. In particular, the Norwegian Environment Agency has defined EQS in sediment for 28 EU priority substances. PCB7 (sum PCB 28, 52, 101, 118, 138, 153, and 180): Target is set at 4.1 TS ug/kg dw. Environmental quality classification of water bodies Recommended threshold values are given only for total PCB7, and not for each individual congener. This is because toxicity data are available for only a minority of congeners. 1.3.5 TEQ values for Dioxins in Sediment Dioxin and dioxin-like compounds. Target is set at 0.00086 TEQ ug/kg dw (Total TEQ). Norwegian Environment Agency TEQ values from the World Health Organization 2005 1.4 Other information External advisors/goalkeepers: Anna Sobek 2. Data This prep document is used to generate and explore the following data layers: cw_con_pcb_bhi2019.csv cw_con_pfos_bhi2019.csv cw_con_dioxin_bhi2019.csv cw_con_penalty_bhi2019.csv These are saved to the layers folder. Intermediate datasets saved to data/CW/contaminants/v2019/intermediate include: pcb_bio_cleaned.csv, pcb_sed_cleaned.csv, pfos_bio_cleaned.csv, dioxin_bio_cleaned.csv and dioxin_sed_cleaned.csv. All these are derived from or informed by the following raw datasets. 2.1 Datasets with Sources 2.1.1 PCB Data PCB Data in Biota Table 1.1: Source: ICES Database Downloaded 22 April 2019 by Ellie Campbell Option Specification Year 1990-2017 Purpose of monitoring All Country All Monitoring Program All Parameter Group Chlorobiphenyls Reporting Laboratory All Analytical laboratory All Geographical Areas (HELCOM) ALL HELCOM sub-basins PCB Congeners Data Code CB180 2,2’,3,4,4’,5,5’-heptachlorobiphenyl SCB7 sum of CBs.- Sum of CB28 2,4,4’-trichlorobiphenyl CB52 2,2’,5,5’-tetrachlorobiphenyl CB101 2,2’,4,5,5’-pentachlorobiphenyl CB118 2,3’,4,4’,5-pentachlorobiphenyl CB153 2,2’,4,4’,5,5’-hexachlorobiphenyl CB138 2,2’,3,4,4’,5’-hexachlorobiphenyl PCB polychlorinated biphenyls - Deprecated- Report as single PCBs CB194 2,2’,3,3’,4,4’,5,5’-octachlorobiphenyl CB105 2,3,3’,4,4’-pentachlorobiphenyl CB110 2,3,3’,4’,6-pentachlorobiphenyl CB126 3,3’,4,4’,5-pentachlorobiphenyl CB128 2,2’,3,3’,4,4’-hexachlorobiphenyl CB149 2,2’,3,4’,5’,6-hexachlorobiphenyl CB151 2,2’,3,5,5’,6-hexachlorobiphenyl CB156 2,3,3’,4,4’,5-hexachlorobiphenyl CB157 2,3,4,3’,4’,5’-hexachlorobiphenyl CB170 2,2’,3,3’,4,4’,5-heptachlorobiphenyl CB44 2,2’,3,5’-tetrachlorobiphenyl CB49 2,2’,4,5’-tetrachlorobiphenyl CB99 2,2’,4,4’,5-pentachlorobiphenyl CB77 3,3’,4,4’-tetrachlorobiphenyl CB169 3,3’,4,4’,5,5’-hexachlorobiphenyl CB31 2,4’,5-trichlorobiphenyl CB81 3,4,4’,5-tetrachlorobiphenyl SCB sum of CBs.- Specify in method data CB189 2,3,3’,4,4’,5,5’-heptachlorobiphenyl CB114 2,3,4,4’,5-pentachlorobiphenyl CB123 1,1’-Biphenyl, 2,3’,4,4’,5’-pentachloro- CB167 2’,3,4,4’,5,5’-hexachlorobiphenyl CB187 2,2’,3,4’,5,5’,6-heptachlorobiphenyl CB66 2,3’,4,4’-tetrachlorobiphenyl CB60 1,1’-Biphenyl, 2,3,4,4’-tetrachloro- CB141 2,2’,3,4,5,5’-hexachlorobiphenyl CB74 2,4,4’,5-tetrachlorobiphenyl CB206 2,2’,3,3’,4,4’,5,5’,6-nonachlorobiphenyl CB33 2’,3,4-trichlorobiphenyl CB18 2,2’,5-trichlorobiphenyl CB183 2,2’,3,4,4’,5’,6-heptachlorobiphenyl CB47 2,2’,4,4’-tetrachlorobiphenyl CB209 2,2’,3,3’,4,4’,5,5’,6,6’-decachlorobiphenyl CB51 2,2’,4,6’-Tetrachlorobiphenyl CB122 1,1’-Biphenyl, 2,3,3’,4’,5’-pentachloro- CB138+163 2,2’,3,4,4’,5’-hexachlorobiphenyl PCBs in Sediment Table 1.2: Source: ICES Database Downloaded 13 February 2020 by Ellie Campbell Option Specification Year All8 Purpose of monitoring All Country All Monitoring Program All Parameter Group Chlorobiphenyls Reporting Laboratory All Analytical laboratory All Geographical Areas (ICES) All ICES Areas 2.1.2 PFOS Data PFOS in Biota Table 1.3: Source: ICES Database Downloaded 22 April 2019 by Ellie Campbell Option Specification Year 2005-2017 (2005 earliest allowed) Purpose of monitoring All Country All Monitoring Program All Parameter Group Organofluorines Reporting Laboratory All Analytical laboratory All Geographical Areas (HELCOM) ALL HELCOM sub-basins 2.1.3 Dioxin Data Dioxins in Biota Table 1.4: Source: ICES Database Downloaded 22 April 2019 by Ellie Campbell Option Specification Year 1998-2017 (1998 earliest allowed) Purpose of monitoring All Country All Monitoring Program All Parameter Group Dioxins Reporting Laboratory All Analytical laboratory All Geographical Areas (HELCOM) ALL HELCOM sub-basins Dioxin Congeners Data Code CDD1N 1 2 3 7 8-pentachlorodibenzo-p-dioxin CDD4X 1 2 3 4 7 8-hexachlorodibenzo-p-dioxin CDD6P 1 2 3 4 6 7 8-heptachlorodibenzo-p-dioxin CDD6X 1 2 3 6 7 8-hexachlorodibenzo-p-dioxin CDD9X 1 2 3 7 8 9-hexachlorodibenzo-p-dioxin CDDO 1 2 3 4 6 7 8 9-octachlorodibenzo-p-dioxin CDF2N 2 3 4 7 8-pentachlorodibenzofuran CDF2T 2 3 7 8-tetrachloro-dibenzofuran CDF4X 2 3 4 6 7 8-hexachlorodibenzofuran CDF6P 1 2 3 4 6 7 8-heptachlorodibenzofuran CDF6X 1 2 3 6 7 8-hexachlorodibenzofuran CDF9P 1 2 3 4 7 8 9-heptachlorodibenzofuran CDF9X 1 2 3 7 8 9-hexachlorodibenzofuran CDFDN 1 2 3 7 8/1 2 3 4 8-pentachloro-dibenzofuran CDFO octachloro-dibenzofuran (group) TCDD 2 3 7 8-tetrachlorodibenzo-p-dioxin Dioxins in Sediment Table 1.5: Source: ICES Database Downloaded 13 February 2020 by Ellie Campbell Option Specification Year All Purpose of monitoring All Country All Monitoring Program All Parameter Group Dioxins Reporting Laboratory All Analytical laboratory All Geographical Areas (ICES) All ICES Areas 2.1.4 Concerning Substances Datasets A list of concerning substances was obtained from European Chemical Agency Candidate List of substances of very high concern for Authorisation (published in accordance with Article 59(10) of the REACH Regulation). These substances were compared with those in the ICES database. Datasets for substances with ICES records were downloaded and saved in a similar manner as the PCBs, PFOS, and Organofluorines datasets. 2.2 Centralization &amp; Normalization This preliminary data wrangling includes steps to harmonize and check the 5 datasets used in the Contaminants subgoal: Check number of years with samples by Country and Species, for Contaminants in Biota datasets Rename columns and some variables within columns to improve clarity Standardize by converting units and also between methods of measurement (e.g. wet vs. dry weight or muscle vs liver matrix analyzed) More details about the standardization and convertions in section 2.2.2. ## root location of the raw data dir_rawdata &lt;- file.path(dir_B, &quot;Goals&quot;, &quot;CW&quot;, &quot;CON&quot;) lapply( list( c(&quot;ContaminantsBiota_20Feb07_PCBs&quot;, &quot;pcb_rawdata_bio&quot;), c(&quot;ContaminantsSediment_PCBs&quot;, &quot;pcb_rawdata_sed&quot;), c(&quot;ContaminantsBiota_20Feb07_PFOS&quot;, &quot;pfos_rawdata_bio&quot;), c(&quot;ContaminantsBiota_20Feb07_Dioxins&quot;, &quot;dioxin_rawdata_bio&quot;), c(&quot;ContaminantsSediment_Dioxins&quot;, &quot;dioxin_rawdata_sed&quot;) ), function(x){ read_csv( file.path(dir_rawdata, x[1], paste(x[1], &quot;csv&quot;, sep = &quot;.&quot;)), ## where not read in correctly, column types must be specified ... col_types = cols( .default = col_character(), MYEAR = col_number(), Latitude = col_number(), Longitude = col_number(), NOINP = col_number(), Value = col_number(), DETLI = col_number(), LMQNT = col_number(), UNCRT = col_number(), tblAnalysisID = col_number(), tblParamID = col_number(), tblBioID = col_number(), tblSampleID = col_number() ) ) %&gt;% assign(x = x[2], envir = .GlobalEnv) } ) Check number of years with samples by Country {.tabset .tabset-fade .tabset-pills} PCBs PFOS Dioxins 2.2.1 Rename Fields/Variables Renaming columns and some variables within columns for clarity. See references: Contaminants in Biota and Contaminants in Sediment. For more information about the ICES reporting format for environmental data see this document, also referenced in this document from HELCOM BalticBOOST workshop on the HOLAS II hazardous substance assessment. rename_vars &lt;- function(dataset){ df_vars_renamed &lt;- dataset %&gt;% ## create date, month, year, day columns dplyr::mutate(date = as.Date(DATE, &quot;%d/%m/%Y&quot;)) %&gt;% dplyr::mutate( day = lubridate::day(date), month = lubridate::month(date), year = lubridate::year(date)) %&gt;% ## change column names dplyr::rename( country = Country, report_institute = RLABO, station = STATN, monit_year = MYEAR, date_ices = DATE, latitude = Latitude, longitude = Longitude, param_group = PARGROUP, variable = PARAM, value = Value, unit = MUNIT, species = Species, sex_specimen = SEXCO, num_indiv_subsample = NOINP, test_organism = `Test Organism`, matrix_analyzed = MATRX, not_used_in_datatype = NODIS, monit_program = MPROG, monit_purpose = PURPM, basis_determination = BASIS, qflag = QFLAG, vflag = VFLAG, detect_lim = DETLI, quant_lim = LMQNT, uncert_val = UNCRT, method_uncert = METCU, analyt_lab = ALABO, ref_source = REFSK, method_storage = METST, method_pretreat = METPT, method_pur_sep = METPS, method_chem_fix = METFP, method_chem_extract = METCX, method_analysis = METOA, formula_calc = FORML, sub_samp_id = SUBNO, bulk_id = BULKID, sampler_type = SMTYP, factor_compli_interp = FINFL, analyt_method_ref = tblAnalysisID, measurement_ref = tblParamID, samp_ref = tblSampleID ) %&gt;% ## improve clarity of &#39;basis_determination&#39; and &#39;matrix_analyzed&#39; column content mutate(basis_determination = case_when( basis_determination == &quot;L&quot; ~ &quot;lipid weight&quot;, basis_determination == &quot;W&quot; ~ &quot;wet weight&quot;, basis_determination == &quot;D&quot; ~ &quot;dry weight&quot; )) %&gt;% mutate(matrix_analyzed = case_when( matrix_analyzed == &quot;LI&quot; ~ &quot;liver&quot;, matrix_analyzed == &quot;MU&quot; ~ &quot;muscle&quot;, matrix_analyzed == &quot;WO&quot; ~ &quot;wholeorganism&quot; )) return(df_vars_renamed) } ## same names and structures so can apply function to all datasets lapply( list(&quot;pcb_rawdata_bio&quot;, &quot;pfos_rawdata_bio&quot;, &quot;dioxin_rawdata_bio&quot;), function(x){ renameddf &lt;- rename_vars(get(x)) %&gt;% rename(sub_samp_ref = tblBioID) assign(str_remove(x, &quot;_rawdata&quot;), renameddf, envir = .GlobalEnv) } ) lapply( list(&quot;pcb_rawdata_sed&quot;, &quot;dioxin_rawdata_sed&quot;), function(x){ renameddf &lt;- rename_vars(get(x)) %&gt;% rename(press_depth = DEPHU, depth_low = DEPHL) %&gt;% mutate(press_depth = as.numeric(press_depth), depth_low = as.numeric(depth_low)) assign(str_remove(x, &quot;_rawdata&quot;), renameddf, envir = .GlobalEnv) } ) 2.2.2 Standardize Units The main objective of the code below is to clean the contaminants datases set so they contain only values based on wet weight for biota or dry weight for sediment-matrix measurements, in standardized units of ug/kg. This includes the following pre-processing steps: Remove flagged and deprecated data entries Separate B-BIO data from the other param group data (OC-CB, OC-DX, or O-FL for PCB, Dioxin, PFOS resp.) for use in lipid basis to wet weight conversion for biota or for conversion to dry weight for sediments; also for calculation of muscle equivalent in PFOS data Take averages where there are duplicate data samples, based on the sub_samp_ref value groupings for biota or samp_ref value groupings for sediment-matrix measurements If wrangling PFOS dataset, calculate the muscle equivalent of values where matrix analyzed was liver, using Faxneld et al 2014, table 8 Convert all congener concentration data to ug/kg, and to wet weight for biota or dry weight for sediment If data were presented in lipid weight, they were converted to wet weight by: \\((\\mbox{EXLIP%}/100)*(\\mbox{CB conc. lipid weight})\\) The datasets each contain two main categories (param_groups) one of which is BBIO. BBIO consists of variables with information about the sample like dry/lipid/wet weight percentage, age, weight and length. The second category contains the congeners concentration information. In stages, these are each manipulated and later rejoined by the sample (samp_ref or sub_samp_ref) ID numbers. Check Sediment data Coverage before Filtering and Standardizing Units Setting the cutoff to 0.05m (concentration measurements from sediment samples taked from within 5cm of the surface) means we retain coverage in the Gulf of Finland for PCBs indicator, and many more measurements in Germany around Kiel. Setting the depth cutoff to any smaller value would result in poor coverage. ## basemap with baltic countries borders and BHI regions with ID numbers bhi_rgns_simple &lt;- rmapshaper::ms_simplify( input = sf::st_read( dsn = file.path(dirname(dir_B), &quot;Shapefiles&quot;, &quot;BHI_shapefile_corrected&quot;), layer = &quot;BHI_shapefile_corrected&quot;, quiet = TRUE )) %&gt;% sf::st_as_sf() basemap &lt;- ggplot2::ggplot() + geom_sf( data = rnaturalearth::ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) %&gt;% sf::st_crop(xmin = 0, xmax = 40, ymin = 53, ymax = 67), fill = &quot;ivory&quot;, color = &quot;lightsteelblue&quot;, size = 0.1, alpha = 0.8 ) + geom_sf(data = bhi_rgns_simple, fill = NA, size = 0.15, color = &quot;lightsteelblue&quot;) + scale_x_continuous(limit = c(4, 32)) + scale_y_continuous(limit = c(53.5, 66)) + theme(panel.background = element_rect(fill = &quot;#F8FBFC&quot;, color = &quot;#E2EEF3&quot;)) standardize_con_data &lt;- function(data_renamed, matrix_biota = TRUE, contam_param, rm_vars = NULL){ contam_param &lt;- substr(contam_param, str_length(contam_param)-1, str_length(contam_param)) ## what are the specific parameters? ## unique parameter groups and associated variables: chk_params &lt;- data_renamed %&gt;% select(param_group, variable) %&gt;% distinct() %&gt;% arrange(param_group, variable) ## filter and/or remove unneeded variables from data ---- message(&quot;STEP 1: filter and/or unselect unneeded variables and congeners from dataset\\n&quot;) df &lt;- data_renamed %&gt;% ## remove &#39;suspect&#39; and other non-&#39;acceptable&#39;: https://vocab.ices.dk/?ref=58 filter(!vflag %in% c(&quot;S&quot;, &quot;C&quot;)) %&gt;% ## remove certain variables-- summarized data or depreciated codes filter(!variable %in% rm_vars) if(contam_param != &quot;FL&quot;){ ## remove samples for liver tissue, keep muscle, and whole organism for length x weight df &lt;- filter(df, matrix_analyzed != &quot;liver&quot; | is.na(matrix_analyzed)) } ## for PFOS (contaminant pargroup &#39;O-FL&#39;), keep liver measurements-- ## all compounds except parameter &#39;PFOS&#39; measured only in the liver ## DRYWT% and EXLIP% have been measured for both muscle and liver ## sediment versus biota datasets, different sample/id variables sampvars &lt;- c(&quot;sub_samp_id&quot;, &quot;samp_ref&quot;, &quot;sub_samp_ref&quot;) if(!matrix_biota){ sampvars &lt;- setdiff(sampvars, &quot;sub_samp_ref&quot;) } ## check alignment of all measurements with sub_samp_ref for biota, samp_ref for sediment ## (most unique besides measurement_ref) ## there are more unique measurement_ref but these are for different vars w/in sub_samp_id chk_ids &lt;- c() for(i in c(sampvars, &quot;measurement_ref&quot;)){ chk_ids &lt;- c(chk_ids, sprintf(&quot;%s: %s&quot;, i, length(unique(df[[i]])))) } if(nrow(df %&gt;% filter(is.na(sampvars[length(sampvars)]))) != 0){ warning(sprintf(&quot;there are observations without %s in the dataset&quot;, sampvars[length(sampvars)])) } message(sprintf(&quot;NOTE will align by %s when grouping to identify duplicates\\n&quot;, sampvars[length(sampvars)])) ## BBIO DATA ## separate out bbio data for lipid to wet-weight conversion ---- ## B-BIO variable code: http://vocab.ices.dk/?CodeID=51634 ## b-bio data -- length, weight, fat and lipid content ## lipid content, etc. needed to convert lipid basis samples into the wet weight are in the B-BIO column message(&quot;STEP 2: separate out bbio data and wrangle for use in lipid to wet-weight conversion...\\n&quot;) df_bbio &lt;- df %&gt;% filter(param_group == &quot;B-BIO&quot;) %&gt;% select( station, latitude, longitude, date, year, species, matrix_analyzed, basis_determination, qflag, variable, unit, value, !!!syms(sampvars) ) ## if there are cm, convert to mm df_bbio &lt;- df_bbio %&gt;% left_join( read_csv( here::here(&quot;supplement&quot;, &quot;lookup_tabs&quot;, &quot;unit_conversion.csv&quot;), col_types = cols() ) %&gt;% filter(ConvertUnit == &quot;mm&quot;), by = c(&quot;unit&quot; = &quot;OriginalUnit&quot;) ) %&gt;% mutate( value = ifelse(is.na(ConvertUnit), value, value*ConvertFactor), unit = ifelse(is.na(ConvertUnit), unit, &quot;mm&quot;) ) %&gt;% select(-ConvertUnit, -ConvertFactor) ## confirm that units of bbio, are one-to-one chk_bbio_units &lt;- df_bbio %&gt;% select(variable, unit) %&gt;% distinct() ## if dealing with sediment, need to keep units for now... if(matrix_biota){df_bbio &lt;- select(df_bbio, -unit)} chk_num_bbio_dup &lt;- nrow(df_bbio) - nrow(distinct(df_bbio %&gt;% select(-value))) ## BBIO DUPLICATES ## identify, explore, handle bbio duplicates ---- ## group to identify duplicates; for a given sub_samp_ref only some variables may have duplicates grpvars &lt;- c( &quot;station&quot;, &quot;year&quot;, &quot;species&quot;, &quot;basis_determination&quot;, &quot;matrix_analyzed&quot;, &quot;qflag&quot;, sampvars, &quot;date&quot;, &quot;variable&quot;, &quot;longitude&quot;, &quot;latitude&quot; ) chk &lt;- c() for(i in 1:6){ bbio_duplicates &lt;- df_bbio %&gt;% group_by(!!!syms(c(grpvars[i], grpvars[7:length(grpvars)]))) %&gt;% summarise(n = n()) %&gt;% filter(n &gt; 1) %&gt;% ungroup() chk &lt;- c(chk, nrow(filter(bbio_duplicates, n &gt; 1))) } if(var(chk) != 0){ message(sprintf( &quot;NOTE bbio duplicates dataframe dims vary with grpvars: %s&quot;, paste(grpvars[which(chk != chk[which.max(tabulate(match(chk, chk)))])], collapse = &quot;, &quot;) )) } ## join duplicate table by grouped vars to locate within full bbio dataset bbio_duplicates &lt;- df_bbio %&gt;% group_by(!!!syms(grpvars)) %&gt;% summarise(n = n()) %&gt;% filter(n &gt; 1) %&gt;% ungroup() df_bbio &lt;- left_join(df_bbio, bbio_duplicates, by = grpvars) ## take averages for variable/sample duplicates df_bbio &lt;- bind_rows( ## averages of duplicates df_bbio %&gt;% filter(n &gt; 1) %&gt;% group_by(!!!syms(grpvars)) %&gt;% summarize(value = mean(value)) %&gt;% ungroup(), ## rows of bbio data with no duplicates df_bbio %&gt;% filter(is.na(n)) %&gt;% select(-n) ) ## check for unique variables and matrix_analyzed, per species chk_bbio_vars &lt;- NULL if(matrix_biota){ chk_bbio_vars &lt;- do.call( rbind, lapply( as.list(unique(df_bbio$species)), function(x){ cbind( df_bbio %&gt;% filter(species == x) %&gt;% select(matrix_analyzed, basis_determination, variable) %&gt;% distinct() %&gt;% arrange(variable, matrix_analyzed, basis_determination), species = x ) } ) ) } ## WIDE BBIO DATA ## bbio data wide format ---- ## remove basis_determ. as some bio vars are recorded for whole organism, others for liver or muscle, ## no concentration variables measured for whole organism matrix, so don&#39;t need for joining... ## no problem pivoting wider also indicates uniquely identified by remaining grouping variables # unique(filter(df, param_group != &quot;B-BIO&quot;)$matrix_analyzed) if(contam_param == &quot;FL&quot;){ ## for PFOS we have liver and muscle measurements ## need to deal with matrix_analyzed to get &#39;muscle equivalent&#39; from conc. measurements in liver df_bbio_wide &lt;- df_bbio %&gt;% mutate(variable = paste(matrix_analyzed, variable, sep = &quot;_&quot;)) %&gt;% select(-matrix_analyzed, -basis_determination) } else { df_bbio_wide &lt;- df_bbio %&gt;% select(-basis_determination) } df_bbio_wide &lt;- df_bbio_wide %&gt;% tidyr::pivot_wider(names_from = variable, values_from = value) ## which columns are needed to uniquely identify and later rejoin with congener conc. data ## i.e. at this stage, which subset of grpvars gives groupings such that all n are one? # for(i in grpvars){print(paste(i, length(unique(df_bbio_wide[[i]]))))} chkgrpvars &lt;- intersect(grpvars, names(df_bbio_wide)) chk &lt;- chkgrpvars for(i in 1:length(chkgrpvars)){ bbio_wide_duplicates &lt;- df_bbio_wide %&gt;% group_by(!!!syms(setdiff(chk, chkgrpvars[i]))) %&gt;% summarise(n = n()) %&gt;% ungroup() %&gt;% filter(n &gt; 1) if(nrow(bbio_wide_duplicates) == 0){ chk &lt;- setdiff(chk, chkgrpvars[i]) } } message(sprintf( &quot;NOTE minimum group ID variables for later rejoining uniquely with congener data:\\n%s\\n&quot;, paste(chk, collapse = &quot;, &quot;) )) chk_bbio_wide_ids &lt;- chk ## sub_samp_id and samp_ref together are as unique as sub_samp_ref # nrow(select(df_bbio_wide, sub_samp_ref) %&gt;% distinct()) # nrow(select(df_bbio_wide, sub_samp_id, samp_ref) %&gt;% distinct()) ## CONGENER CONCENTRATIONS DATA ## check congener concentration data, units and duplicates ---- if(!matrix_biota){ ## units of depth variables meters ## only keep sediment measurements in top 2cm, ## or maximum 5cm if filtering to within 2cm of surface yeilds too few data pts... df &lt;- df %&gt;% filter(depth_low &lt;= 0.05) } df_conc &lt;- df %&gt;% filter(str_detect(param_group, pattern = contam_param)) %&gt;% select( station, latitude, longitude, date, year, species, matrix_analyzed, basis_determination, variable, unit, value, detect_lim, quant_lim, qflag, !!!syms(sampvars) ) ## convert congener concentration units all to ug/kg message(&quot;STEP 3: convert congener concentrations units to ug/kg&quot;) df_conc &lt;- df_conc %&gt;% left_join( read_csv( here::here(&quot;supplement&quot;, &quot;lookup_tabs&quot;, &quot;unit_conversion.csv&quot;), col_types = cols() ) %&gt;% filter(ConvertUnit == &quot;ug/kg&quot;), by = c(&quot;unit&quot; = &quot;OriginalUnit&quot;) ) %&gt;% mutate( value = value*ConvertFactor, detect_lim = detect_lim*ConvertFactor, unit = &quot;ug/kg&quot; ) %&gt;% select(-ConvertUnit, -ConvertFactor) ## check whether variables vs units relationship is one-to-one chk_conc_units &lt;- df_conc %&gt;% select(variable, unit) %&gt;% distinct() %&gt;% arrange(variable) df_conc &lt;- select(df_conc, -unit) ## take averages for congener conc. variable x sample duplicates ---- ## identify duplicates ## group to identify duplicates, ## for a given sub_samp_ref only some vars/congeners may have duplicates message(&quot;STEP 4: averaging, where multiple congener concentrations observations per sub sample\\n&quot;) chk_num_conc_dup &lt;- nrow(df_conc) - nrow(distinct(df_conc %&gt;% select(-value, -detect_lim, -quant_lim))) conc_duplicates &lt;- df_conc %&gt;% group_by(!!!syms(grpvars)) %&gt;% summarise(n = n()) %&gt;% ## no cases where duplicates with-and-without qflags, else would keep cases unflagged observations... # group_by(!!!syms(setdiff(grpvars, &quot;qflag&quot;))) %&gt;% # mutate(allflagged = !any(is.na(qflag))) %&gt;% # filter(n &gt; 1, !allflagged) %&gt;% ... filter(n &gt; 1) %&gt;% ungroup() ## join duplicates tables by grouped vars to locate them in original dataset df_conc &lt;- left_join(df_conc, conc_duplicates, by = grpvars) chk_conc_dup &lt;- filter(df_conc, !is.na(n)) df_conc &lt;- bind_rows( ## averages of duplicates df_conc %&gt;% filter(n &gt; 1) %&gt;% group_by(!!!syms(grpvars)) %&gt;% summarize( value = mean(value), detect_lim = mean(detect_lim, na.rm = TRUE), quant_lim = mean(detect_lim, na.rm = TRUE) ) %&gt;% ungroup(), ## rows of conc data with no duplicates df_conc %&gt;% filter(is.na(n)) %&gt;% select(-n) ) ## remaining duplicates for biota datasets are due to dual wet/lipid weight records; ## of these, keep wet weight records, when has a value if(matrix_biota){ chk &lt;- df_conc %&gt;% group_by(!!!syms(setdiff(grpvars, c(&quot;basis_determination&quot;, &quot;matrix_analyzed&quot;)))) %&gt;% mutate(n = n(), ww_val = any(basis_determination == &quot;wet weight&quot; &amp; !is.na(value))) %&gt;% filter(n &gt; 1) %&gt;% mutate( rm_duplicate = (ww_val &amp; basis_determination == &quot;lipid weight&quot;)| (!ww_val &amp; basis_determination == &quot;wet weight&quot;) ) %&gt;% ungroup() df_conc &lt;- df_conc %&gt;% left_join(chk, by = intersect(names(df_conc), names(chk))) %&gt;% mutate(rm_duplicate = ifelse(is.na(rm_duplicate), TRUE, rm_duplicate)) %&gt;% filter(rm_duplicate) %&gt;% select(-n, -ww_val, -rm_duplicate) } ## do not want to spread the data because the qflag, detli etc is unique to each congener ## but, spread to check if one row for every unique sub_samp_ref for biota, samp_ref for sediment df_conc_wide &lt;- df_conc %&gt;% select(-detect_lim, -quant_lim) %&gt;% tidyr::pivot_wider(names_from = variable, values_from = value) if(length(unique(df_conc[[sampvars[length(sampvars)]]])) != nrow(distinct(df_conc_wide))){ message( &quot;NOTE conc. subsamples not uniquely identified even after averaging; multiple obs per ID, probably due to qflags\\n&quot; ) } ## for biota convert lipid weight measurements to wet weight ---- ## UNITS HAVE ALL BEEN CONVERTED TO MICROGRAMS PER KILOGRAM ## use the df_bbio_wide datatable to convert values in df_conc table df_final &lt;- left_join(df_conc, df_bbio_wide, by = intersect(grpvars, names(df_bbio_wide))) if(matrix_biota){ message(&quot;STEP 5: converting all congener concentrations in biota to wet weight, muscle equivalence&quot;) ## for PFOS data convert liver values into those for muscle ## using conversion values from Faxneld et al 2014 ## https://www.diva-portal.org/smash/get/diva2:767385/FULLTEXT01.pdf) ## follow methods in the HELCOM core indicator p.9 ## http://www.helcom.fi/Core%20Indicators/PFOS_HELCOM%20core%20indicator%202016_web%20version.pdf ## use the mean liver:muscle ratio for all species (17.9), see Table 8 in Faxneld et al 2014 if(contam_param == &quot;FL&quot;){ df_final &lt;- df_final %&gt;% mutate_at( vars(c(&quot;value&quot;, &quot;detect_lim&quot;, &quot;quant_lim&quot;)), list(pfos_muscle_equiv = ~ case_when( variable == &quot;PFOS&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./17.9, variable == &quot;PFOS&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., ## NOT IN BHI1.0, BUT INCLUDING FOR INITIAL EXPLORATION... variable == &quot;PFOA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./13.4, variable == &quot;PFOA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFOA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./6.13, variable == &quot;PFOA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFOA&quot; &amp; species == &quot;Perca fluviatilis&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./13.7, variable == &quot;PFOA&quot; &amp; species == &quot;Perca fluviatilis&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFDA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./19.4, variable == &quot;PFDA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFDA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./5.69, variable == &quot;PFDA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFDA&quot; &amp; species == &quot;Perca fluviatiliss&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./5.69, variable == &quot;PFDA&quot; &amp; species == &quot;Perca fluviatilis&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFNA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./15.5, variable == &quot;PFNA&quot; &amp; species == &quot;Clupea harengus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFNA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./5.62, variable == &quot;PFNA&quot; &amp; species == &quot;Zoarces viviparus&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFNA&quot; &amp; species == &quot;Perca fluviatilis&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./13.7, variable == &quot;PFNA&quot; &amp; species == &quot;Perca fluviatilis&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFPEDA&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./7.4, variable == &quot;PFPEDA&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ ., variable == &quot;PFUnDA&quot; &amp; matrix_analyzed == &quot;liver&quot; ~ ./10.1, variable == &quot;PFUnDA&quot; &amp; matrix_analyzed == &quot;muscle&quot; ~ . )) ) %&gt;% mutate_at( vars(c(&quot;value_pfos_muscle_equiv&quot;, &quot;detect_lim_pfos_muscle_equiv&quot;, &quot;quant_lim_pfos_muscle_equiv&quot;)), ## will probably all be in wet weight already, but just in case... list(wet_wgt = ~ case_when( basis_determination == &quot;lipid weight&quot; ~ .*(`muscle_EXLIP%`/100), # IS THIS HOW EXLIP% VARIABLE WORKS?? basis_determination == &quot;dry weight&quot; ~ .*(100/`muscle_DRYWT%`), # IS THIS HOW DRYWT% VARIABLE WORKS???? basis_determination == &quot;wet weight&quot; ~ . )) ) } else { df_final &lt;- df_final %&gt;% ## if value is not wet weight convert, otherwise keep value mutate_at( vars(c(&quot;value&quot;, &quot;detect_lim&quot;, &quot;quant_lim&quot;)), list(wet_wgt = ~ case_when( basis_determination == &quot;lipid weight&quot; ~ .*(`EXLIP%`/100), # IS THIS HOW EXLIP% VARIABLE WORKS???? basis_determination == &quot;dry weight&quot; ~ .*(100/`DRYWT%`), # IS THIS HOW DRYWT% VARIABLE WORKS???? basis_determination == &quot;wet weight&quot; ~ . )) ) } } ## for sediment data, still need to convert to dry weights if(!matrix_biota){ ## what to do with the dry weights.... message(&quot;STEP 5: converting all congener concentrations in sediment to dry weight&quot;) df_final &lt;- df_final %&gt;% ## if value is not dry weight convert, otherwise keep value ## even though some have units of ug/kg treat the DRYWT% as percentage... mutate_at( vars(c(&quot;value&quot;, &quot;detect_lim&quot;, &quot;quant_lim&quot;)), list(dry_wgt = ~ case_when( basis_determination == &quot;wet weight&quot; ~ .*(`DRYWT%`/100), # IS THIS HOW DRYWT% VARIABLE WORKS???? basis_determination == &quot;dry weight&quot; ~ . )) ) } ## rejoin with meta information ---- ## rejoin with info on country and monitoring program info, qflaugs, etc message(&quot;FINAL STEP: rejoining with meta information\\n&quot;) df_final &lt;- df %&gt;% filter(str_detect(param_group, pattern = contam_param)) %&gt;% select( country, monit_program, monit_purpose, report_institute, monit_year, date_ices, day, month, num_indiv_subsample, bulk_id, !!!syms(grpvars) ) %&gt;% distinct() %&gt;% right_join(df_final, by = grpvars) %&gt;% mutate(qflagged = ifelse(is.na(qflag), FALSE, TRUE)) ## return wrangled data and checks ---- ## list of checks as part of result chks &lt;- list( chk_params, chk_ids, chk_bbio_units, chk_num_bbio_dup, chk_bbio_vars, chk_conc_units, chk_num_conc_dup, chk_conc_dup ) df_final &lt;- filter(df_final, !is.na(value)) if(!all(mutate(group_by(df_final, !!!syms(grpvars)), n = n())$n == 1)){ warning(&quot;NOTE rows of final dataframe are not uniquely identified by grouping variables&quot;) } return(list( df_final = df_final, groupingvars = grpvars, df_conc_wide = df_conc_wide, df_bbio_wide = df_bbio_wide, checks = chks )) } 2.2.3 Wrangle all and Save Apply the Standardization function defined above to all 5 Contaminants datasets and save the cleaned, harmonized data for later analysis. For PCBs in biota data, remove PCB, SCB, SCB7 variables as these are summarized data or depreciated codes; for PCBs in sediments remove PCB and SCB. dir_interm &lt;- here::here(&quot;data&quot;, &quot;CW&quot;, &quot;contaminants&quot;, version_year, &quot;intermediate&quot;) lapply( list( ## for param definitions see //vocab.ices.dk/?ref=37 ## PCB datasets ## remove PCB, SCB, SCB7 - these are summarized data or depreciated codes ## OC-CB variable codes: vocab.ices.dk/?CodeID=26983 list(&quot;pcb_bio&quot;, TRUE, &quot;OC-CB&quot;, c(&quot;PCB&quot;, &quot;SCB&quot;, &quot;SCB7&quot;)), list(&quot;pcb_sed&quot;, FALSE, &quot;OC-CB&quot;, c(&quot;PCB&quot;, &quot;SCB&quot;)), ## Dioxin datasets list(&quot;dioxin_bio&quot;, TRUE, &quot;OC-DX&quot;, NULL), list(&quot;dioxin_sed&quot;, FALSE, &quot;OC-DX&quot;, NULL), ## PFOS dataset list(&quot;pfos_bio&quot;, TRUE, &quot;O-FL&quot;, NULL) ), function(dat){ dat_final &lt;- standardize_con_data(get(dat[[1]]), dat[[2]], dat[[3]], dat[[4]]) assign( x = paste(dat[[1]], &quot;cleaned&quot;, sep = &quot;_&quot;), value = dat_final, envir = .GlobalEnv ) assign( x = paste(dat[[1]], &quot;clean_df&quot;, sep = &quot;_&quot;), value = dat_final[[&quot;df_final&quot;]], envir = .GlobalEnv ) write_csv( dat_final[[&quot;df_final&quot;]], file.path(dir_interm, paste(dat[[1]], &quot;cleaned.csv&quot;, sep = &quot;_&quot;)) ) } ) 2.3 Initial Data Exploration ## to start running code from here, will need to load in cleaned datasets... # dir_interm &lt;- here::here(&quot;data/CW/contaminants/v2019/intermediate&quot;) # lapply(list.files(dir_interm), function(dat){ # dat_final &lt;- read_csv(file.path(dir_interm, dat)) # assign( # x = str_replace(dat, &quot;cleaned.csv&quot;, &quot;clean_df&quot;), # value = dat_final, # envir = .GlobalEnv # ) # }) make_plotdf &lt;- function(x, yrs){ grpvars &lt;- c(&quot;year&quot;, &quot;latitude&quot;, &quot;longitude&quot;, &quot;variable&quot;, &quot;num_distinct_dates&quot;, &quot;species&quot;) valvar &lt;- &quot;value_wet_wgt&quot; if(str_detect(x, &quot;sed&quot;)){ grpvars &lt;- setdiff(grpvars, &quot;species&quot;) valvar &lt;- &quot;value_dry_wgt&quot; } if(str_detect(x, &quot;pfos&quot;)){ valvar &lt;- &quot;value_pfos_muscle_equiv_wet_wgt&quot; } cbind( get(x) %&gt;% filter(!is.na(!!!syms(valvar))) %&gt;% filter(year %in% yrs, longitude &gt; 9) %&gt;% group_by(latitude, longitude, variable) %&gt;% ## number of disinct dates at the location for the variable mutate(num_distinct_dates = n_distinct(date)) %&gt;% group_by(!!!syms(grpvars)) %&gt;% ## mean annual values at the locatioin, by variable summarize( mean_val = ifelse( str_detect(x, &quot;sed&quot;), mean(value_dry_wgt), ifelse( str_detect(x, &quot;pfos&quot;), mean(value_pfos_muscle_equiv_wet_wgt), mean(value_wet_wgt) ) ) ) %&gt;% ungroup(), source = str_to_upper(str_remove(x, &quot;_clean_df&quot;))) } ## apply make_plotdf bringing all datasets together plotdf &lt;- bind_rows( do.call( rbind, lapply( list(&quot;pcb_bio_clean_df&quot;, &quot;dioxin_bio_clean_df&quot;, &quot;pfos_bio_clean_df&quot;), function(x) make_plotdf(x, 2014:2019) )) %&gt;% mutate(matrix = &quot;biota&quot;, indicator = str_remove(source, &quot;_[A-Z].*&quot;)), do.call( rbind, lapply( list(&quot;pcb_sed_clean_df&quot;, &quot;dioxin_sed_clean_df&quot;), function(x) make_plotdf(x, 2014:2019) )) %&gt;% mutate(matrix = &quot;sediment&quot;, indicator = str_remove(source, &quot;_[A-Z].*&quot;)) ) 2.3.2 Spatial Distributions of Measurements {.tabset .tabset-fade .tabset-pills} The maps below show data distribution spatially. Size and color correspond to number of distinct dates measurements were collected for a variable, for the given location within the specified time period (2016 through 2019); larger points with more yellow color indicate greater number of observations while smaller more red points indicate fewer observations. Opacity corresponds to number of years with greater transparency indicating fewer years of data. These faceted plots are created for multiple species; the species selected for visualization are those with the greatest number of measurements recorded across the three indicators. make_map &lt;- function(mapdata){ ## make data spatial using lat/lon columns df &lt;- sf::st_as_sf( x = mapdata, agr = &quot;identity&quot;, coords = c(&quot;longitude&quot;, &quot;latitude&quot;), crs = 4326 ) ## contaminants datasets overlaying basemap speciesmap &lt;- basemap + geom_sf( data = df, aes( size = num_distinct_dates, color = num_distinct_dates), show.legend = FALSE, alpha = 0.5, shape = 19 ) + scale_color_gradient2( low = &quot;red3&quot;, mid = &quot;lightcoral&quot;, high = &quot;lightgoldenrod&quot;, midpoint = 2.5 ) + facet_wrap( c(&quot;indicator&quot;, &quot;variable&quot;), labeller = label_wrap_gen(width = 35, multi_line = FALSE), ncol = 5 ) return(speciesmap) } # for(i in unique(plotdf$indicator)){ # species_obs &lt;- plotdf %&gt;% # filter(matrix == &quot;biota&quot;, indicator == i) %&gt;% # group_by(species) %&gt;% # summarise(n = sum(num_distinct_dates)) %&gt;% # arrange(desc(n)) # print(head(species_obs)) # } Clupea Harengus make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Clupea harengus&quot;))) Zoarces Viviparus make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Zoarces viviparus&quot;))) Perca Fluviatilis make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Perca fluviatilis&quot;))) Platichthys Flesus make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Platichthys flesus&quot;))) Mytilus Edulis make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Mytilus edulis&quot;))) Uria Aalge make_map(filter(plotdf, matrix == &quot;biota&quot;, str_detect(species, &quot;Uria aalge&quot;))) Sediments make_map(filter(plotdf, matrix == &quot;sediment&quot;)) 3. Wrangling, Evaluation, and Gapfilling read_clean_df &lt;- function(filename){ read_csv( file.path(dirname(data_path), &quot;intermediate&quot;, filename), ## ensure column types are read correctly... col_types = cols( bulk_id = col_character(), qflag = col_character(), `LIPIDWT%` = col_number(), `DRYWT%` = col_number(), `EXLIP%` = col_number(), WTMEA = col_number(), WTMIN = col_number(), WTMAX = col_number(), sub_samp_id = col_number(), LNMEA = col_number(), LNMAX = col_number(), LNMIN = col_number(), unit = col_character() ) ) } 3.1 PCB Indicator 3.1.1 Match BHI Regions ## use &#39;read_clean_df&#39; function from above to read cleaned data with correct data types for columns ## use &#39;join_rgns_info&#39; helper function defined in R/spatial.R pcb_bio &lt;- join_rgns_info( read_clean_df(&quot;pcb_bio_cleaned.csv&quot;), latlon_vars = c(&quot;latitude&quot;, &quot;longitude&quot;), rgn_shps_loc = file.path(dirname(dir_B), &quot;Shapefiles&quot;), return_spatial = FALSE, buffer_shp = buffer_sf ) pcb_sed &lt;- join_rgns_info( read_clean_df(&quot;pcb_sed_cleaned.csv&quot;), latlon_vars = c(&quot;latitude&quot;, &quot;longitude&quot;), rgn_shps_loc = file.path(dirname(dir_B), &quot;Shapefiles&quot;), return_spatial = FALSE, buffer_shp = buffer_sf ) 3.1.2 Filter PCBs to ICES6 Set or PCB7 for Sediment The PCBs indicator uses only the ICES6 congeners: CB28, CB52, CB101, CB138, CB153, CB180. Additionally, only herring are used from the biota datasets, as they are fairly equally spatially distributed across the baltic sea, while many other species are predominantly in the south. Checking Outliers/Questionable Measurements {.tabset .tabset-fade .tabset-pills} PCBs in Biota PCBs in Sediment Visualize flagged data in Timeseries Below the data are plotted in congener-subbasin combinations. Colorscale corresponds to number of observations, with lighter blues/greens indicating more observations for the given date-congener-subbasin group, while darker colors indicate fewer observations in the dataset for the given date-congener-subbasin combination. 3.1.3 Evaluate Flagged Data, Station Impact, &amp; Sampling Patterns What do the qflags indicate? Quantification limits, Flags Codes &lt; = less than &gt; = greather than D = reported value is less than the detection limit (detect_lim) Q = reported value is less than the limit of quantification (quant_lim) ~ separates multiple flags Congener-Sums Timeseries by Country {.tabset .tabset-fade .tabset-pills} Defining two approaches to deal with flagged data The function below aggregates the data spreading by variable (so each congner has a column and each date/location/sample is a single row) and summing the congeners rowwise to get date/location/sample specific concentration sums of the specified congners. The function allows for two approaches to handling flagged data: “NoQflag” which removes the flagged observations or “Adjusted” which adjust values. Adjustment of values would ideally use detect_lim/2, however since detect_lim values are not always provided, we apply the transformation to the reported data value. ## timeseries plots, congeners by country plot_cwcon_initial &lt;- function(dataset, col_pal, contam_param = &quot;OC-CB&quot;, matrix = &quot;bio&quot;, cntry_or_basin = &quot;subbasin&quot;){ ## one of OC-CB, OC-DX or O-FL; becomes OC, DX, or FL respectively contam_param &lt;- substr(contam_param, str_length(contam_param)-1, str_length(contam_param)) if(contam_param == &quot;FL&quot;){contam_param &lt;- &quot;PF&quot;} if(contam_param == &quot;DX&quot;){contam_param &lt;- &quot;CD&quot;} cntry_or_basin &lt;- str_to_lower(cntry_or_basin) dat &lt;- dataset %&gt;% rename(subbasin = Subbasin) %&gt;% select(month, Year = year, zone = cntry_or_basin, contains(contam_param)) %&gt;% filter(!is.na(zone), Year &gt; 2000) %&gt;% tidyr::pivot_longer( cols = starts_with(contam_param), names_to = &quot;Congener&quot;, values_to = &quot;value_plot&quot; ) %&gt;% group_by(Congener, month, Year, zone) %&gt;% summarize(Value = mean(value_plot, na.rm = TRUE) %&gt;% round(3)) %&gt;% ungroup() %&gt;% mutate(Date = as.Date(paste(&quot;1&quot;, month, Year, sep = &quot;-&quot;), tryFormats = &quot;%d-%m-%Y&quot;)) ## reorder factor levels of congeners so colors will match across plots for same congeners if(contam_param == &quot;CB&quot;){ if(isTRUE(all.equal(names(select(dataset, starts_with(contam_param))), ices6_congeners))){ dat$Congener &lt;- factor(dat$Congener, levels = ices6_congeners) } if(isTRUE(all.equal(names(select(dataset, starts_with(contam_param))), pcb7sed_congeners))){ dat$Congener &lt;- factor(dat$Congener, levels = c(ices6_congeners, &quot;CB118&quot;)) } dioxinlike_pcbs &lt;- c(&quot;CB118&quot;,&quot;CB156&quot;,&quot;CB105&quot;,&quot;CB169&quot;,&quot;CB167&quot;,&quot;CB77&quot;,&quot;CB157&quot;) if(isTRUE(all.equal(names(select(dataset, starts_with(contam_param))), dioxinlike_pcbs))){ dat$Congener &lt;- factor(dat$Congener, levels = dioxinlike_pcbs) } } if(contam_param == &quot;CD&quot;){ sed_dioxins &lt;- c( &quot;CDD1N&quot;,&quot;CDD4X&quot;,&quot;CDD6P&quot;,&quot;CDD6X&quot;,&quot;CDD9X&quot;,&quot;CDDO&quot;,&quot;CDF2N&quot;,&quot;CDF2T&quot;, &quot;CDF4X&quot;,&quot;CDF6P&quot;,&quot;CDF6X&quot;,&quot;CDF9P&quot;,&quot;CDF9X&quot;,&quot;CDFO&quot;,&quot;TCDD&quot; ) if(matrix == &quot;sed&quot;){ dat$Congener &lt;- factor(dat$Congener, levels = sed_dioxins) } else {dat$Congener &lt;- factor(dat$Congener, levels = c(sed_dioxins, &quot;CDFDN&quot;))} } ## timeseries plots of all congeners by country plot &lt;- ggplot(data = dat, aes(Date, Value, fill = Congener)) + geom_col(position = &quot;stack&quot;, show.legend = FALSE) + scale_x_date( breaks = function(x){seq.Date(from = min(dat$Date), to = max(dat$Date), by = &quot;3 months&quot;)}, date_labels = &quot;%b %Y&quot; ) + scale_fill_manual(values = col_pal) + labs(x = NULL, y = NULL) + theme(axis.text.x = element_text(angle = 45, size = 6)) + facet_wrap(~zone, scales = &quot;free_y&quot;, ncol = 1) return(plot) # return(plotly::ggplotly(plot)) } Visualize Timeseries, Monthly Sums PCB Congeners in Biota ## create color palettes fullpal &lt;- c( RColorBrewer::brewer.pal(8, &quot;Dark2&quot;), RColorBrewer::brewer.pal(9, &quot;Set1&quot;) ) cols &lt;- colorRampPalette(fullpal)(42)[sample(1:42, size = 6)] plot_cwcon_initial(pcb_bio_qflag_adjust, col_pal = cols, contam_param = &quot;OC-CB&quot;, cntry_or_basin = &quot;country&quot;) # plotly::ggplotly(plot_cwcon_initial(pcb_bio_qflag_adjust, col_pal = cols, contam_param = &quot;OC-CB&quot;, cntry_or_basin = &quot;country&quot;)) PCB Congeners in Sediments plot_cwcon_initial(pcb_sed_qflag_adjust, c(cols, &quot;turquoise&quot;), &quot;OC-CB&quot;, &quot;sed&quot;, &quot;country&quot;) Spatial distributions of PCB sampling Locations 3.1.4 Status and Trend Options Most-recent Years in Data Layers for each Approach to Flagged Data lastyr_Adjusted lastyr_NoQflag Subbasin 2014 2014 Aland Sea 2015 2015 Arkona Basin 2016 2014 Bay of Mecklenburg 2018 2018 Bornholm Basin 2018 2018 Bothnian Bay 2018 2018 Bothnian Sea 2018 2018 Eastern Gotland Basin 2018 2018 Gdansk Basin 2016 2014 Great Belt 2018 2018 Gulf of Finland 2018 2018 Gulf of Riga 2014 2014 Kattegat 2016 2014 Kiel Bay 2016 2016 Northern Baltic Proper 2016 2016 The Quark 2008 2008 The Sound 2014 2014 Western Gotland Basin A function to calculate the Indicators The function below takes as inputs: datalayer, years across which data is to be aggregated in status calculation, the biota reference point for the contaminant (health threshold in same units as datalayer values) and the sediment reference point, the trend-calculation approach, and trend lag i.e. the number of years we want to project into the future. Default approach for calculating the trend (scaledObs) is to scale the observations by the matrix-and-contaminant-specific reference point, capping at one, then group by spatial unit (BHI region or Subbasin) and matrix, and regress the scaled values against year; the year coefficient multiplied by trendlag becomes the trend score. Other approaches considered are: calculating trend with zscores of data, or using a mixed-effects model to try to account for different stations. See commented code below for more details. Compare two approaches to deal with flagged data, for BHI regions vs Basin Start with mean ICES6 conc. by date and location (unique observations) Scale observations compared to the relevant contaminant-and-matrix-relevant reference point, capping at one Calculate status as mean of all scaled obs. for past 5 years in either BHI region or basin Compare by-basin and by-BHI region results for status and for trend, assess number of data points contributing 3.1.5 Save PCB contaminants layer and intermediate datasets 3.1.6 Methods discussion Only herring (no other species) used from biota dataset, because herring are most equally spatially spaced across the baltic sea, whereas others are mostly in the south. Status formula, ICES6 PCBs Biota and 7PCBs in Sediment \\(X_{\\mbox{ICES6}} = \\min\\{\\mbox{bio_reference_point/mean_ICES6_region, } 1\\}\\) \\(X_{\\mbox{7sedPCB}} = \\min\\{\\mbox{sed_reference_point/mean_7sedPCB_region, } 1\\}\\) \\(X_{\\mbox{PCB}} = (X_{\\mbox{ICES6}} + X_{\\mbox{7sedPCB}})/2\\) \\(\\mbox{bio_reference_point} = \\mbox{health_threshold} = 75ug/kg\\mbox{ wet weight}\\) \\(\\mbox{sed_reference_point} = \\mbox{health_threshold} = 4.1ug/kg\\mbox{ dry weight}\\) Score scaled between 0 and 1. If value is below 75, score = 1. Conclusions &amp; Decisions regarding Status and Trend Options Including the qflag-adjusted values lowers the mean concentration by date and location Including qflag-adjusted values also provides more observations in the Kattegat, The Quark, and W. Gotland Basin When aggregating by BHI regions, more observations for Regions 1, 11, 26, 35, 36, 39, 41, 42 when including qflagged values Using data including qflag-adjusted (this could lower values), Use 5 year mean ICES6 concentration for status Use the five status years plus another five prior for the regression that factors into trend calculation Trend Considerations Work on mixed effect model for trends? Need to think about the interpretation of the data treatment. (a) If use raw observations, then normalize (zscore data), then fit trend, if get increase or decrease but all values are below the threshold, does it make sense to apply a change in the trend to the status? Would we really think the future status will be lower? (b) If take all raw observations, calculate “status” as done for the mean value, then fit trend, is this more true to the idea that variation below the human health threshold should not affect the trajectory of the future status? Need to think if simple linear regression is okay, or if need to account for site? BHI1.0 discussions with Anna Sobek Indicator choice: We agreed that ICES6 is the best option Decision about use of qflagg-adjusted data: use qflagged data with the adjustement of (congener conc/2) Decision about spatial scale of the data: decide best approach is to calculate for each basin Trend decision: best approach is first convert individual observations to a “status” relative to the human health threshold, then fit linear model by basin for 10 year period. (Tred Check: Does the trend value need to be rescaled to between -1 and 1? Does not exceed now but need to consider if method broadly works?) 3.2 PFOS Indicator 3.2.1 Match BHI Regions Use Lat/Long to Match BHI Regions # use &#39;join_rgns_info&#39; helper function defined in spatial.R pfos &lt;- join_rgns_info( read_clean_df(&quot;pfos_bio_cleaned.csv&quot;), helcomID_col = &quot;HELCOM_ID&quot;, latlon_vars = c(&quot;latitude&quot;, &quot;longitude&quot;), rgn_shps_loc = file.path(dirname(dir_B), &quot;Shapefiles&quot;), return_spatial = FALSE, buffer_shp = buffer_sf ) 3.2.2 Filter Organofluorines Data keeping only PFOS in Clupea harengus Only herring (Clupea harengus) are used from the biota datasets, as they are fairly equally spatially distributed across the baltic sea, while many other species are predominantly in the south. Also, heerring are . In the raw organofluorine dataset, matrix analyzed for most measurements was liver but there were some also where muscle was analyzed. In the initial data cleaning (see bhi-prep/data/CW/contaminants/v2019/con_data.rmd), the concentrations from liver measurements were converted to muscle equivalent using the report: Distribution of PFAS in liver and muscle of herring, perch, cod, eelpout, arctic char, and pike from limnic and marine environments in Sweden. Faxneld et al 2014. 3.2.3 Evaluate Flagged Data &amp; Sampling Patterns Visualize PFOS flagged data in Timeseries PFOS data plotted by subbasin. Colorscale in plot one corresponds to number of observations, with lighter blues/greens indicating more observations for the given date-congener-subbasin group, while darker colors indicate fewer observations in the dataset for the given date-congener-subbasin combination. Plot 2 shows the same information in boxplot format, with data grouped by year. Concentrations Timeseries and Boxplots with Observation Counts Spatial distributions of PFOS sampling Locations, Years 2014-2018 3.2.4 Status and Trend Options Most-recent Years in Data Layers for each Approach to Flagged Data lastyr_Adjusted lastyr_NoQflag Subbasin 2014 2014 Aland Sea 2014 2014 Arkona Basin 2018 2018 Bornholm Basin 2018 2018 Bothnian Bay 2018 2018 Bothnian Sea 2018 2018 Eastern Gotland Basin 2018 2018 Gulf of Finland 2014 2014 Kattegat 2017 2017 Northern Baltic Proper 2016 2016 The Quark 2014 2014 Western Gotland Basin Compare two approaches to deal with flagged data, for BHI regions vs Basin Start with mean concentrations by date and location Scale observations compared to the relevant contaminant-and-matrix-relevant reference point, capping at one Calculate status as mean of all scaled obs. for past 5 years in either BHI region or basin Compare by-basin and by-BHI region results for status and for trend, assess number of data points contributing 3.1.5 Save PFOS contaminants layer and intermediate datasets 3.1.6 Methods discussion Status formula, ICES6 PCBs Biota and 7PCBs in Sediment Conclusions &amp; Decisions regarding Status and Trend Options Trend Considerations 3.3 Dioxin Indicator 3.3.1 Match BHI Regions Dioxins and dioxin-like PCBs datasets are manipulated as separate objects for the next steps, combined only in the last code chunk before section 3.3.3 ‘Status and Trend Options’. Sediment and biota datasets for each dioxins and dioxin-like PCBs are joined before spatial plotting. ## use &#39;join_rgns_info&#39; helper function defined in spatial.R dioxin_bio &lt;- join_rgns_info( read_clean_df(&quot;dioxin_bio_cleaned.csv&quot;), latlon_vars = c(&quot;latitude&quot;, &quot;longitude&quot;), rgn_shps_loc = file.path(dirname(dir_B), &quot;Shapefiles&quot;), return_spatial = FALSE, buffer_shp = buffer_sf ) dioxin_sed &lt;- join_rgns_info( read_clean_df(&quot;dioxin_sed_cleaned.csv&quot;), latlon_vars = c(&quot;latitude&quot;, &quot;longitude&quot;), rgn_shps_loc = file.path(dirname(dir_B), &quot;Shapefiles&quot;), return_spatial = FALSE, buffer_shp = buffer_sf ) 3.3.2 Filter Dioxin-like PCBs to join with Dioxins dataset, and Convert all to Toxic Equivalents To convert dioxin and dioxin-like PCB congener concentrations to toxic equivalents we use the IPCS Reference Table, taken from The 2005 World Health Organization Re-evaluation of Human and Mammalian Toxic Equivalency Factors for Dioxins and Dioxin-like Compounds (Van den Berg et al, 2005). Filter PCB to keep only dioxin-like PCBs, convert units, and convert to TEQ Use TEF conversion factor to convert Dioxin concentrations to TEQ Checking Outliers/Questionable Measurements {.tabset .tabset-fade .tabset-pills} Dioxin-like PCBs in Biota Dioxin-like PCBs in Sediment Dioxins in Biota 3.3.4 Status and Trend Options Subbasin lastyr_Adjusted lastyr_NoQflag Aland Sea 2017 2017 Arkona Basin 2017 2017 Bay of Mecklenburg 2008 2008 Bornholm Basin 2017 2017 Bothnian Bay 2018 2018 Bothnian Sea 2018 2018 Eastern Gotland Basin 2016 2016 Great Belt 2015 2015 Gulf of Finland 2018 2018 Gulf of Riga 2018 Kattegat 2017 2017 Kiel Bay 2011 2011 Northern Baltic Proper 2017 2017 The Quark 2017 2017 The Sound 2015 2015 Western Gotland Basin 2017 2017 Compare two approaches to deal with flagged data, for BHI regions vs Basin Start with total TEQs: congeners summed per sample, means by date and location, dioxin and dioxin-like PCB summes added together per unique date and location Take mean of all unique obs. for latest 5 years in either BHI region or basin Compare by-basin and by-BHI region results for status and for trend, assess number of data points contributing 3.3.5 Save Dioxin contaminants layer and intermediate datasets 3.3.6 Methods discussion Status formula \\(X_{dioxinTEQ} = \\min\\{1, \\mbox{ teq threshold}/\\mbox{mean dioxin-like pcb teq value}\\}\\) Conclusions &amp; Decisions regarding Status and Trend Options Trend Considerations 3.4 Concerning Substances Indicator This indicator is a new addition since the BHI1.0, conceptualized as a more comprehensive way to account for the fact that many concerning, hazardous substances are not currently monitored in the Baltic Sea. In the earlier assessment, a penalty factor of 0.1 was applied to the entire Baltic to reduce the contaminant subgoal scores so they better reflected this concerning situation. This method uses a list compiled by ECHA of concerning substances, and involves cross-referencing with those monitored substances in the ICES contaminants databases for biota and for sediments. Those on the list which are monitored, are assessed for spatial coverage of monitoring; substances on the list may be monitored somewheree in the Baltic Sea, but only in some basins or for some countries. The final indicator score is the percentage of substances on the list that are monitored in the given region. 3.4.1 Regional monitoring of Concerning Substances Of the concerning substances which are monitored, some are monitored only in some BHI regions and/or years. The code below is used in assessing this spatial coverage. ## read in master table of emerging contaminant ## this was compiled by Andrea and checked by Anna Sobeck for correctness/completeness data_loc &lt;- file.path(dir_B, &quot;Goals&quot;, &quot;CW&quot;, &quot;CON&quot;) subst_of_concern &lt;- read_csv(file.path(data_loc, &quot;concerning_substances_lookup.csv&quot;)) ## spatial regions table for joining joindf &lt;- BHI_rgns_shp %&gt;% st_drop_geometry() %&gt;% select(-Area_km2) %&gt;% mutate( Subbasin = as.character(Subbasin), HELCOM_ID = as.character(HELCOM_ID), rgn_nam = as.character(rgn_nam), rgn_key = as.character(rgn_key) ) %&gt;% mutate(year = list(1990:2020)) %&gt;% tidyr::unnest(year) ## loop through substances and determine which regions they are/not monitored in rgn_monitor_bio_allsubst &lt;- joindf rgn_monitor_sed_allsubst &lt;- joindf plotlistbio &lt;- list() plotlistsed &lt;- list() for(nm in unique(filter(subst_of_concern, ICES_monitored)$filename)){ bio_fp &lt;- file.path( data_loc, &quot;ContaminantsBiota_ConcerningSubstances&quot;, sprintf(&quot;ContaminantsBiota_%s.csv&quot;, nm) ) sed_fp &lt;- file.path( data_loc, &quot;ContaminantsSediment_ConcerningSubstances&quot;, sprintf(&quot;ContaminantsSediment_%s.csv&quot;, nm) ) if(file.exists(bio_fp)){ regionalmonitoringbio &lt;- get_spatial_monitor_info( bio_fp, matrix = &quot;bio&quot;, bhi_join_tab = joindf ) colnames(regionalmonitoringbio$monitored) &lt;- names(regionalmonitoringbio$monitored) %&gt;% str_replace(&quot;ICES_monitored&quot;, paste(nm, &quot;monitored&quot;, sep = &quot;_&quot;)) rgn_monitor_bio_allsubst &lt;- rgn_monitor_bio_allsubst %&gt;% left_join(regionalmonitoringbio$monitored) plotlistbio[[nm]] &lt;- regionalmonitoringbio$obscounts } if(file.exists(sed_fp)){ regionalmonitoringsed &lt;- get_spatial_monitor_info( sed_fp, matrix = &quot;sed&quot;, bhi_join_tab = joindf ) colnames(regionalmonitoringsed$monitored) &lt;- names(regionalmonitoringsed$monitored) %&gt;% str_replace(&quot;ICES_monitored&quot;, paste(nm, &quot;monitored&quot;, sep = &quot;_&quot;)) rgn_monitor_sed_allsubst &lt;- rgn_monitor_sed_allsubst %&gt;% left_join(regionalmonitoringsed$monitored) plotlistsed[[nm]] &lt;- regionalmonitoringsed$obscounts } } ## for the remaining substances of concern (not monitored at all) create columns for(s in unique(filter(subst_of_concern, !ICES_monitored)$filename)){ ## add to bio dataset dfbio &lt;- mutate(rgn_monitor_bio_allsubst, addcolumn = FALSE) colnames(dfbio) &lt;- c(names(rgn_monitor_bio_allsubst), paste0(s, &quot;_monitored&quot;)) rgn_monitor_bio_allsubst &lt;- dfbio ## add to sed dataset dfsed &lt;- mutate(rgn_monitor_sed_allsubst, addcolumn = FALSE) colnames(dfsed) &lt;- c(names(rgn_monitor_sed_allsubst), paste0(s, &quot;_monitored&quot;)) rgn_monitor_sed_allsubst &lt;- dfsed } ## join and spread so can easily sum num. substances monitored rgn_monitor_allsubst &lt;- full_join( rgn_monitor_bio_allsubst %&gt;% tidyr::pivot_longer( cols = ends_with(&quot;_monitored&quot;), names_to = &quot;substance&quot;, values_to = &quot;bio_monitored&quot; ), rgn_monitor_sed_allsubst %&gt;% tidyr::pivot_longer( cols = ends_with(&quot;_monitored&quot;), names_to = &quot;substance&quot;, values_to = &quot;sed_monitored&quot; ) ) rgn_monitor_allsubst &lt;- rgn_monitor_allsubst %&gt;% mutate(monitored = bio_monitored|sed_monitored) %&gt;% mutate(monitored = ifelse(is.na(monitored), FALSE, monitored)) %&gt;% select(-bio_monitored, -sed_monitored) %&gt;% mutate(substance = str_remove(substance, &quot;_monitored&quot;)) # gridExtra::grid.arrange(grobs = plotlistbio, nrow = length(plotlistbio)) # gridExtra::grid.arrange(grobs = plotlistbio, nrow = length(plotlistsed)) 3.4.2 Save concerning substances layer and intermediate datasets The data layer for the concerning substances indicator contains true/false records per BHI region per year for each of the 35 distinct substances on the European Chemical Agency Candidate List of substances of very high concern for Authorisation. 4. Visualizing Contaminants Data Layers 4.1 Contaminants data layers Maps &amp; Subbasin Trends Maps on the left show each indicator’s status individually, and the larger map on the right shows the combined status score with PCB, PFOS, and Dioxin indicators averaged and penalized by the Concerning Substances indicator (monitored proportion). 5. Considerations for BHI3.0 From the ICES Organofluorines dataset, include PFAS in addition to PFOS. To include PFAS, a suitable reference point will need to be found. 6. References Faxneld et al. 2014a Biological effects and environmental contaminants in herring and Baltic Sea top predators Faxneld et al. 2014b Distribution of PFAS in liver and muscle of herring, perch, cod, eelpout, arctic char, and pike from limnic and marine environments in Sweden. Bignert, A., Nyberg, E., Sundqvist, K.L., Wiberg, K., 2007. Spatial variation in concentrations and patterns of the PCDD/F and dioxin-like PCB content in herring from the northern Baltic Sea. J. Environ. Monit. 9, 550–556. Working Group on the State of the Environment and Nature Conservation Commission Regulation (EU) No. 1259/2011 of 2 December 2011. Amending Regulation (EC) No 1881/2006 as regards maximum levels for dioxins, dioxin-like PCBs and non dioxin-like PCBs in foodstuffs. Van den Berg et al, World Health Organization 2005. The 2005 World Health Organization Re-evaluation of Human and Mammalian Toxic Equivalency Factors for Dioxins and Dioxin-like Compounds. HELCOM PFOS core indicator document Norwegian environment agency, PCBs and Dioxins indicator in sediment Norwegian Environmental quality classification of water bodies "],
["wild-caught-fisheries-food-provision-subgoal.html", "Chapter 2 Wild-Caught Fisheries - Food Provision Subgoal 1. Background 2. Data 3. Prep: Wrangling &amp; Derivations, Checks/Evaluation, Gapfilling 4. Visualizing Data Layers 5. Considerations for BHI3.0 6. References", " Chapter 2 Wild-Caught Fisheries - Food Provision Subgoal 1. Background 1.1 Goal Description The Fisheries sub-goal of Food Provision describes the ability to maximize the sustainable yield of wild-caught seafood for human consumption. For the BHI cod and herring stocks in the Baltic Sea were included as wild-caught fisheries. 1.2 Model &amp; Data The data used for this goal are cod and herring spawning biomass (SSB) and fishing mortality (F) data. The current status is calculated as a function of the ratio between the single species current biomass at sea (B) and the reference biomass at maximum sustainable yield (BMSY), as well as the ratio between the single species current fishing mortality (F) and the fishing mortality at maximum sustainable yield (FMSY). These ratios (B/Bmsy and F/Fmsy) are converted to scores between 0 and 1 using as one component this general relationship. This piecewise equation simply converts the F/FMSY value to an F’ score that will fall between 0-1 (this function applies a penalty when B/BMSY scores indicate good/underfishing but F/FMSY scores indicate high fisheries related mortality). Cod and herring data can be found here. Search for cod or herring, then specify the ecoregion as Baltic Sea and search for the most current assessment. 1.3 Reference points The reference point used for the computation are based on the MSY principle and are described as a functional relationship. MSY means the highest theoretical equilibrium yield that can be continuously taken on average from a stock under existing average environmental conditions without significantly affecting the reproduction process (European Union 2013, World Ocean Review 2013). 1.4 Other information External advisors/goalkeepers are Christian Möllmann &amp; Stefan Neuenfeldt 2. Data This prep document is used to generate and explore the following data layers: fis_bbmsy_bhi2019.csv fis_ffmsy_bhi2019.csv fis_landings_bhi2019.csv fis_cod_bbmsy_bhi2019.csv fis_cod_ffmsy_bhi2019.csv fis_cod_landings_bhi2019.csv np_bbmsy_bhi2019.csv np_ffmsy_bhi2019.csv np_landings_bhi2019.csv These are saved to the layers/v2019 folder. Intermediate datasets saved to data/FIS/v2019/intermediate include: fis_full_merged_dataset.csv andfis_cod_fultonsK.csv. All these are derived from or informed by the following raw datasets. 2.1 Datasets with Sources 2.1.1 Landings (for F/FMSY) and SSB (for B/BMSY) Data Cod in subdivisions 22-24, western Baltic stock Table 2.1: Source: ICES database Downloaded 2019-10-07 by Andrea De Cervo Option Specification Species: Gadus morhua EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: cod.27.22-24 Assessment Key: 10446 Cod in subdivisions 24-32, eastern Baltic stock Table 2.2: Source: ICES database Downloaded 2019-10-07 by Andrea De Cervo Option Specification Species: Gadus morhua EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: cod.27.24-32 Assessment Key: 12941 Herring in subdivisions 20-24 -Skagerrak, Kattegat and western Batic- Table 2.3: Source: ICES database Downloaded 2019-10-07 by Andrea De Cervo Option Specification Species: Clupea harengus EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: her.27.20-24 Assessment Key: 12592 Herring in subdivisions 25-29,32 -central Baltic Sea (excluding Gulf of Riga)- Table 2.4: Source: ICES database Downloaded 2019-10-07 by Andrea De Cervo Option Specification Species: Clupea harengus EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: her.27.25-2932 Assessment Key: 10408 Herring in subdivision 28.1 (Gulf of Riga) Table 2.5: Source: ICES database Downloaded 2019-10-08 by Andrea De Cervo Option Specification Species: Clupea harengus EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: her.27.28 Assessment Key: 10404 Herring in subdivisions 30-31 (Gulf of Bothnia) Table 2.6: Source: ICES database Downloaded 2019-10-08 by Andrea De Cervo Option Specification Species: Clupea harengus EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: her.27.3031 Assessment Key: 12738 Sprat in subdivisions 22-32 (Baltic Sea) Table 2.7: Source: ICES database Downloaded 2019-10-08 by Andrea De Cervo Option Specification Species: Sprattus sprattus EcoRegion (Fishstock): Baltic Sea Assessment year: 2019 FishStock: spr.27.22-32 Assessment Key: 12942 2.1.2 Cod Trawl Survey Baltic International Trawl Survey (BITS) Cod Length and Weight - ICES subdivisions 21-29 Table 2.8: Source: ICES DATRAS database Downloaded 2019-10-22 by Eleanore Campbell Option Specification Data Product: SMALK Survey: BITS (Baltic International Trawl Survey) Quarters: 4 Years: All Species: All species -&gt; Gadus morhua Baltic International Trawl Survey (BITS) Cod CPUE - ICES subdivisions 21-29 Table 2.9: Source: ICES DATRAS database Downloaded 2019-11-07 by Eleanore Campbell Option Specification Data Product: CPUE per length per haul per hour Survey: BITS (Baltic International Trawl Survey) Quarters: All Years: All Ships: All Gear: All Areas: All Species: Standard species -&gt; Gadus morhua 2.1.3 FMSY and BMSY Reference Points Cod (Gadus morhua) in subdivisions 22–24, western Baltic stock (western Baltic Sea) Reference points: BMSY: 21 876 ; FMSY (Ftotal 2020): 0.26 Cod (Gadus morhua) in subdivisions 24–32, eastern Baltic stock (eastern Baltic Sea) Reference points: BMSY (Bpa): 108 035 ; FMSY: 0.3 Herring (Clupea harengus) in Subdivisions 20-24 (Skagerrak, Kattegat and western Baltic) Reference points: BMSY 150 000 ; FMSY 0.31 Herring (Clupea harengus) in Subdivisions 25-29,32 (excluding Gulf of Riga) Reference points: BMSY 600 000 ; FMSY 0.22 Herring (Clupea harengus) in Subdivision 28.1 (Gulf of Riga) Reference points: BMSY 60 000 ; FMSY 0.32 Herring (Clupea harengus) in Subdivisions 30 and 31 (Gulf of Bothnia) Reference points: BMSY 140 998 ; FMSY 0.15 Sprat (Sprattus sprattus) in Subdivisions 22-32 (Baltic Sea) Reference points: BMSY 570 000 ; FMSY 0.26 2.2 Centralization &amp; Normalization Each assessed stock has its own raw datafile. Cod and herring data are saved under Goals/FP/FIS and sprat data are saved in the Goals/NP folder. The MSY values (FMSY and BMSY for each assessed stock) are taken from the ICES advice reports, linked in the standardgraphs.ices.dk aspx pages. No table is saved with these values- they are entered directly into a dataframe in the code below. ## root location of the raw data dir_rawdata &lt;- file.path(dir_B, &quot;Goals&quot;, &quot;FP&quot;, &quot;FIS&quot;) # list.files(dir_rawdata) ## Fisheries data from ICES ## if csvs are saved w/ semicolons: # source(file.path(here::here(), &quot;R&quot;, &quot;semicolon_to_comma.R&quot;)) # lapply( # list(&quot;cod_SDs22_24&quot;, &quot;cod_SDs24_32&quot;, # &quot;herring_SD_28.1&quot;, &quot;herring_SDs20_24&quot;, # &quot;herring_SDs25_29_32&quot;, &quot;herring_SDs30_31&quot;), # function(x){ # fp &lt;- file.path(dir_rawdata, x, paste0(x, &quot;_reformat.csv&quot;)) # semicolon_to_comma(fp, remove_na_cols = TRUE, overwrite = TRUE) # } # ) # semicolon_to_comma(file.path(dir_B,&quot;Goals&quot;,&quot;NP&quot;,&quot;sprat_SDs22_32&quot;,&quot;sprat_SDs22_32_reformat.csv&quot;), TRUE, TRUE) ## cod data cod1raw &lt;- read_csv(file.path(dir_rawdata, &quot;cod_SDs22_24&quot;, &quot;cod_SDs22_24_reformat.csv&quot;)) cod2raw &lt;- read_csv(file.path(dir_rawdata, &quot;cod_SDs24_32&quot;, &quot;cod_SDs24_32_reformat.csv&quot;)) ## herring data herring1raw &lt;- read_csv(file.path(dir_rawdata, &quot;herring_SD_28.1&quot;, &quot;herring_SD_28.1_reformat.csv&quot;)) herring2raw &lt;- read_csv(file.path(dir_rawdata, &quot;herring_SDs20_24&quot;, &quot;herring_SDs20_24_reformat.csv&quot;)) herring3raw &lt;- read_csv(file.path(dir_rawdata, &quot;herring_SDs25_29_32&quot;, &quot;herring_SDs25_29_32_reformat.csv&quot;)) herring4raw &lt;- read_csv(file.path(dir_rawdata, &quot;herring_SDs30_31&quot;, &quot;herring_SDs30_31_reformat.csv&quot;)) ## sprat data sprat1raw &lt;- read_csv(file.path(dir_B, &quot;Goals&quot;, &quot;NP&quot;, &quot;sprat_SDs22_32&quot;, &quot;sprat_SDs22_32_reformat.csv&quot;)) ## make MSY values table ## these values are obtained from ICES reports, see data/FIS/fis_np_data.rmd for more details msy_data &lt;- t(data.frame( c(&quot;cod&quot;, &quot;22-24&quot;, &quot;cod_SDs22_24&quot;, 21876, 0.26), c(&quot;cod&quot;, &quot;24-32&quot;, &quot;cod_SDs24_32&quot;, 108035, 0.3), c(&quot;herring&quot;, &quot;28.1&quot;, &quot;herring_SD_28.1&quot;, 60000, 0.32), c(&quot;herring&quot;, &quot;20-24&quot;, &quot;herring_SDs20_24&quot;, 150000, 0.31), c(&quot;herring&quot;, &quot;25-29,32&quot;, &quot;herring_SDs25_29_32&quot;, 600000, 0.22), c(&quot;herring&quot;, &quot;30-31&quot;, &quot;herring_SDs30_31&quot;, 140998, 0.15), c(&quot;sprat&quot;, &quot;22-32&quot;, &quot;sprat_SDs22_32&quot;, 570000, 0.26) )) ## for testing effect of using 2013 values... # msy_2013_data &lt;- t(data.frame( # c(&quot;cod&quot;, &quot;22-24&quot;, &quot;cod_SDs22_24&quot;, 36400, 0.26), # c(&quot;cod&quot;, &quot;24-32&quot;, &quot;cod_SDs24_32&quot;, 88200, 0.46), # c(&quot;herring&quot;, &quot;28.1&quot;, &quot;herring_SD_28.1&quot;, 60000, 0.35), # c(&quot;herring&quot;, &quot;20-24&quot;, &quot;herring_SDs20_24&quot;, 110000, 0.28), # c(&quot;herring&quot;, &quot;25-29,32&quot;, &quot;herring_SDs25_29_32&quot;, 600000, 0.26), # c(&quot;herring&quot;, &quot;30-31&quot;, &quot;herring_SDs30_31&quot;, 316000, 0.15), # c(&quot;sprat&quot;, &quot;22-32&quot;, &quot;sprat_SDs22_32&quot;, 570000, 0.29) # )) # msy_data &lt;- msy_2013_data colnames(msy_data) &lt;- c(&quot;species&quot;, &quot;SDs&quot;, &quot;stockname&quot;, &quot;BMSY&quot;, &quot;FMSY&quot;) rownames(msy_data) &lt;- NULL msy_data &lt;- as_tibble(msy_data) 2.2.0 Merge datasets and calculate F/FMSY and B/BMSY ratios combined_rawdata &lt;- rbind( ## cod cod1raw %&gt;% dplyr::mutate(catch_tonnes = ifelse( !is.na(discards_tonnes), landings_tonnes + discards_tonnes, landings_tonnes )) %&gt;% dplyr::select( year, ssb, fis_mort = fishing_mortality_age3_5, catch = catch_tonnes # landings = landings_tonnes ) %&gt;% mutate(stockname = &quot;cod_SDs22_24&quot;), cod2raw %&gt;% dplyr::mutate(catch_tonnes = ifelse( !is.na(discards_tonnes), landings_tonnes + discards_tonnes, landings_tonnes )) %&gt;% dplyr::select( year, ssb, fis_mort = fishing_mortality_age4_6, catch = catch_tonnes # landings = landings_tonnes ) %&gt;% mutate(stockname = &quot;cod_SDs24_32&quot;), ## herring herring1raw %&gt;% dplyr::select( year, ssb = ssb_tonnes, fis_mort = `F`, catch = catches_tonnes # no data on discards, only catch... ) %&gt;% mutate(stockname = &quot;herring_SD_28.1&quot;), herring2raw %&gt;% dplyr::select( year, ssb = ssb_tonnes, fis_mort = F_age3_6, catch = catches_tonnes ) %&gt;% mutate(stockname = &quot;herring_SDs20_24&quot;), herring3raw %&gt;% dplyr::select( year, ssb = ssb_tonnes, fis_mort = F_age3_6, catch = catches_tonnes ) %&gt;% mutate(stockname = &quot;herring_SDs25_29_32&quot;), herring4raw %&gt;% dplyr::select( year, ssb = ssb, fis_mort = F_age3_7, catch = catches_tonnes ) %&gt;% mutate(stockname = &quot;herring_SDs30_31&quot;), ## sprat sprat1raw %&gt;% dplyr::select( year, ssb = ssb_tonnes, fis_mort = F_age3_5, catch = catches_tonnes ) %&gt;% mutate(stockname = &quot;sprat_SDs22_32&quot;)) %&gt;% ## join with msy data filter(!is.na(year)) %&gt;% left_join(msy_data, by = c(&quot;stockname&quot;)) %&gt;% mutate(bbmsy = ssb/as.numeric(BMSY), ffmsy = fis_mort/as.numeric(FMSY)) %&gt;% arrange(species, stockname, year) 2.2.1 Standardize Units: Match BHI Regions to ICES Subdivisions Map of ICES regions. The map below shows the overlap between ICES subdivisions and the BHI regions: source(here::here(&quot;R&quot;, &quot;spatial.R&quot;)) regions_shape() # loads spatial features objects ## ICES shapefile has crs EPSG:3035 ## https://spatialreference.org/ref/epsg/etrs89-etrs-laea/ ## transform to match BHI crs of EPSG:4326, and simplify ices_transform &lt;- rmapshaper::ms_simplify(input = ICES_rgns_shp) %&gt;% sf::st_as_sf() %&gt;% sf::st_transform(crs = 4326) bhi_rgns_simple &lt;- rmapshaper::ms_simplify(input = BHI_rgns_shp) %&gt;% sf::st_as_sf() # also simplify BHI shp for plotting map_bhi_ices &lt;- ggplot2::ggplot() + ## baltic countries borders geom_sf( data = rnaturalearth::ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) %&gt;% st_crop(xmin = 0, xmax = 40, ymin = 53, ymax = 67), fill = &quot;ivory&quot;, size = 0.1 ) + ## ICES areas geom_sf( data = ices_transform, aes(fill = ICES_area), color = NA, alpha = 0.5 ) + scale_fill_manual(values = colorRampPalette(RColorBrewer::brewer.pal(9, &quot;Set3&quot;))(14)) + # scale_fill_manual(values = as.vector(pals::kelly(n = 14))) + # library(pals) # scale_fill_manual(values = colorRampPalette(beyonce_palette(127))(14)) + # library(beyonce) labs(fill = &quot;ICES Subdivisions&quot;, x = NULL, y = NULL) + ## BHI regions with ID numbers geom_sf(data = bhi_rgns_simple, fill = NA, size = 0.15, color = &quot;grey40&quot;) + scale_x_continuous(limit = c(5, 37)) + scale_y_continuous(limit = c(53.5, 66)) + theme( panel.background = element_rect(fill = &quot;#F8FBFC&quot;, color = &quot;#E2EEF3&quot;), legend.position = c(0.9, 0.6) ) map_bhi_ices + geom_sf_text(data = bhi_rgns_simple, aes(label = BHI_ID)) A lookup table derived from the overlap between ICES subdivisions and BHI regions as shown in the map above, is used in the code below to match BHI region IDs to the raw dataset: ## based on &#39;prep/FIS/raw/DataOrganization.R&#39; by Melanie Frazier March 16 2016, in bhi-1.0-archive ## table for matching ICES to BHI regions regions &lt;- read_csv( here::here(&quot;supplement&quot;, &quot;lookup_tabs&quot;, &quot;ices_to_bhi_lookup.csv&quot;), col_types = cols()) %&gt;% mutate(ices_numeric = ifelse(ices_numeric == 3, 21, ices_numeric)) # 3a.21 overlaps BHI rgn 1 &amp; 2 ## convert ICES stock assessments to BHI regions combined_w_rgns &lt;- combined_rawdata %&gt;% ## expand ices subdivisions categories to one row per subdiv rowwise() %&gt;% mutate( ## check unique(combined_rawdata$SDs) to make sure this string parsing will work sd_from = as.numeric(str_split(SDs, &quot;-|,&quot;)[[1]][1]), sd_to = as.numeric(str_split(SDs, &quot;-|,&quot;)[[1]][2]), sd_extra = as.numeric(str_split(SDs, &quot;-|,&quot;)[[1]][3]) ) %&gt;% mutate( sd_to = ifelse(is.na(sd_to), sd_from, sd_to), sd_extra = ifelse(is.na(sd_extra), sd_from, sd_extra), incl28.2 = sd_from &lt;= 28 &amp; sd_to &gt;= 28, incl28.1 = sd_from &lt;= 28 &amp; sd_to &gt;= 28 &amp; species != &quot;herring&quot; ) %&gt;% ## ICES regions 28.1 for Riga and 28.2 elsewhere but no 28 mutate(SDs = list( unique( c(sd_from:sd_to, sd_extra)[c(sd_from:sd_to, sd_extra)!=28] %&gt;% c(ifelse(incl28.2, 28.2, sd_from)) %&gt;% c(ifelse(incl28.1, 28.1, sd_from)) ) )) %&gt;% tidyr::unnest(ices_subdiv = SDs) %&gt;% ## NOTE: ## using catches instead of landings, because herring landings were not reported, just catch ## but i dont want to go back through code and change everything to from &#39;landings&#39; to &#39;catch&#39; dplyr::select(year, species, stockname, ssb, BMSY, bbmsy, fis_mort, FMSY, ffmsy, landings = catch, ices_subdiv) %&gt;% filter(ices_subdiv != 20) %&gt;% # filter because no BHI region assigned to SD 20 and will cause NA means... ## add BHI regions info using ices_to_bhi_lookup left_join(dplyr::select(regions, region_id, ices_numeric, area_km2), by = c(&quot;ices_subdiv&quot; = &quot;ices_numeric&quot;)) ## ICES subdivs 20 and 21 are North Sea and left out of BHI1.0, but herring in 3a.21 for rgn 1 &amp; 2 # combined_w_rgns &lt;- combined_w_rgns %&gt;% filter(!ices_subdiv %in% c(20, 21)) surveyBITS_cod &lt;- read_csv(file.path(dir_rawdata, &quot;SMALK_2019-10-22_16_34_01&quot;, &quot;SMALK_2019-10-22_16_34_01.csv&quot;)) # unique(surveyBITS_cod$Country) # no data for Finland, or really any areas north of North Baltic Proper q4_fultonsK &lt;- surveyBITS_cod %&gt;% mutate(length_cm = LngtClass/10) %&gt;% dplyr::select(year = Year, ices_subdiv = Area, eez = Country, length_cm, wgt_gram = IndWgt) %&gt;% mutate( ## revise country EEZ codes to be consistent with codes used elsewhere by BHI eez = ifelse(eez == &quot;GFR&quot;, &quot;DEU&quot;, ifelse(eez == &quot;DEN&quot;, &quot;DNK&quot;, ifelse(eez == &quot;LAT&quot;, &quot;LVA&quot;, eez))), ## calculate fultons K and assign length classes fultonsK = wgt_gram/(length_cm^3)*100, length_group = floor(length_cm/10) ) %&gt;% filter(!is.na(fultonsK), fultonsK &lt; 2) %&gt;% ## per Casini et al exclude lengths &lt; 10cm and ≥60cm-- not enough data: filter(length_group %in% 1:5) %&gt;% mutate( length_group = ifelse( length_group == 1, &quot;10-20cm&quot;, ifelse( length_group == 2, &quot;20-30cm&quot;, ifelse( length_group == 3, &quot;30-40cm&quot;, &quot;40-60cm&quot; ) ) ) ) %&gt;% ## join BHI regions ## area 28 includes both 28.2 and gulf of Riga 28.1 ## http://www.ices.dk/marine-data/Documents/DATRAS/Survey_Maps_Datras.pdf mutate(ices_subdiv = ifelse(ices_subdiv == 28, list(28.1, 28.2), ices_subdiv)) %&gt;% tidyr::unnest(ices_subdiv = ices_subdiv) %&gt;% right_join( regions %&gt;% dplyr::select(region_id, eez, ices_subdiv = ices_numeric) %&gt;% filter(ices_subdiv %in% c(unique(surveyBITS_cod$Area), 28.1, 28.2)), by = c(&quot;ices_subdiv&quot;, &quot;eez&quot;) ) # filter(q4_fultonsK, is.na(fultonsK)) # NA check q4_fultonsK &lt;- filter(q4_fultonsK, !is.na(fultonsK)) ## will give BHI region 1 have same penalty as 2, BHI 5 same as 6, and BHI 29 same as 26 ## as these regions are small, close, and/or share overlapping ICES areas; see ICES vs BHI regions map above No cod in Northern part of the Baltic Sea! Filter combined fisheries dataset to reflect this. cpue_sf &lt;- read_csv(file.path( dir_rawdata, &quot;CPUE_per_length_per_haul_per_hour_2019-11-07_13_36_17&quot;, &quot;CPUE_per_length_per_haul_per_hour_2019-11-07_13_36_17.csv&quot;)) %&gt;% dplyr::select(Year, DateTime, Ship, Gear, ShootLat, ShootLong, rateCPUE = CPUE_number_per_hour) %&gt;% filter(Year &gt;= 2008) %&gt;% distinct() %&gt;% sf::st_as_sf(coords = c(&quot;ShootLong&quot;, &quot;ShootLat&quot;), crs = 4326) map_bhi_ices + geom_sf(aes(size = rateCPUE), color = &quot;royalblue3&quot;, alpha = 0.02, shape = 16, data = cpue_sf) + labs(size = &quot;Number/Hour&quot;, x = NULL, y = NULL) + guides(fill = FALSE) + theme(legend.position = c(0.15, 0.85)) combined_w_rgns &lt;- combined_w_rgns %&gt;% filter(!(species == &quot;cod&quot; &amp; region_id %in% 27:42)) 2.2.2 Save Datasets ## full merged dataset with MSY and raw data, as well as calculated ratios ## this will be used for the shiny app among other things! write_csv( combined_w_rgns %&gt;% rename(catch = landings), here::here(&quot;data&quot;, &quot;FIS&quot;, version_year, &quot;intermediate&quot;, &quot;fis_full_merged_dataset.csv&quot;) ) ## full merged dataset with MSY and raw data, as well as calculated ratios ## this will be used for the shiny app among other things! write_csv( q4_fultonsK, file.path(here::here(), &quot;data&quot;, &quot;FIS&quot;, version_year, &quot;intermediate&quot;, &quot;fis_cod_fultonsK.csv&quot;) ) 3. Prep: Wrangling &amp; Derivations, Checks/Evaluation, Gapfilling 3.1 Reorganizing/wrangling This section prepares data layers for FIS and NP at the same time, separating the fish stocks for each: FIS stocks: cod_22-24, cod_25-32, her_28.1, her_20-24, her_25-29,32, her_30-31 NP stocks: spr_22-32 3.1.1 Wrangle and save layers for FIS and NP Goals The F/FMSY, B/BMSY, and landings data are the ICES stock assessment area values, expanded to have all years rows per BHI region within the stock assessment area, and row-bound to include all stocks in one table. 3.2 Evaluate data &amp; sampling patterns 3.2.1 Comparing with previous BHI Assessment The code below loads FIS layers from current and prior BHI assessments so the raw metrics can be compared before scores are calculated– an early check which can help catch data quality issues, and helpful to suss out how changes in original data might be reflected in final goal scores. This involves matching current and prior ICES stock assessment areas, joining the datasets, and plotting values of one BHI version against the other, per metric and stock. These plots can be used to e.g. identify outliers. Values for which the ICES areas changed are highlighted so as to effects of this can be visually inspected. 3.2.2 Proportions of total catch over time Of all the fisheries landings that occurred in a given area and year, what proportion is made up by each stock? How have these proportions changed over time? Note: different stocks are assessed in different groupings of ICES areas/subdivisions and do not neatly overlap. Without more information (regardless of how catches may in reality be spatially distributed across the assessment areas and BHI regions), the partitioning of catches by BHI regions assumed uniform catch rate over the area, and thus regional:total catch fraction was assumed to be the same as rgn area:total stock area fraction. 3.2.3 Regions map for stock proportions (most recent year) of total catch These proportions are the weights used for combining statuses of multiple stock into one status value for the region. 3.3 Status and trend Calculating status consists of the following steps: - derive Eastern Baltic cod penalty factor - calculate F-scores and B-scores - take mean of F and B scores, with data grouped by region_id, stock, year - derive weights from landings data (proportions of catch made up of different stocks in each region) - apply penalty for cod condition in the Eastern Baltic - calculate status as a geometric mean weighted by proportion of catch in each region The formulas for calculating F and B scores are based on this paper. 3.3.1 Eastern Baltic cod condition penalty factor Biomass and mortality are not sufficient to characterize the status of the Eastern Baltic cod, as it is condition not just populations which have significantly declined. Fulton’s K is used as a measure of condition. The following method based on Casini et al. 2016 : Individual body condition (Fulton’s K) estimated as K = W/(L^3) × 100 W = the total weight (g) of the fish L = total length (cm) of the fish condition averaged per length-class for each region, year lengths &lt; 10 cm and ≥60 cm excluded– not enough data focused on quarter 4 as it corresponds to the main feeding season The original metric considered for this penalty factor was proportion of surveyed cod in length category 40-60cm (the most commercially important) with Fulton’s K less than 0.8. However, due to small sample sizes per survey area in this length class (n = 1 some cases, increasingly common in more recent years), this metric will not suffice. Including smaller size classes 20-30cm and 30-40cm will help increase sample size, especially for future asssessments as fewer larger fish may be caught in the future. Within ICES survey areas, country was found to have significant effect on condition. So, rather than grouping by ICES area and matching resulting penalty factors to BHI regions in the same way as with mortality and biomass data, country information was retained and used in matching to BHI regions. Penalty factor as proportion of fish in class 40-60cm with K &gt; 0.8 3.3.2 F-Scores, B-Scores, Weights Status and trend are calculated by functions.R when the full BHI index is calculated. The calculations are included here also, so that parameters and results (sensitivity) can be explored. Scores are calculated in two ways (B-scores and F-scores) for each stock in a region, which are then averaged, weighted by a penalty factor if they correspond to Eastern Baltic cod, and combined for all stocks in a region as the geometric mean using catch proportions of total. Calculating F-scores is slightly more complicated, using both B/BMSY and F/FMSY ratios: F-scores are base off both F/FMSY and B/BMSY values. The piecewise function used here is derived so that parameters are bounds on F and B which can be conceptualized/are more intuitive and adjustable. See 3.5 Methods discussion section for more details on this function. The important thing to note here is that these values are adjustable and should be tested and reviewed if necessary during the calculation and comparison to the data. Use F and B scores to calculate overall FIS goal status: Use the average catch for each stock/region across the last 15 years to obtain weights Apply Eastern Baltic cod condition penalty factor Take geometric mean weighted by proportion each stock comprises of total catch in each region 3.3.3 Status 3.4 Gapfilling The F/FMSY and B/BMSY data processing for FIS and NP goals do not include any gapfilling or interpolation. However, the matching ICES subdivisions to BHI regions is not exact, and… The calculation of the Eastern Baltic Cod penalty factor does involve some gapfilling. Specifically, no data was reported in for cod in the Baltic International Trawl survey (BITS) for ICES areas 30, 31, 32 or in ICES area 29 except for Estonia. While… 3.5 Methods discussion 3.5.1 Adjustment of Cod scores Based on Body Weight and Length Source: Casini M et al. 2016 3.5.2 Matching ICES stock assessment areas to BHI Regions 3.5.3 Setting F-Score and B-score parameters 4. Visualizing Data Layers 4.1 Goal Status Map Below is a map of the FIS goal status scores. These are not the finalized BHI scores with pressure, resilience, or trend included- just status. Spatially, data inputs are the same value per year per stock, across the BHI regions in which the stock exists. BHI status and trend scores differ spatially across regions as they are combinations of multiple stocks status weighted by landings proportions. 5. Considerations for BHI3.0 Implement strong sustainability concept e.g. with a BMSY reference representing ‘ideal’ (near pristine) environmental conditions (e.g. historic extent of anoxic bottom) 6. References Casini M et al. 2016 Hypoxic areas, density-dependence and food limitation drive the body condition of a heavily exploited marine sh predator. R. Soc. open sci. 3: 160416. http://dx.doi.org/10.1098/rsos.160416 "],
["mariculture-food-provision-subgoal.html", "Chapter 3 Mariculture - Food Provision Subgoal 1. Background 2. Data 3. Prep: Wrangling &amp; Derivations, Checks/Evaluation, Gapfilling 4. Visualizing Data Layers 5. Considerations for BHI3.0 6. References", " Chapter 3 Mariculture - Food Provision Subgoal 1. Background 1.1 Goal Description The Mariculture sub-goal of the Food Provision (FP) goal describes a country’s ability to maximize the sustainable yield of farmed fish and shellfish in the ocean for human consumption. Mariculture is not a large industry in the Baltic, but it does provide some food production. For the BHI rainbow trout production was included in parts of Denmark, Sweden, Germany, and Finland, using available data. All other BHI regions are scored as NA, and thus MAR will not contribute to their overall FP goal score. 1.2 Model &amp; Data Tonnes of mariculture production data were collected from country databases or reports: Rainbow trout mariculture Sweden: Jorbruksverket database Denmark: Ministry of Environment and Food of Denmark database Finland (mariculture by species dataset): Natural Resources Institute database Finland (total mariculture by area): Natural Resources Institute database Germany: Email from plant manager (tassilo@jaeger-kleinicke.de) Finfish Mariculture &amp; Aquaculture Production Finfish Mariculture: HELCOM database All Baltic countries, Aquaculture Production: FAO FishStatJ Reference points Maximum nutrient discharge (N and P) where existing and new marine fish farms should not exceed the annual average of: 7g of P (tot-P) and 50g of N (tot-N) per kilogram of fish produced. Other information Data for BHI1.0 were compiled primarily by Ginnette Flores Carmenate as part of a Masters thesis. Data sources and aggregation approaches were slightly revised for BHI2.0. See data prep methods for more details. 2. Data Rainbow trout production (Denmark, Sweden and Finland) and Finfish (Denmark, Germany, Sweden and Finland) This prep document is used to generate and explore the following data layers: mar_harvest_bhi2019.csv mar_harvest_bhi2019.csv fis_ffmsy_bhi2019.csv These are saved to the layers/v2019 folder. Saved to data/MAR/v2019/intermediate are two intermediate datasets: mar_full_merged_dataset.csv and mar_gapfilling.csv. All these are derived from or informed by the raw datasets from HELCOM, national databases, and FAO. 2.1 Datasets with Sources 2.1.1 Rainbow trout mariculture Sweden Table 3.1: Source: Jorbruksverket database from document Downloaded 2019-10-09 by Andrea De Cervo Option Specification PDF: Vattenbruk 2018 Location data: Page 7, table A 2.1.2 Rainbow trout mariculture Denmark Table 3.2: Source: Ministry of Environment and Food of Denmark database Downloaded 2019-10-11 by Andrea De Cervo Option Specification Faste tabeller med akvakulturststistik: Produktion af hovedarter fordelt på region Rows: Regnbueørred, Saltvand 2.1.3 Mariculture in Finland Mariculture by Species (Rainbow Trout) Table 3.3: Source: Natural Resources Institute database Downloaded 2019-10-10 by Andrea De Cervo Option Specification Luke statistics database: Food fish production by species (1 000 kg, million e) Production: Quantity (1 000 kg) Area: Sea Fish: Rainbow trout Year: All Total mariculture by Area Table 3.4: Source: Natural Resources Institute database Downloaded 2020-1-20 by Andrea De Cervo Option Specification Luke statistics database: Food fish production (1 000 kg ungutted fish) by area ELY-centre: All Year: All Area: Sea 2.1.4 Rainbow trout mariculture Germany Table 3.5: Source: Email from plant manager Received 2019-10-30 Option Specification Location: Kiel Bay 2.1.5 Finfish Mariculture Table 3.6: Source: HELCOM database metadata Downloaded 2019-10-09 by Andrea De Cervo Option Specification HELCOM Map and Data service: Pressures and human activities Human activities: Finfish mariculture 2.1.6 All Baltic countries, Aquaculture Production (FAO) Table 3.7: Source: FAO FishStatJ Downloaded 2019-10-16 by Andrea De Cervo Option Specification FAO FishStatJ: Global aquaculture production Quantity: 1950-2017 2.1.7 Reference Point: maximum nutrient discharge (N and P) In 2016 HELCOM Contracting Parties adopted Recommendation 37/3 on “Sustainable aquaculture in the Baltic Sea Region”. However, the only parameter that can be used as reference point for Mariculture subgoal in the Baltic Sea (that can be also found on Finfish Mariculture data provided by HELCOM) is the maximum nutrient discharge for P and N, where existing and new marine fish farms should not exceed the annual average of: - 7g of P (tot-P) - 50g of N (tot-N) per 1kg fish (living weight) produced. (The nutrient limit values (P and N) are calculated on the basis that living fish contains 0,4% of phosphorus and 2,75% of nitrogen.) This recommendation was adopted in 2004, but since there are not updated nutrient limit values, this will be the parameter used as reference point. Only data provided by HELCOM on finfish mariculture include nutrient discharge. However, nutrient inputs from fish farms in Denmark were calculated on the basis of production data, and some numbers that were missing on nutrient input in Sweden were calculated by SCB, Statistics Sweden based on average input/ amount produced fish. Therefore, estimates for all other datasets will be made. 2.2 Centralization &amp; Normalization ## root location of the raw data dir_rawdata &lt;- file.path(dir_B, &quot;Goals&quot;, &quot;FP&quot;, &quot;MAR&quot;) # list.files(dir_rawdata) ## rainbow trout data rbt_de_raw &lt;- read_delim(file.path(dir_rawdata, &quot;rbt_de&quot;, &quot;rbt_de.csv&quot;), delim = &quot;;&quot;) rbt_dk_raw &lt;- read_delim(file.path(dir_rawdata, &quot;rbt_dk&quot;, &quot;rbt_dk.csv&quot;), delim = &quot;;&quot;) rbt_dk2005raw &lt;- read_delim(file.path(dir_rawdata, &quot;rbt_dk&quot;, &quot;rbt_dk_2005.csv&quot;), delim = &quot;;&quot;) rbt_fi_raw &lt;- read_delim(file.path(dir_rawdata, &quot;rbt_fi&quot;, &quot;rbt_fi.csv&quot;), delim = &quot;;&quot;) rbt_se_raw &lt;- read_delim(file.path(dir_rawdata, &quot;rbt_se&quot;, &quot;rbt_se.csv&quot;), delim = &quot;;&quot;) ## finland mariculture data by area and year mar_fi_raw &lt;- read_csv(file.path(dir_rawdata, &quot;mar_fi&quot;, &quot;mar_by_area.csv&quot;)) ## FAO rainbow trout data fao_rbt_raw &lt;- read_delim(file.path(dir_rawdata, &quot;FAO_fishstat&quot;, &quot;FAO_fishstat.csv&quot;), delim = &quot;;&quot;) # countrycodes for FAO dataset countrycode &lt;- data.frame( area = c(&quot;Germany&quot;, &quot;Denmark&quot;, &quot;Estonia&quot;, &quot;Finland&quot;,&quot;Sweden&quot;), country = c(&quot;DE&quot;, &quot;DK&quot;, &quot;ES&quot;, &quot;FI&quot;, &quot;SE&quot;) ) ## HELCOM Finfish mariculture data ## this is spatial data so we need to remove the geometry column ## also need to convert many columns from factor to numeric finfish_mariculture_raw &lt;- sf::st_read(file.path(dir_rawdata, &quot;Finfish_mariculture&quot;, &quot;Finfish_mariculture.shp&quot;)) st_geometry(finfish_mariculture_raw) &lt;- NULL finfish_mariculture_raw[, 1:28] &lt;- sapply(finfish_mariculture_raw[, 1:28], as.character) finfish_mariculture_raw[, 8:28] &lt;- sapply(finfish_mariculture_raw[, 8:28], as.numeric) 2.2.1 Spatial regions of the Data Create lookup tab for matching areas with bhi regions. May be multiple designations for the same areas, or intersections/overlap of different areas. To avoid double-counting, need to distinguish national/subnational data. bhiregions &lt;- bind_rows( ## germany c(country = &quot;DE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Kiel Bay&quot;, rgn = 8), ## denmark c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Arhus_cty&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Vejle_cty&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Fyns_cty&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Sønderjylland_cty&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Nordjyllands_cty&quot;, rgn = 2), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Frederiksborg_cty&quot;, rgn = list(2, 6)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Roskilde_cty&quot;, rgn = 12), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Storstrøms_cty&quot;, rgn = list(3, 7, 9, 12)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Vestsjællands_cty&quot;, rgn = list(2, 3)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Hovedstaden&quot;, rgn = list(2, 6, 12, 15)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Sjælland&quot;, rgn = list(3, 7, 9, 12)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Syddanmark&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Midtjylland&quot;, rgn = list(2, 3)), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Belts Danish coastal waters&quot;, rgn = 3), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bornholm Basin&quot;, rgn = 15), c(country = &quot;DK&quot;, lvl = &quot;subnatl&quot;, area = &quot;Arkona Basin&quot;, rgn = 12), ## sweden c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Kalmar lan&quot;, rgn = 26), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Gavleborgs lan&quot;, rgn = 37), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Vasternorrlands lan&quot;, rgn = 37), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Stockholm lan&quot;, rgn = list(35, 29)), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Vasterbottens lan&quot;, rgn = list(41, 39)), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Norrbottens lan&quot;, rgn = 41), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Aland Sea&quot;, rgn = 35), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Western Gotland Basin&quot;, rgn = 26), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bornholm Basin&quot;, rgn = 14), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;The Sound&quot;, rgn = 5), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bothnian Sea&quot;, rgn = 37), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bothnian Bay&quot;, rgn = 41), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Ne_coast&quot;, rgn = list(37, 39, 41)), c(country = &quot;SE&quot;, lvl = &quot;subnatl&quot;, area = &quot;Other_coasts&quot;, rgn = list(29, 35, 26, 14, 11, 5, 1)), ## finland c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Archipelago Sea&quot;, rgn = 36), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bothnian Sea&quot;, rgn = 38), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Gulf of Finland&quot;, rgn = 32), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Bothnian Bay&quot;, rgn = 42), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;The Quark&quot;, rgn = 40), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Aland&quot;, rgn = 36), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Kainuu&quot;, rgn = 42), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Ostrobothnia&quot;, rgn = list(38, 40, 42)), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Kaakkois_Suomi&quot;, rgn = 32), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Uusimaa&quot;, rgn = 32), c(country = &quot;FI&quot;, lvl = &quot;subnatl&quot;, area = &quot;Varsinais_Suomi&quot;, rgn = list(36, 38)), ## countries c(country = &quot;DE&quot;, lvl = &quot;natl&quot;, area = &quot;Germany&quot;, rgn = list(16, 13, 10, 8, 4)), c(country = &quot;DK&quot;, lvl = &quot;natl&quot;, area = &quot;Denmark&quot;, rgn = list(15, 12, 9, 7, 6, 3, 2)), c(country = &quot;SE&quot;, lvl = &quot;natl&quot;, area = &quot;Sweden&quot;, rgn = list(41, 39, 37, 35, 29, 26, 20, 14, 11, 5, 1)), c(country = &quot;FI&quot;, lvl = &quot;natl&quot;, area = &quot;Finland&quot;, rgn = list(42, 40, 38, 36, 32, 30)), c(country = &quot;ES&quot;, lvl = &quot;natl&quot;, area = &quot;Estonia&quot;, rgn = list(34, 31, 28, 25)), c(country = &quot;LA&quot;, lvl = &quot;natl&quot;, area = &quot;Latvia&quot;, rgn = list(27, 24)), c(country = &quot;LI&quot;, lvl = &quot;natl&quot;, area = &quot;Lithuania&quot;, rgn = 23), c(country = &quot;PO&quot;, lvl = &quot;natl&quot;, area = &quot;Poland&quot;, rgn = list(21, 18, 17)), c(country = &quot;RU&quot;, lvl = &quot;natl&quot;, area = &quot;Russia&quot;, rgn = list(33, 22, 19)) ) bhiregions[, 4:15] &lt;- sapply(bhiregions[, 4:15], as.numeric) bhiregions &lt;- bhiregions %&gt;% tidyr::pivot_longer(cols = 4:15, names_to = &quot;num&quot;, values_to = &quot;region_id&quot;) %&gt;% filter(!is.na(region_id)) %&gt;% dplyr::select(country, area, region_id, level = lvl) source(here::here(&quot;R&quot;, &quot;spatial.R&quot;)) regions_shape() # loads spatial features objects bhi_rgns_simple &lt;- rmapshaper::ms_simplify(input = BHI_rgns_shp) %&gt;% sf::st_as_sf() %&gt;% dplyr::right_join( dplyr::select(bhiregions, area, BHI_ID = region_id), by = c(&quot;BHI_ID&quot;) ) %&gt;% mutate(areacountry = paste(area, rgn_nam, sep = &quot;, &quot;)) cols &lt;- c( RColorBrewer::brewer.pal(7, &quot;Set2&quot;), RColorBrewer::brewer.pal(9, &quot;Set1&quot;), RColorBrewer::brewer.pal(6, &quot;Accent&quot;) ) areasMap &lt;- ggplot2::ggplot() + geom_sf( data = rnaturalearth::ne_countries(scale = &quot;medium&quot;, returnclass = &quot;sf&quot;) %&gt;% st_crop(xmin = 0, xmax = 40, ymin = 53, ymax = 67), fill = &quot;ivory&quot;, size = 0.1 ) + geom_sf( data = bhi_rgns_simple, aes(fill = areacountry), colour = NA, show.legend = FALSE ) + facet_wrap(~area, ncol = 6) + scale_fill_manual( values = colorRampPalette(cols)(51)[sample(1:51)] ) + scale_x_continuous(limit = c(5, 37)) + scale_y_continuous(limit = c(53.5, 66)) + theme( plot.margin = grid::unit(c(2, 2, 2, 2), &quot;mm&quot;), axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.text.y = element_blank(), axis.ticks.y = element_blank() ) MARareasMap &lt;- here::here(&quot;data&quot;, &quot;MAR&quot;, version_year, &quot;intermediate&quot;) ggsave(&quot;mar_areas_maps.png&quot;, areasMap, &quot;png&quot;, MARareasMap, width = 14, height = 15.5, units = c(&quot;in&quot;), dpi = 250) knitr::include_graphics(file.path(MARareasMap, &quot;mar_areas_maps.png&quot;)) 2.2.2 Finish datasets: use total-mariculture-by-region to downscale Rainbow Trout data Data were available both as total marine production by region within Finlnd, and also as total production nation-wide per fish species. Rainbow trout dominated the total fish production (over 90%). Following Ginnette’s approach from the first assessment, we convert the total production by region to rainbow trout production by region by using the country wide percent rainbow trout of the marine production in each year. Other minor contributions to total production were European whitefish, Trout, other species, Roe of rainbow trout, roe of european whitefish. ## two datasets: ## one on rainbow trout production at national level, ## the other with total mariculture production by region mar_finland &lt;- bind_rows( ## rainbow trout production in finland rbt_fi_raw %&gt;% dplyr::mutate( farm_species = str_to_sentence(production), produced_tonnes = tot_wt_tonnes, area = &quot;Finland&quot; ) %&gt;% dplyr::select(-production, -tot_wt_tonnes) %&gt;% filter(year &gt;= 1997), ## total mariculture production by area in finland mar_fi_raw %&gt;% mutate( area = str_replace(area, &quot;\\x81land&quot;, &quot;Aland&quot;), area = str_replace(area, &quot;Etel\\x8a-Savo&quot;, &quot;Etel-Savo&quot;), area = str_replace(area, &quot;H\\x8ame&quot;, &quot;Hame&quot;), area = str_replace(area, &quot;TOTAL&quot;, &quot;Finland Total&quot;) ) %&gt;% filter( # !area == &quot;TOTAL&quot;, ## no/very little coastline associated with these areas !area %in% c(&quot;Hame&quot;, &quot;North Karelia&quot;, &quot;Central Finland&quot;, &quot;Etel-Savo&quot;, &quot;Pohjois-Savo&quot;, &quot;Lapland&quot;) ) %&gt;% tidyr::gather(key = &quot;year&quot;, value = &quot;produced_tonnes&quot;, -area) %&gt;% mutate(year = as.numeric(year)) %&gt;% dplyr::mutate(farm_species = &quot;All mariculture&quot;) ) ## plot production to compare across years and areas ## substitute data = mar_finland_totals to see just national totals trout vs. all species ggplot(mapping = aes(year, produced_tonnes, fill = area), data = mar_finland) + geom_col(position = position_dodge(), width = 0.8, color = &quot;grey60&quot;, alpha = 0.8) + ggtitle(&quot;Finnish mariculture production (tonnes) 1997-2018&quot;) + labs(x = &quot;Year&quot;, y = &quot;Production (tonnes)&quot;, fill = &quot;Area&quot;) ## comparison of &#39;all mariculture&#39; data totals and national level species-specific data ## sub-dataset with only total mariculture for Finland and/or national level species-specific prduction data mar_finland_totals &lt;- filter(mar_finland, str_detect(area, &quot;^Finland&quot;)) hist_finland &lt;- ggplot(mar_finland_totals, aes(produced_tonnes)) + geom_histogram(binwidth = 400, fill = &quot;blue&quot;, alpha = 0.5, color = &quot;grey&quot;) + facet_wrap( ~ area, nrow = 2) boxplot_finland &lt;- ggplot(mar_finland_totals, aes(area, produced_tonnes)) + stat_boxplot(geom = &quot;errorbar&quot;, width = 0.2) + geom_boxplot() # t.test(produced_tonnes ~ area, mar_finland_totals) # wilcox.test(produced_tonnes ~ area, mar_finland_totals) ## p ≈ 0.17 so don&#39;t reject null that true location shift is equal to 0 ## finland area-specific rainbow trout data ## calculate percentage from the total to the species-specific prduction data rbt_percent &lt;- mar_finland_totals %&gt;% dplyr::select(-farm_species) %&gt;% tidyr::pivot_wider(names_from = area, values_from = produced_tonnes) %&gt;% dplyr::rename( tot_rainbow_trout = Finland, total = `Finland Total` ) %&gt;% mutate(rbt_percent = (tot_rainbow_trout/total)) rbt_fi_area &lt;- mar_finland %&gt;% filter(area != &quot;Finland&quot;, area != &quot;Finland Total&quot;) %&gt;% select(-farm_species) %&gt;% tidyr::pivot_wider(names_from = area, values_from = produced_tonnes) %&gt;% ## regional &#39;produced tonnes&#39; values are total mariculture rename( Varsinais_Suomi = `Varsinais-Suomi`, Kaakkois_Suomi = `Southeastern Finland` ) %&gt;% left_join(rbt_percent, by = &quot;year&quot;) %&gt;% tidyr::pivot_longer(cols = 2:7) %&gt;% mutate( country = &quot;FI&quot;, area = name, farm_species = &quot;Rainbow trout&quot;, produced_tonnes = value*rbt_percent, p_kg = as.numeric(NA), n_kg = as.numeric(NA) ) %&gt;% select(-tot_rainbow_trout, -total, -rbt_percent, -name, -value) ## add back years where don&#39;t have area specific data rbt_fi_area &lt;- bind_rows( rbt_fi_area, rbt_fi_raw %&gt;% dplyr::mutate( farm_species = str_to_sentence(production), produced_tonnes = tot_wt_tonnes, country = &quot;FI&quot;, area = &quot;finland&quot;, p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area) ) %&gt;% dplyr::select(-production, -tot_wt_tonnes) %&gt;% filter(year &lt; 1997) ) gridExtra::grid.arrange(hist_finland, boxplot_finland, nrow = 1, widths = c(2, 1.5)) 2.2.3 Merge datasets National and FAO datasets rbt_raw &lt;- bind_rows( ## finland rainbow trout data by area calculated rbt_fi_area, ## rbt_de rainbow trout germany rbt_de_raw %&gt;% dplyr::mutate(farm_species = str_to_sentence(production)) %&gt;% tidyr::gather(key = &quot;area&quot;, value = &quot;produced_tonnes&quot;, -year, -farm_species, -production) %&gt;% dplyr::mutate( produced_tonnes = as.numeric(produced_tonnes), country = &quot;DE&quot;, p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area), area = str_replace(area, &quot;Kiel_bay&quot;, &quot;Kiel Bay&quot;) ) %&gt;% select(year, country, area, farm_species, produced_tonnes, p_kg, n_kg) %&gt;% arrange(country), ## rbt_dk2005 rainbow trout 2005 denmarks rbt_dk2005raw %&gt;% dplyr::mutate(farm_species = str_to_sentence(production)) %&gt;% dplyr::select(-tot_wt_ton, -production) %&gt;% dplyr::rename( arhus_cty = cty1, vejle_cty = cty2, fyns_cty = cty3, sønderjylland_cty = cty4, ribe_cty = cty5, ringkøbing_cty = cty6, viborg_cty = cty7, nordjyllands_cty = cty8, frederiksborg_cty = cty9, roskilde_cty = cty10, storstrøms_cty = cty11, vestsjællands_cty = cty12 ) %&gt;% tidyr::gather(key = &quot;area&quot;, value = &quot;produced_tonnes&quot;, -year, -farm_species) %&gt;% # filter out the counties on the Atlantic coasts filter( !(area == &quot;viborg_cty&quot;), !(area == &quot;ringkøbing_cty&quot;), !(area == &quot;ribe_cty&quot;) ) %&gt;% dplyr::mutate( country = &quot;DK&quot;, p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area) ) %&gt;% arrange(country), ## rbt_dk rainbow trout denmark ## https://www.was.org/easOnline/AbstractDetail.aspx?i=4377 rbt_dk_raw %&gt;% dplyr::mutate(farm_species = str_to_sentence(production)) %&gt;% dplyr::select(-production) %&gt;% dplyr::rename( denmark = tot_wt_ton, hovedstaden = &quot;reg1&quot;, sjælland = &quot;reg2&quot;, syddanmark = &quot;reg3&quot;, midtjylland = &quot;reg4&quot; ) %&gt;% tidyr::gather(key = &quot;area&quot;, value = &quot;produced_tonnes&quot;, -year, -farm_species) %&gt;% dplyr::mutate( country = &quot;DK&quot;, p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area) ) %&gt;% arrange(country), ## rbt_se rainbow trout sweden rbt_se_raw %&gt;% dplyr::mutate( farm_species = str_to_sentence(production), sweden = tot_wt_mtonnes ) %&gt;% select(-ne_farm_no, -other_farm_no, -production, -tot_wt_mtonnes) %&gt;% tidyr::gather(key = &quot;area&quot;, value = &quot;produced_tonnes&quot;, -year, -farm_species) %&gt;% mutate( country = &quot;SE&quot;, p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area) ) %&gt;% arrange(country) ) %&gt;% mutate(source = &quot;national&quot;) rbt_raw &lt;- bind_rows( rbt_raw, ## fao_rbt fao data on rainbow trout fao_rbt_raw %&gt;% dplyr::mutate( area = country, farm_species = str_to_sentence(species) ) %&gt;% filter( ## aqua area atlantic NE, so maybe keep marine? # !(environment == &quot;Marine&quot; &amp; area == &quot;Denmark&quot;), str_detect(farm_species, &quot;Rainbow trout&quot;) ) %&gt;% select(-aqua_area, -Unit, -environment, -(&quot;1950&quot;:&quot;1971&quot;), -country, -species) %&gt;% tidyr::gather(key = &quot;year&quot;, value = &quot;produced_tonnes&quot;, -area, -farm_species) %&gt;% ## remove characters from production numeric values ## &quot;F&quot; stands FAO estimates from available sources of information mutate( year = as.numeric(year), produced_tonnes = str_replace(produced_tonnes, &quot;F&quot;, &quot; &quot;), produced_tonnes = as.numeric(produced_tonnes), p_kg = as.numeric(NA), n_kg = as.numeric(NA), area = capitalize(area) ) %&gt;% group_by(area, year) %&gt;% mutate( produced_tonnes = sum(produced_tonnes), p_kg = sum(p_kg), n_kg = sum(n_kg) ) %&gt;% distinct() %&gt;% filter(!is.na(produced_tonnes)) %&gt;% ## join with countrycode data left_join(countrycode, by = &quot;area&quot;) %&gt;% mutate(source = &quot;fao&quot;) %&gt;% select(year, country, area, farm_species, produced_tonnes, p_kg, n_kg, source) %&gt;% filter(area != &quot;Finland&quot;) %&gt;% # remove finland fao data-- duplicates or superceded by rbt_fi_area calculation filter(!(year %in% 2006:2017 &amp; area == &quot;Denmark&quot;)) %&gt;% # use Denmark national data instead here... filter(!(year %in% 2009:2018 &amp; area == &quot;Sweden&quot;)) # sweden natl data matches fao, but includes 2009-2018 ) ## reassign types and join bhi region_ids by area ## use lookup table defined in code chunk above rbt_raw[, c(5:7)] &lt;- sapply(rbt_raw[, c(5:7)], as.numeric) Finfish data from HELCOM ## wrangling finfish data so can merge with other datasets ## source of this dataset is helcom ## spatial file located here: ## http://metadata.helcom.fi/geonetwork/srv/eng/catalog.search#/metadata/3cfa469a-6a78-4913-b82f-57fd0e7f4dc0 finfish_raw &lt;- as_tibble(finfish_mariculture_raw) %&gt;% mutate(SUBBASIN = ifelse(is.na(SUBBASIN), COUNTY, SUBBASIN)) %&gt;% dplyr::rename( area = SUBBASIN, farm_species = PRODUCTION, country = COUNTRY ) %&gt;% ## remove the facilities on land ## these are entries with any of NA, on land, or On land as &#39;AREA&#39; ## are we sure that &#39;NA&#39; value for AREA means that it is on land? there are so many NAs, leaves only &quot;SE&quot; &quot;DK&quot; &quot;FI&quot; data... filter(is.na(AREA) |!str_detect(str_to_lower(AREA), &quot;on land&quot;), !(area == &quot;Bay of Mecklenburg&quot;)) %&gt;% tibble::rowid_to_column(&quot;farm_ID&quot;) %&gt;% mutate(farm_ID = as.factor(farm_ID)) %&gt;% ## replace NA value with general mariculture name &#39;finfish&#39; mutate( area = str_replace(area,&quot;Sland Sea&quot;,&quot;Aland Sea&quot;), AREA = str_replace(AREA, &quot;,&quot;, &quot;.&quot;), farm_species = ifelse( is.na(farm_species), &quot;Finfish&quot;, ifelse( str_detect(farm_species, &quot;Rainbow trout|rainbow trout&quot;), &quot;Rainbow trout&quot;, farm_species ) ) ) %&gt;% select(-AREA, -NAME, -COMMENTS) ## rename names within AREA without &lt;?&gt; symbols arealookup &lt;- data.frame( fix_area = c( &quot;Kalmar lan&quot;, &quot;Gavleborgs lan&quot;, &quot;Vasternorrlands lan&quot;, &quot;Vasternorrlands lan&quot;, &quot;Stockholm lan&quot;, &quot;Vasterbottens lan&quot;, &quot;Norrbottens lan&quot; ), area = unique(finfish_raw$area)[1:7] ) arealookup[,] &lt;- sapply(arealookup[,], as.character) ## gather production, phosphorus and nitrogen vars by year spreadcols &lt;- names(finfish_raw)[1:5] gathercols &lt;- names(finfish_raw)[6:26] ## reshape to have year and 3 variable cols: ## production (PR), nitrogen (N), and phosphorus (P) finfish_gather_yr &lt;- as_tibble(finfish_raw) %&gt;% tidyr::pivot_longer(cols = gathercols, names_to = &quot;varyear&quot;, values_to = &quot;value&quot;) %&gt;% mutate( year = str_extract(varyear, pattern = &quot;[0-9]{4}&quot;), var = str_extract(varyear, pattern = &quot;[A-Z]+&quot;) ) %&gt;% filter(!is.na(year)) %&gt;% # filter out na years as these represent aggregated values, but keep NA values tidyr::pivot_wider(id_cols = c(spreadcols, &quot;year&quot;, &quot;farm_ID&quot;), names_from = var, values_from = value) %&gt;% ## where production is zero and nutrients aren&#39;t close to zero, assume production should be NA... rowwise() %&gt;% dplyr::mutate(PR = ifelse(PR &lt; 1 &amp; (!is.na(N)|!is.na(P)), ifelse(any(c(N,P) &lt; 10), PR, NA), PR)) %&gt;% ungroup() %&gt;% ## keep only necessary columns and join with renamed areas select(year, country, area, farm_species, produced_tonnes = PR, p_kg = P, n_kg = N, farm_ID) %&gt;% left_join(arealookup, by = &quot;area&quot;) %&gt;% mutate(area = ifelse(!is.na(fix_area), fix_area, area), source = &quot;helcom&quot;) %&gt;% select(-fix_area, -farm_ID) combined_rawdata &lt;- rbind(rbt_raw, finfish_gather_yr) readr::write_csv( combined_rawdata, here::here(&quot;data&quot;, &quot;MAR&quot;, version_year, &quot;intermediate&quot;, &quot;mar_merged_rawdata.csv&quot;) ) 2.2.4 Standardize Units: Production regions and BHI Region assignments Note: where multiple BHI regions exist within the areas reported for mariculture data (e.g. “Ne_coast” for Sweden contains BHI regions 37, 39, and 41), the data values are split among the regions based on region sizes, i.e. with the assumption that each unit area is equally likely to contain the given mariculture farm… For future assessments, if adequate data are available, mariculture sites may be matched to BHI regions more precisely using spatial files (shapefiles). ## join spatial area information to bhiregions lookup table st_geometry(bhi_rgns_simple) &lt;- NULL bhiregions &lt;- bhi_rgns_simple %&gt;% dplyr::select(region_id = BHI_ID, Area_km2) %&gt;% distinct() %&gt;% right_join(bhiregions, by = &quot;region_id&quot;) %&gt;% mutate(level = as.numeric(ifelse(level == &quot;natl&quot;, &quot;1&quot;, &quot;2&quot;))) ## combine the datasets and add the ID column, then deal with overlapping data ## overlap here due to nesting of different spatial resolutions, not duplicate entries combined_w_rgns &lt;- combined_rawdata %&gt;% left_join(bhiregions, by = c(&quot;country&quot;, &quot;area&quot;)) %&gt;% ## in the case where theres no subnational data, use national mutate(level = ifelse(level == 2 &amp; is.na(produced_tonnes) &amp; is.na(p_kg)&amp; is.na(n_kg), 0, level)) %&gt;% group_by(year, country, region_id, farm_species) %&gt;% ## top_n function will select uppermost available level within grouping top_n(1, level) %&gt;% ungroup() level_area &lt;- combined_w_rgns %&gt;% group_by(year, country, level, area, farm_species) %&gt;% summarize(level_area_km2 = sum(Area_km2)) %&gt;% ungroup() combined_w_rgns &lt;- combined_w_rgns %&gt;% left_join(level_area, by = c(&quot;year&quot;, &quot;country&quot;, &quot;level&quot;, &quot;area&quot;, &quot;farm_species&quot;)) %&gt;% mutate(area_frac = Area_km2/level_area_km2) %&gt;% group_by(year, country, level, area, farm_species, region_id) %&gt;% mutate(area_frac = sum(area_frac)) %&gt;% # if there are multiple points per group, should keep unique ungroup() %&gt;% ## split production and nutrient use ## based on sizes of regions overlapping subnational areas mutate( ## split at subnational level split_production = ifelse(level == 2, produced_tonnes*area_frac, NA), split_N = ifelse(level == 2, n_kg*area_frac, NA), split_P = ifelse(level == 2, p_kg*area_frac, NA) ) %&gt;% group_by(year, country, farm_species) %&gt;% ## calculate subnational totals to subtract from national ## so remainder can be split among bhi regions without subnational categorization ## use only national data so don&#39;t count production amounts twice ## for nutrients, only have from helcom data, so use those mutate( subnatl_prod = sum(ifelse(source == &quot;national&quot;, split_production, 0), na.rm = TRUE), subnatl_N = sum(ifelse(source == &quot;helcom&quot;, split_N, 0), na.rm = TRUE), subnatl_P = sum(ifelse(source == &quot;helcom&quot;, split_P, 0), na.rm = TRUE) ) %&gt;% ungroup() %&gt;% mutate( ## split remainder at national level split_production = ifelse(level == 1, (produced_tonnes-subnatl_prod)*area_frac, split_production), split_N = ifelse(level == 1, (n_kg-subnatl_N)*area_frac, split_N), split_P = ifelse(level == 1, (p_kg-subnatl_P)*area_frac, split_P) ) %&gt;% select( year, country, source, area, level, region_id, farm_species, produced_tonnes, n_kg, p_kg, rgn_area_km2 = Area_km2, area_fraction = area_frac, split_production, split_N, split_P ) readr::write_csv( combined_w_rgns, here::here(&quot;data&quot;, &quot;MAR&quot;, version_year, &quot;intermediate&quot;, &quot;mar_combined_w_rgns.csv&quot;) ) 2.3 Initial Data Exploration Data by Source datasources &lt;- ggplot( combined_w_rgns %&gt;% mutate(region_id = as.factor(region_id)) %&gt;% mutate(year = as.numeric(year)) %&gt;% mutate(source = ifelse(source == &quot;fao&quot;, &quot;FAO&quot;, str_to_title(source))), aes(x = year, y = split_production, color = source) ) datasources + geom_point(alpha = 0.5) + facet_wrap(~ country, ncol = 1) + labs(x = &quot;Year&quot;, y = &quot;Production, split over BHI Regions\\n&quot;, color = &quot;Data Source&quot;) + theme(legend.position = &quot;bottom&quot;) 3. Prep: Wrangling &amp; Derivations, Checks/Evaluation, Gapfilling 3.1 Reorganizing/wrangling 3.2 Imputation/Gapfilling of merged datasets 3.2.1 Investigate estimates with linear models ## gapfill using raw merged data, ## not data split and assigned to BHI regions! plotdf &lt;- combined_rawdata %&gt;% filter(!is.na(p_kg) &amp; !is.na(n_kg)) %&gt;% filter(produced_tonnes &gt; 20) %&gt;% ## to use predict function later based on lm obj, need these names in models dplyr::rename(split_production = produced_tonnes, split_N = n_kg, split_P = p_kg) ## check relationships between production and nutrients ## quite linear, so probably ok to gapfill using this relationship... ## note: remember &#39;split&#39; values here are actually original data renamed! p_mdl &lt;- lm(split_P ~ 0 + split_production, data = plotdf) n_mdl &lt;- lm(split_N ~ 0 + split_production, data = plotdf) # summary(p_mdl) # summary(n_mdl) ## production estimates with linear models ## better without phosphorus, among other things because of negative coefficient... prod_mdl &lt;- lm(split_production ~ 0 + split_N, data = plotdf) # summary(prod_mdl) ggplot(plotdf) + geom_abline(slope = coef(p_mdl)[[&quot;split_production&quot;]], intercept = 0, color = &quot;grey&quot;) + geom_point(aes(x = split_production, y = split_P), color = &quot;blue&quot;, alpha = 0.75) + labs(x = &quot;Production&quot;, y = &quot;Phosphorus Use\\n&quot;) ggplot(plotdf) + geom_abline(slope = coef(prod_mdl)[[&quot;split_N&quot;]], intercept = 0, color = &quot;grey&quot;) + geom_point(aes(x = split_N, y = split_production), color = &quot;blue&quot;, alpha = 0.75) + labs(x = &quot;Nitrogen Use\\n&quot;, y = &quot;Production&quot;) 3.2.2 Gapfill and save MAR layers ## create dataset with nutrient ESTIMATES (kg) from COMBINED data mar_gapfilling &lt;- combined_w_rgns %&gt;% ## identify where to gapfill mutate( gapfill_nutrients = (is.na(split_P)|is.na(split_N)) &amp; !is.na(split_production), gapfill_prod = is.na(split_production) &amp; !is.na(split_N) &amp; !is.na(split_P) ) %&gt;% ## estimates based on production or nutrient use cbind( estim_p_kg = predict(p_mdl, combined_w_rgns), estim_n_kg = predict(n_mdl, combined_w_rgns), estim_prod = predict(prod_mdl, combined_w_rgns) ) %&gt;% ## gapfilling nutrients based on production and vice versa... ## production from regression w N and P, so cannot gapfill if either are NA mutate( split_N_gf = ifelse(is.na(split_N), estim_n_kg, split_N), split_P_gf = ifelse(is.na(split_P), estim_p_kg, split_P), split_prod_gf = ifelse(gapfill_prod, estim_prod, split_production), gapfilled = gapfill_nutrients|gapfill_prod ) %&gt;% select( year, country, region_id, farm_species, gapfilled, gapfill_nutrients, gapfill_prod, gapfill_nutrients, estim_n_kg, estim_p_kg, estim_prod, split_N_gf, split_P_gf, split_prod_gf ) %&gt;% mutate(year = as.character(year)) %&gt;% mutate(year = as.numeric(year)) mar_datalayers &lt;- mar_gapfilling %&gt;% ## get summarized values by BHI region group_by(year, region_id) %&gt;% summarize( n_kg = sum(split_N_gf, na.rm = TRUE), p_kg = sum(split_P_gf, na.rm = TRUE), produced_tonnes = sum(split_prod_gf, na.rm = TRUE), pct_prod_gf = sum(gapfill_prod)/n(), pct_nutrient_gf = sum(gapfill_nutrients)/n(), pct_gf = sum(gapfilled)/n() ) %&gt;% ungroup() %&gt;% ## nutrient ratios mutate( ## calculate ratios of nutrients used to fish produced ## grams per kg fish, unit conversion factors cancel n_ratio = ifelse(produced_tonnes == 0, 0, n_kg/produced_tonnes), p_ratio = ifelse(produced_tonnes == 0, 0, p_kg/produced_tonnes) ) ## save gapfilled dataset and dataset recording where gapfilling occurred write_csv(mar_gapfilling, here::here(&quot;data&quot;, &quot;MAR&quot;, version_year, &quot;intermediate&quot;, &quot;mar_gapfilling.csv&quot;)) write_csv( mar_datalayers %&gt;% select(year, region_id, produced_tonnes), file.path(dir_layers, version_year, sprintf(&quot;mar_harvest_bhi%s.csv&quot;, assess_year)) ) write_csv( mar_datalayers %&gt;% select(year, region_id, n_kg, p_kg, n_ratio, p_ratio), file.path(dir_layers, version_year, sprintf(&quot;mar_nutrients_bhi%s.csv&quot;, assess_year)) ) 4. Visualizing Data Layers 4.1 Nutrient Use As noted above, the HELCOM recommnedation is 50gN and 7kgP per kg of fish. The plots below explore differences between recorded and recommended nutrient use. The histogram plots show the distributions of differences with max allowable nutrients minus actual or estimated, so negative values are in excess of the recommendation. ## using gapfilled data plotdf &lt;- mar_datalayers %&gt;% left_join( read_csv(here::here(&quot;supplement&quot;, &quot;lookup_tabs&quot;, &quot;rgns_complete.csv&quot;)) %&gt;% select(region_id, country = region_name) %&gt;% mutate(country = str_replace(country, &quot;[A-Za-z ]+, &quot;, &quot;&quot;)) %&gt;% distinct(), by = &quot;region_id&quot; ) %&gt;% mutate( region_id = as.factor(region_id), diffsN = 50*produced_tonnes - n_kg, diffsP = 7*produced_tonnes - p_kg, diffsN_Ratio = 50 - n_ratio, diffsP_Ratio = 7 - p_ratio ) %&gt;% rename(Year = year, Production = produced_tonnes) histdf &lt;- plotdf %&gt;% select(Year, country, region_id, diffsN, diffsP, diffsN_Ratio, diffsP_Ratio, Production) %&gt;% tidyr::pivot_longer(cols = c(diffsN, diffsP)) ## distributions differences: max allowable nutrients minus actual or estimated ## negative values are in excess of the allowance hist_all &lt;- ggplot(histdf) + geom_histogram(aes(value), color = &quot;blue&quot;, fill = NA, binwidth = 800) + facet_wrap(~ name, nrow = 2) + labs(x = NULL, y = NULL) hist_lessthan0 &lt;- ggplot(filter(histdf, value &lt; 0)) + geom_histogram(aes(value), color = &quot;blue&quot;, fill = NA) + facet_wrap(~ name, nrow = 2) + labs(x = NULL, y = NULL) ## siginificant difference between more recent and older N and P values? # wilcox.test(value ~ timegroup, diffs_timewise) histN_yrs &lt;- ggplot(histdf %&gt;% filter(name == &quot;diffsN&quot;, value &lt; 5000) %&gt;% mutate(timegroup = ifelse(Year &lt; 2008, &quot;N before 2008&quot;, &quot;N after 2008&quot;))) + geom_histogram(aes(value), color = &quot;blue&quot;, fill = NA, binwidth = 50) + facet_wrap(~ timegroup, nrow = 2, scales = &quot;free_y&quot;) + labs(x = NULL, y = NULL) histP_yrs &lt;- ggplot(histdf %&gt;% filter(name == &quot;diffsP&quot;, value &lt; 5000) %&gt;% mutate(timegroup = ifelse(Year &lt; 2016, &quot;P before 2008&quot;, &quot;P after 2008&quot;))) + geom_histogram(aes(value), color = &quot;blue&quot;, fill = NA, binwidth = 50) + facet_wrap(~ timegroup, nrow = 2, scales = &quot;free_y&quot;) + labs(x = NULL, y = NULL) Nutrient Use: Recommended minus Reported Use (g/kg Fish) gridExtra::grid.arrange(hist_all, hist_lessthan0, histN_yrs, histP_yrs, nrow = 1) 4.2 Timeseries Plots ## time series of production and nutrient use by country timeseriesdf &lt;- plotdf %&gt;% group_by(Year, country) %&gt;% mutate( Nmax = sum(50*Production, na.rm = TRUE), Pmax = sum(7*Production, na.rm = TRUE) ) %&gt;% ungroup() %&gt;% rename(Nitrogen = n_kg, Phosphorus = p_kg) ggplot(timeseriesdf, aes(Year, Production, fill = region_id)) + geom_area(position = &quot;stack&quot;, alpha = 0.5, show.legend = FALSE) + facet_wrap(~ country, ncol = 1, scales = &quot;free_y&quot;) + labs(y = &quot;Mariculture production (tonnes, gapfilled)\\n&quot;) nutrientTimeseries &lt;- ggplot() + geom_area( mapping = aes(x = Year, y = Value, fill = RegionID), data = timeseriesdf %&gt;% tidyr::pivot_longer(cols = c(Nitrogen, Phosphorus, Nmax, Pmax, Production)) %&gt;% mutate(Value = round(value), RegionID = region_id) %&gt;% filter(name %in% c(&quot;Nitrogen&quot;, &quot;Phosphorus&quot;), Year &gt; 1975), position = &quot;stack&quot;, alpha = 0.5, show.legend = FALSE ) + geom_line( mapping = aes(x = Year, y = Value), data = timeseriesdf %&gt;% tidyr::pivot_longer(cols = c(Nitrogen, Phosphorus, Nmax, Pmax, Production)) %&gt;% mutate(Value = round(value)) %&gt;% filter(name %in% c(&quot;Nmax&quot;, &quot;Pmax&quot;), Year &gt; 1975) %&gt;% mutate(name = ifelse(name == &quot;Nmax&quot;, &quot;Nitrogen&quot;, &quot;Phosphorus&quot;)), inherit.aes = FALSE, size = 0.4, color = &quot;grey&quot;, show.legend = FALSE ) + facet_grid(rows = vars(country), cols = vars(name), scales = &quot;free_y&quot;) + labs(y = &quot;Nutrient Use (kg, gapfilled)\\n&quot;) # nutrientTimeseries_plotly &lt;- plotly::ggplotly(nutrientTimeseries) # nutrientTimeseries_plotly$x$layout$showlegend &lt;- FALSE # nutrientTimeseries_plotly nutrientTimeseries 4.3 Map of Mariculture Data Below is a map with the MAR goal data. Included in the map are data on production (tonnes), nutrient use (grams per kg fish produced), percentage of data gapfilled for (1) production and (2) nutrient use. library(leaflet) plotshp &lt;- rmapshaper::ms_simplify(input = BHI_rgns_shp) %&gt;% sf::st_as_sf() %&gt;% dplyr::select(rgn_nam, rgn_key, Subbasin, HELCOM_ID, region_id = BHI_ID, Area_km2) %&gt;% left_join( mar_datalayers %&gt;% filter(year == 2017) %&gt;% select(region_id, produced_tonnes, n_ratio, p_ratio, pct_prod_gf, pct_nutrient_gf), by = &quot;region_id&quot; ) %&gt;% ## because production data were split among regions ## based on the assumption that each unit area was equally likely to contain given mariculture facility ## should present this data as average production per area... mutate(produced_tonnes = produced_tonnes/Area_km2) %&gt;% mutate(Name = paste(Subbasin, rgn_nam, sep = &quot;, &quot;)) ## create palettes based on min max of data values palProd &lt;- leaflet::colorNumeric(&quot;RdYlBu&quot;, log10(seq(1, 5, 0.01)), &quot;#fcfcfd&quot;, reverse = TRUE) palN &lt;- leaflet::colorNumeric(&quot;RdYlBu&quot;, seq(0, 60, 0.5), &quot;#fcfcfd&quot;, reverse = TRUE) palP &lt;- leaflet::colorNumeric(&quot;RdYlBu&quot;, seq(0, 8.4, 0.05), &quot;#fcfcfd&quot;, reverse = TRUE) pal_gf &lt;- leaflet::colorNumeric(&quot;Greys&quot;, seq(0, 1, 0.01)) ## create maps leaflet(data = plotshp) %&gt;% addProviderTiles(providers$CartoDB.Positron) %&gt;% setView(18, 59, zoom = 5) %&gt;% addMapPane(&quot;popup&quot;, zIndex = 450) %&gt;% ## production data addPolygons( stroke = TRUE, opacity = 0.3, weight = 1, fillOpacity = 0.95, fillColor = ~palProd(produced_tonnes), group = &quot;Production (tonnes)&quot; ) %&gt;% ## nutrients use data addPolygons( stroke = TRUE, opacity = 0.3, weight = 1, fillOpacity = 0.95, fillColor = ~palN(n_ratio), group = &quot;Nitrogen use ratio (grams/kg fish)&quot; ) %&gt;% addPolygons( stroke = TRUE, opacity = 0.3, weight = 1, fillOpacity = 0.95, fillColor = ~palP(p_ratio), group = &quot;Phosphorus use ratio (grams/kg fish)&quot; ) %&gt;% ## layers controls, popup layer, and formatting addLayersControl( baseGroups = c( &quot;Production (tonnes/per km2)&quot;, &quot;Nitrogen use ratio (grams/kg fish)&quot;, &quot;Phosphorus use ratio (grams/kg fish)&quot; # &quot;Production data gapfilled (proportion)&quot;, # &quot;Nutrient data gapfilled (proportion)&quot; ), options = layersControlOptions(collapsed = FALSE) ) %&gt;% addPolygons( popup = paste( &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Region:&quot;, &quot;&lt;/strong&gt;&quot;, plotshp$Name, &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;BHI Region ID:&quot;, &quot;&lt;/strong&gt;&quot;, plotshp$region_id, &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Production:&quot;, &quot;&lt;/strong&gt;&quot;, round(plotshp$produced_tonnes, 5), &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Nitrogen:&quot;, &quot;&lt;/strong&gt;&quot;, round(plotshp$n_ratio, 2), &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Phosphorus:&quot;, &quot;&lt;/strong&gt;&quot;, round(plotshp$p_ratio, 2), &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Gapfill Prop., Nutrients:&quot;, &quot;&lt;/strong&gt;&quot;, plotshp$pct_nutrient_gf, &quot;&lt;/h5&gt;&quot;, &quot;&lt;h5&gt;&lt;strong&gt;&quot;, &quot;Gapfill Prop., Production:&quot;, &quot;&lt;/strong&gt;&quot;, plotshp$pct_prod_gf, &quot;&lt;/h5&gt;&quot; ), fillOpacity = 0, stroke = FALSE, options = pathOptions(pane = &quot;popup&quot;) ) 4.4 Gapfilling percentages by Country and Region percentagegf &lt;- ggplot( mar_datalayers %&gt;% left_join( read_csv(here::here(&quot;supplement&quot;, &quot;lookup_tabs&quot;, &quot;rgns_complete.csv&quot;)) %&gt;% select(region_id, country = region_name) %&gt;% mutate(country = str_replace(country, &quot;[A-Za-z ]+, &quot;, &quot;&quot;)) %&gt;% distinct(), by = &quot;region_id&quot; ) %&gt;% filter(year &gt; 2008) %&gt;% mutate(region_id = as.factor(region_id)) %&gt;% mutate(year = as.character(year)), aes(fill = region_id, x = year, y = pct_prod_gf) # also visualize: pct_gf, pct_nutrient_gf ) percentagegf + geom_col(position = position_dodge(), alpha = 0.5, show.legend = FALSE) + facet_wrap(~ country) + labs(x = &quot;Year&quot;, y = &quot;Percentage gapfilled production data\\n&quot;, fill = &quot;BHI Region ID&quot;) 5. Considerations for BHI3.0 If more adequate data are available, mariculture sites may be matched to BHI regions more precisely using spatial files (shapefiles). In particular, regarding Sweden, there are reports (e.g. page 8, table 9) where information about rainbow trout production in “other coasts” is split into two areas: sounth-eastern coast and south-western coast. However, these data are only available until 2014. 6. References Trujillo, P., (2008). Using a mariculture sustainability index to rank countries’ performance. Pp. 28-56 In: Alder, J. and D. Pauly (eds.). 2008. A comparative assessment of biodiversity, fisheries and aquaculture in 53 countries’ Exclusive Economic Zones.’ Fisheries Centre Research Reports. Fisheries Centre, University of British Columbia "]
]
