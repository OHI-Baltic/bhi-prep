
## 2. Data

```{r Preamble, echo = FALSE, include = FALSE, error = FALSE}
source(here::here("R", "data.R"))
source(here::here("R", "spatial.R"))
```

For the Eutrophication sub-goal five indicators were included:

-   winter (December-February) dissolved inorganic nitrogen (DIN) concentrations in the surface layer (0 - 10 m depth)
-   winter (December-February) dissolved inorganic phosphorus (DIP) concentrations in the surface layer (0 - 10 m depth)
-   summer (June-September) chlorophyll a concentration in the surface layer (0 - 10 m depth)
-   summer (June-September) Secchi depth
-   oxygen debt (hypoxic area below the halocline)

### 2.1 Datasets with Sources
<br/>

#### 2.1.1. Secchi Depth data

**Secchi Depth, ICES**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/SecchiDepth_ICES -->

Extraction from ICES database is classified into HELCOM Assessment Units – HELCOM sub basins with coastal WFD water bodies or water types

```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Dataset set:", "Oceanographic (per Parameter)"), 
  c("Parameter:", "secchi depth (Download)")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES data portal](http://ecosystemdata.ices.dk/inventory/Index.aspx?) <br/> Requested 24 Feb 2020 by Andrea De Cervo and received 24 Feb 2020 by Else Juul Green") 
```
*must request all records as web download limited to max 10000 records per layer*

<br/>

**Secchi Depth, SMHI**  
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/SecchiDepth_SMHI -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Datatype:", "Physical and Chemical"), 
  c("Parameter:", "secchi depth"),
  c("Months:", "All"),
  c("Years:", "1893-2020"),
  c("Decimal/fält-avgränsare (decimal/delimiter):", "punkt/semikolon (period/semicolon)"),
  c("Teckenkodning:", "UTF-8"),
  c("Rubrikrad:", "Englelska (English)")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [SMHI Shark database](http://www.smhi.se/klimatdata/oceanografi/havsmiljodata/marina-miljoovervakningsdata) (https://sharkweb.smhi.se) <br/> Downloaded 6 March 2020 by Andrea De Cervo")
```

<br/>

#### 2.1.2. Oxygen debt

**Oxygen debt ICES**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "Oxygen"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 30 March 2020 by Andrea De Cervo")
# each dataset has been extracted by country and Denmark split into five (5) because too big
```
*The maximum number of stations per download is 20000*

<br/>

**CTD ICES**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "CTD"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 10 April 2020 by Andrea De Cervo")
# each dataset has been extracted by country, Denmark split into three (3) and Germany into five (5) because too big. No CTD found for Lithuania
```
*The maximum number of stations per download is 20000*

<br/>

**Hydrogen Sulphide ICES**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Period:", "2000-2020"), 
  c("Parameter:", "Hydrogen Sulphide"),
  c("Country:", "(choose each Baltic country at a time)"),
  c("Ship:", "Any")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 10 April 2020 by Andrea De Cervo")

```
*The maximum number of stations per download is 20000*

<br/>

**CTD SMHI**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/OxygenDebt_ICES -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Datatype:", "Physical and Chemical"), 
  c("Parameter:", "Dissolved oxygen O2 CTD"),
  c("Months:", "All"),
  c("Years:", "2000-2020"),
  c("Decimal/fält-avgränsare (decimal/delimiter):", "punkt/semikolon (period/semicolon)"),
  c("Teckenkodning:", "UTF-8"),
  c("Rubrikrad:", "Englelska (English)")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [ICES database](https://ocean.ices.dk/HydChem/HydChem.aspx?plot=yes) <br/> Downloaded 16 April 2020 by Andrea De Cervo")

```

<br/>

#### 2.1.3. Chlorophyll a, and Nutrients (DIN and DIP)

**Chlorophyll a, and Nutrients, Baltic Nest**
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/NestData/nestdata_winter_nutrients.csv -->
<!-- dataset save location BHI_share/BHI 2.0/Goals/CW/EUT/NestData/nestdata_summer_chlorophyl.csv -->
```{r echo = FALSE, results = "asis"}
tab <- t(data.frame(
  c("Latitude/Longitude Begin/End:", "Baltic Sea"), 
  c("Dates Begin/End:", "Jan 1, 2005 to Dec 31, 2019"), 
  c("Parameters:", "PO4P, NO3N, NO2N, NO23N, NH4N, CHL")))

colnames(tab) <- c("Option", "Specification")
rownames(tab) <- NULL

knitr::kable(tab, caption = "Source: [Baltic Nest database](http://nest.su.se/dataPortal/getStations) <br/> Downloaded 28 February 2020 by Ellie Campbell. See data.R/get_nest_data function for more detailed info.")
```
<br/>

**Nutrients, Baltic Nest**
```{r using get_nest_data function to download winter nutrient data, eval = FALSE}
dir_B <- "/home/ellie/data/bhi_share/BHI 2.0"
get_nest_data(
  date_range = c(20050101,20191231), 
  months = c(11,12,1:3), 
  param_codes = c("NO3N","NO2N","NO23N","NH4N","TOTN","PO4P")
) %>% readr::write_csv(file.path(dir_B, "Goals", "CW", "EUT", "NestData", "nestdata_winter_nutrients.csv"))
```
<br/>

**Chlorophyll a, Baltic Nest**
```{r using get_nest_data function to download summer chlorophyl A data, eval = FALSE}
get_nest_data(
  date_range = c(20050101, 20191231), 
  months = 5:10, 
  param_codes = c("CHL")
) %>% readr::write_csv(file.path(dir_B, "Goals", "CW", "EUT", "NestData", "nestdata_summer_chlorophyl.csv"))
```
<br/>

#### 2.1.4. HELCOM HOLAS Basin
These basins are the relevant physical units.  
Secchi data will be first assessed at this level and then assigned to BHI region. EEZ divisions may result in some BHI regions that have no data but they are physically the same basin as a BHI region with data.

```{r basin lookup}
dir_lookup <- file.path(dir_prep, "supplement", "lookup_tabs")
basin_lookup_table <-  read.csv(file.path(dir_lookup, "bhi_basin_country_lookup.csv"), sep=";")
basin_lookup <- basin_lookup_table %>% 
  select(bhi_id = BHI_ID, basin = Subbasin, rgn_nam) %>% 
  mutate(basin = as.character(basin),
         rgn_nam = as.character(rgn_nam))
  
```
<br/>


#### 2.1.5. Threshold values

The threshold values have been agreed on by HELCOM and by Heads of Delegation (HOD) and the applied threshold values for core and pre-core indicators in the HELCOM open sea assessment units are presented in the [Baltic Sea Environment Proceedings no.156](http://stateofthebalticsea.helcom.fi/wp-content/uploads/2019/09/BSEP156-Eutrophication.pdf) (p.10, Table 2).

```{r read raw datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## root location of the raw data
dir_B <- file.path(dirname(dir_prep), "bhi-data", "BHI 2.0")
dir_rawdata <- file.path(dir_B, "Goals", "CW", "EUT")

eut_thresholds_values <- read.delim(file.path(dir_rawdata, "eut_threshold_values.csv"), sep = ";")

eut_thresholds <- eut_thresholds_values %>% 
  rename(basin = Assessment.units, winter_DIN = DIN.._mol.l.1., winter_DIP = DIP.._mol.l.1., 
         summer_chla = Chla.._g.l.1., summer_secchi = Water.clarity..m., oxyg_debt = O2..mg.l.1.) %>% 
  select(basin, winter_DIN, winter_DIP, summer_chla, summer_secchi, oxyg_debt) %>% 
  mutate(basin = str_replace_all(basin,"_",""),
         basin = str_trim(basin, side = "right"),
         ## ‘N’ means that the indicator is not applicable there, so it will be replaced as NA
         oxyg_debt = str_replace(oxyg_debt, "N", " "),
         oxyg_debt = as.numeric(oxyg_debt)) 


```
<br/>

### 2.2 Centralization & Normalization

#### 2.2.1 Spatial regions of the Data

**Create lookup tab for matching areas with bhi regions and helcom coastal codes.**   
May be multiple designations for the same areas, or intersections/overlap of different areas. To avoid double-counting, need to distinguish national/subnational data. 

```{r to match areas with bhi regions, echo = TRUE}
## Create an additional lookup table from the datasets used in the BHI 1.0 
## ('ices_secchi' and 'smhi_secchi')
basin_additional_lookup_table <- rbind(
  ices_secchi %>%
    select(-X1, -secchi, -Month, -Year, -Date, -Station, -Cruise), 
#    mutate(Station = str_replace(Station, "^0+", " "))
  smhi_secchi %>% 
    select(-X1, -value, -Month, -Year, -Date, -unit, 
           -Stationsnamn, -Provtagningstillfaelle.id) %>% 
#    rename(Station = Stationsnamn, Cruise = Provtagningstillfaelle.id) %>% 
    mutate("Assessment_unit" = " ")
)  

readr::write_csv(
  basin_additional_lookup_table, 
  file.path(dir_lookup, "basin_add_lookup_table.csv")
)
```


**Secchi data**
```{r read raw datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## read in secchi data
secchi_raw_ices <- read.delim(file.path(dir_rawdata, "SecchiDepth_ICES", "SecchiDepth_ICES.csv"), sep = ";")
secchi_raw_smhi <- read.delim(file.path(dir_rawdata, "SecchiDepth_SMHI", "SecchiDepth_SMHI.csv"), sep = ";")
basin_add_lookup_table <-  read.csv(file.path(dir_lookup, "basin_add_lookup_table.csv"))
```
<br/>

**Oxygen and CTD**

```{r read raw datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
## this will read in both the oxygen and CTD datasets from the OxygenDebt_ICES directory
## in the same step, this will check for duplicates and then keep only the distinct observations
read_ox_data <- function(datasets = "ox"){
  
  lapply(
    ## lists all subfiles in OxygenDebt_ICES directory, and selects only ones with csv extension
    grep(
      pattern = datasets, 
      list.files(file.path(dir_rawdata, "OxygenDebt_ICES"), pattern = ".csv", recursive = TRUE),
      value = TRUE
    ),
    ## read in the file and assign to a variable in the global environment
    function(x){
      tmp <- read.delim(file.path(dir_rawdata, "OxygenDebt_ICES", x), sep = ",", stringsAsFactors = FALSE)
      
      ## Check for duplicates in all national datasets
      
      # duplicates <- tmp %>% 
      #   group_by(
      #     Cruise, Station, yyyy.mm.ddThh.mm, Bot..Depth..m., TEMP..deg.C., PSAL..psu.,
      #     PRES..db., Latitude..degrees_north., Longitude..degrees_east., DOXY..ml.l.
      #   ) %>%
      #   summarise(n = n()) %>%
      #   filter(n > 1) %>%
      #   ungroup()
      
      ## Only extract unique observations
      uniquedat <- tmp %>% 
        distinct(
          Cruise, Station, yyyy.mm.ddThh.mm, Bot..Depth..m., TEMP..deg.C., PSAL..psu.,
          PRES..db., Latitude..degrees_north., Longitude..degrees_east., DOXY..ml.l.
        )
      nam <- x %>% 
        stringr::str_extract("[a-zA-Z_0-9\\-]+.csv|[a-z0-9\\-]+.csv|[a-z]+.csv") %>% 
        stringr::str_remove_all(".csv") %>% 
        stringr::str_remove_all("[0-9]{4}\\-[0-9]{2}")
      ## different ctd and h2s naming conventions...
      nam <- ifelse(nam == "0410032c", "finlandctd", nam)
      nam <- ifelse(str_detect(nam, "CTD_"), paste0(str_remove(nam, "CTD_"), "ctd"), nam)
      nam <- ifelse(str_detect(nam, "H2S_"), paste0(str_remove(nam, "H2S_"), "h2s"), nam)
      
      ## assign to names in global environment...
      if(str_detect(nam, "ox$")){
        assign(sprintf("ox_%s", nam), uniquedat, envir = .GlobalEnv)
      }
      if(str_detect(nam, "ctd$")){
        assign(sprintf("ctd_%s", nam), uniquedat, envir = .GlobalEnv)
      }
      if(str_detect(nam, "h2s$")){
        assign(sprintf("h2s_%s", nam), uniquedat, envir = .GlobalEnv)
      }
    }
  ) 
}
```
<br/>

**Chlorophyll a and Nutrients**
```{r read raw datasets, message = FALSE, warning = FALSE, echo = TRUE, results = "hide"}
chlorophyll <- read.delim(file.path(dir_rawdata, "NestData", "nestdata_summer_chlorophyl.csv"), sep = ",")
nutrient <- read.delim(file.path(dir_rawdata, "NestData", "nestdata_winter_nutrients.csv"), sep = ",")
```
<br/>


#### 2.2.2 Secchi datasets

**Duplicates in the Data** 

ICES data contains profile data (eg temperature, but secchi is only measured once). Need only unique secchi records. It appears that SMHI also contains profiles. Also check to see if any SMHI data already in the ICES records.

**Coastal data**  

- non-coastal (offshore) data are flagged with the code "0" under the column *"HELCOM_COASTAL_CODE"*  
- HOLAS basin shape files with coastal and non-coastal areas were overlaid with the secchi sampling locations, all locations were flagged with a code indicating coastal or offshore.  
- Coastal data are removed from the analysis.  
- This should result in a similar dataset used as Fleming-Lehtinen and Laamanen 2012 (see map). 

**ICES secchi data**
```{r}
## 1) Merge the additional basin lookup table to both datasets
## 2) Check duplicates from each raw secchi datasets and distinct (both ices and smhi)
## 3) Use setdiff() to indentify data smhi not in ices 
## 4) Create a new Secchi dataset by only binding the new_smhi_unique object to ices_unique

### ICES Data overview
# colnames(ices_raw_ices)
# str(ices_raw_ices)

# Merge the add basin lookup table to ices dataset
ices <- secchi_raw_ices %>% 
  rename(secchi = Secchi.Depth..m.,  Date = yyyy.mm.ddThh.mm, 
         Latitude = Latitude..degrees_north., Longitude = Longitude..degrees_east., 
         bottom_m = Bot..Depth..m.) %>%
  mutate(Date =  as.Date(Date), Year = format(Date, "%Y"), 
         Date =  as.Date(Date), Month = format(Date, "%m"),
         Month = str_replace(Month, "^0+", ""),
         bottom_m = as.numeric(bottom_m)) %>%
  select(-Type) %>% 
  left_join(basin_add_lookup_table, by = c("Latitude", "Longitude")) # 31.236.646 

#### Look for duplicate data 
# Check for duplicates in ices
ices_duplicates <- ices %>%
  group_by(Latitude, Longitude, Cruise, Station, Date, secchi) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup() 

# Only extract unique observations
ices_unique <- ices %>% 
  distinct(Cruise, Station, Date, Latitude, Longitude, secchi, bottom_m, 
           BHI_ID, HELCOM_COASTAL_CODE, HELCOM_ID, Year, Month) %>% 
# removed 'Assessment_unit'
  mutate(supplier = 'ices') # 102881

## Which ices data have BHI_ID of NA?
ices.na <- ices_unique %>%
  filter(is.na(BHI_ID))
dim(ices.na) # 64437

ices.na.loc <- ices.na %>% 
  dplyr::select(Latitude, Longitude) %>% 
  distinct() ## unique locations
dim(ices.na.loc) # 2142  2

ices.na %>% 
  dplyr::select(HELCOM_COASTAL_CODE) %>% 
  distinct()  ## at least one location is off shore

ices.na %>% 
  filter(HELCOM_COASTAL_CODE == 0)

## will need to manually add BHI_ID for site with NA values and coastal code of 0
```
<br/>

**SMHI secchi data**
```{r}
### SMHI data overview
# colnames(secchi_raw_smhi)
# str(secchi_raw_smhi)
# The 'Value' and 'Unit' columns are partly switched, so need to be fixed
fixed_data_smhi <- secchi_raw_smhi %>% 
  filter(str_detect(Value, "Secchi")) %>% 
  select(-Parameter)

colnames(fixed_data_smhi) <- setdiff(colnames(secchi_raw_smhi), "Quality.flag")
## bind back together with rows that are ok and fix the column classes
new_secchi_smhi <- bind_rows(
  mutate(fixed_data_smhi, Quality.flag = NA),
  filter(secchi_raw_smhi, !str_detect(Value, "Secchi"))
)

# when making 'Value' as numveric, all the values within that column change
new_secchi_smhi <- new_secchi_smhi %>% 
  mutate(Value = as.numeric(as.character(Value)), Parameter = as.character(Parameter))

# Merge the add basin lookup table to secchi dataset
smhi <- new_secchi_smhi %>% 
  rename(secchi = Value, Date = Sampling.date, Cruise = Visit.event.identifier,
         # use the decimal degrees for lat and lon (as for ICES)
         Latitude = Sample.latitude..DD., Longitude = Sample.longitude..DD.,
         # 'Station.water.depth' cosidered as 'Bottom depth'?
         Station = Station.name, bottom_m = Station.water.depth) %>%
  mutate(Date =  as.Date(Date), Year = format(Date, "%Y"),
         Date =  as.Date(Date), Month = format(Date, "%m"),
         Month = str_replace(Month, "^0+" ,""),
         Year = as.character(Year),
         bottom_m = as.numeric(bottom_m),
         Cruise = as.character(Cruise),
         Station = as.character(Station)) %>%  
  select(Cruise, Station, Date, Latitude, Longitude, secchi, bottom_m, Year, Month) %>% 
  left_join(basin_add_lookup_table, by = c("Latitude", "Longitude")) # 10.649.226

#### Look for duplicate data 
# Check for duplicates in ices
smhi_duplicates <- smhi %>%
  group_by(Latitude, Longitude, Cruise, Station, Date, secchi) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  ungroup() 

# Only extract unique observations
smhi_unique <- smhi %>% 
  distinct(Cruise, Station, Date, Latitude, Longitude, secchi, bottom_m, 
           BHI_ID, HELCOM_COASTAL_CODE, HELCOM_ID, Year, Month, ) %>% 
# removed 'Assessment_unit'
  mutate(supplier = 'smhi') # 50696

## is na smhi
smhi.na <- smhi_unique %>%
  filter(is.na(BHI_ID))
dim(smhi.na) # 49121  14

smhi.na.loc <- smhi.na %>% 
  dplyr::select(Latitude, Longitude) %>% 
  distinct() ## unique locations
dim(smhi.na.loc) # 3619   2

smhi.na %>% 
  dplyr::select(HELCOM_COASTAL_CODE)%>% 
  distinct()  ## none are offshore

smhi.na %>% 
  filter(HELCOM_COASTAL_CODE == 0)

#################################################
  ## remove OSPAR rows
#  filter(!(HELCOM.OSPAR.area == "OSPAR")) %>% 
#  dplyr::select(cruise, station, date, year, month,
#                lat, lon, secchi, bottom_m, supplier)

## Use setdiff() to indentify data smhi not in ices  
new_smhi_unique <- setdiff(dplyr::select(smhi_unique, -supplier), dplyr::select(ices_unique, -supplier)) %>%
  mutate(supplier = "smhi") 

## Create a new secchi dataset by only binding the new_smhi_unique object to ices_unique
secchi <- bind_rows(ices_unique, smhi_unique) %>% 
  distinct() %>% # 153577 tot observations 
  rename(secchi_m = secchi)

# Save dataset (bhi-prep)
readr::write_csv(
  secchi, 
  here::here("data", "CW", "eutrophication", version_year, "intermediate", "secchi_merged_rawdata.csv")
)
```

<br/>


#### 2.2.3. Merging Oxygen Datasets

```{r merge country oxygen data and all CTD country data to make two large datasets with rgn info joined also}
## Merging oxygen datasets, only unique entries
read_ox_data(datasets = "ox")
oxdata_to_merge <- ls(pattern = "ox_[a-z].*ox$")

ox_merged <- do.call(rbind, lapply(oxdata_to_merge, function(x){
  cbind(get(x), Country = stringr::str_remove_all(x, "ox|_|[0-9]"))
})) 
ox_merged <- ox_merged %>%
  rename(
    Oxygen = DOXY..ml.l.,
    Date = yyyy.mm.ddThh.mm, 
    Latitude = Latitude..degrees_north.,
    Longitude = Longitude..degrees_east., 
    Temperature = TEMP..deg.C., 
    Salinity = PSAL..psu., 
    Depth = PRES..db., # what is this, pressure or depth?
    Bot_Depth = Bot..Depth..m. # so many NAs in this variable....
  ) %>%
  mutate(
    Year = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%Y")),
    Month = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%m")),
    Day = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%d")),
    Hour = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%H")),
    Minute = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%M")),
    Date = as.Date(Date, "%Y-%m-%d"),
    Station = as.character(Station),
    Oxygen_Original = as.character(Oxygen),
    Oxygen = as.numeric(Oxygen_Original),
    Depth = as.numeric(Depth)
  )
## in some cases oxygen data has non-numeric characters, <0.01 for example...
## these become NAs when coerced to numeric
## what is the best approach: give value of 0.01, NA, or zero?
ox_merged_w_rgns <- join_rgns_info(
  dataset = ox_merged,
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles")
)

colnames(ox_merged_w_rgns) <- str_to_title(names(ox_merged_w_rgns))
ox_merged_w_rgns <- ox_merged_w_rgns %>% 
  filter(!is.na(Helcom_id), !is.na(Oxygen)) %>% 
  select(-Ices_area, -In_25km_buffer, -Rgn_nam, -Rgn_key, -Oxygen_original, -Date) %>%
  rename(Bot_Depth = Bot_depth, BHI_ID = Bhi_id, Assessment_Unit = Helcom_id)

## CTD datasets
read_ox_data(datasets = "CTD/")
ctd_data_to_merge <- ls(pattern = "ctd_[a-z].*ctd$")
## issue with sweden dataset, no oxygen column...
ctd_data_to_merge <- setdiff(ctd_data_to_merge, "ctd_sweden20ctd")

ctd_merged <- do.call(rbind, lapply(ctd_data_to_merge, function(x){
  cbind(get(x), Country = stringr::str_remove_all(x, "ctd|_|[0-9]"))
})) 
ctd_merged <- ctd_merged %>%
  rename(
    Oxygen = DOXY..ml.l.,
    Date = yyyy.mm.ddThh.mm,
    Latitude = Latitude..degrees_north.,
    Longitude = Longitude..degrees_east.,
    Temperature = TEMP..deg.C.,
    Salinity = PSAL..psu.,
    Depth = PRES..db., # what is this, pressure or depth?
    Bot_Depth = Bot..Depth..m. # so many NAs in this variable....
  ) %>%
  mutate(
    Year = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%Y")),
    Month = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%m")),
    Day = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%d")),
    Hour = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%H")),
    Minute = as.numeric(format(strptime(Date, "%Y-%m-%dT%H:%M"), "%M")),
    Date = as.Date(Date, "%Y-%m-%d"),
    Station = as.character(Station),
    Oxygen_Original = as.character(Oxygen),
    Oxygen = as.numeric(Oxygen_Original),
    Depth = as.numeric(Depth)
  )
rm(ctd_data_to_merge)

ctd_merged_w_rgns <- join_rgns_info(
  dataset = ctd_merged,
  rgn_shps_loc = file.path(dirname(dir_B), "Shapefiles")
)

colnames(ctd_merged_w_rgns) <- str_to_title(names(ctd_merged_w_rgns))

ctd_merged_w_rgns <- ctd_merged_w_rgns %>%
  filter(!is.na(Helcom_id), !is.na(Oxygen)) %>% 
  select(-Ices_area, -In_25km_buffer, -Rgn_nam, -Rgn_key, -Oxygen_original, -Date) %>%
  rename(Bot_Depth = Bot_depth, BHI_ID = Bhi_id, Assessment_Unit = Helcom_id)

## Save datasets
dir_interm <- here::here("data", "CW", "eutrophication", version_year, "intermediate")

## maybe in future look into using for big files: https://docs.ropensci.org/piggyback/
readr::write_csv(
  select(ox_merged_w_rgns, -BHI_ID, -Country, -Subbasin, -Station, -Bot_Depth), 
  file.path(dir_interm, "ox_merged_rawdata.csv")
)
readr::write_csv(
  select(ctd_merged_w_rgns, -BHI_ID, -Country, -Subbasin, -Station, -Bot_Depth),
  file.path(dir_interm, "ctd_merged_rawdata.csv")
)
```
<br/>

**OXYGEN SPATIAL VISUALIZATION**

```{r map showing datasets overlaps, results = "show", message = FALSE, echo = TRUE, fig.height = 9, fig.width = 9.5}
## quick map of measurements by subbasin for selected year
plotsf <- ox_merged_w_rgns %>% 
  filter(Year == 2018, !is.na(Code)) %>% 
  sf::st_as_sf(coords = c("Longitude", "Latitude"))
oxmap <- ggplot(plotsf) + geom_sf(aes(color = Code), show.legend = FALSE)


## plot by subbasins
boxplotdf <- ox_merged_w_rgns %>% 
  filter(!is.na(BHI_ID)) %>% 
  mutate(Year = factor(Year))

oxtsplot <- ggplot(boxplotdf) + 
  geom_point(aes(Year, Oxygen), size = 0.2, alpha = 0.1) +
  facet_wrap(
    c("BHI_ID", "Subbasin"), 
    labeller = label_wrap_gen(width = 35, multi_line = FALSE)
  ) +
  labs(x = NULL, y = "Dissolved Oxygen (ml/l)") +
  theme(axis.text.x = element_text(angle = 90))

  
oxboxplot <- ggplot(boxplotdf) + 
  geom_boxplot(aes(Year, Oxygen), outlier.shape = NA, size = 0.2) +
  facet_wrap(
    c("BHI_ID", "Subbasin"), 
    labeller = label_wrap_gen(width = 35, multi_line = FALSE)
  )  +
  labs(x = NULL, y = "Dissolved Oxygen (ml/l)") +
  theme(axis.text.x = element_text(angle = 90))


gridExtra::grid.arrange(oxmap, oxtsplot, oxboxplot, layout_matrix = rbind(c(1,1),c(1,1),c(2,3)))
```


#### 2.2.4. Chlorophyll a Wrangling

**Coastal data**  

- non-coastal (offshore) data are flagged with the code "0" under the column *"HELCOM_COASTAL_CODE"*  
- HOLAS basin shape files with coastal and non-coastal areas were overlaid with the secchi sampling locations, all locations were flagged with a code indicating coastal or offshore.  
- Coastal data are removed from the analysis.  
- This should result in a similar dataset used as Fleming-Lehtinen and Laamanen 2012 (see map). 

**Chlorophyll a data**
```{r merge two finish datasets, results = "show", message = FALSE, echo = TRUE, fig.width = 9.5, fig.height = 4.5}

# Data overview
colnames(chlorophyll)
str(chlorophyll)

colnames(nutrient)
str(nutrient)

chla <- chlorophyll %>% 
  rename(chla_ug_l = CHL,  date = OBSDATE, time = OBSTIME,
         Latitude = LATITUDE, Longitude = LONGITUDE, 
         cruise = SHIP, id = ID, depth_m = OBSDEP) %>%
  mutate(date =  as.Date(date), year = format(date, "%Y"), 
         date =  as.Date(date), month = format(date, "%m")) %>% 
  left_join(basin_add_lookup_table, by = c("Latitude", "Longitude")) # 31.236.646 

## Check for duplicates 
chla_duplicates <- chla %>%
    group_by(id, cruise, date, year, month, Latitude,
             Longitude, chla_ug_l, depth_m) %>%
    summarise(n = n()) %>%
    filter(n > 1) %>%
    ungroup() #no duplicates

# Only extract unique observations
chla_unique <- chla %>% 
  distinct(id, cruise, date, year, month, Latitude, Longitude, chla_ug_l, 
           depth_m, BHI_ID, HELCOM_COASTAL_CODE, HELCOM_ID) 
# 44071

## Which ices data have BHI_ID of NA?
chla.na <- chla_unique %>%
  filter(is.na(BHI_ID))
dim(chla.na) # 21591 

chla.na.loc <- chla.na %>% 
  dplyr::select(Latitude, Longitude) %>% 
  distinct() ## unique locations
dim(chla.na.loc) # 1448  2

chla.na %>% 
  dplyr::select(HELCOM_COASTAL_CODE) %>% 
  distinct()  ## no locations off shore

chla.na %>% 
  filter(HELCOM_COASTAL_CODE == 0)

## will need to manually add BHI_ID for site with NA values and coastal code of 0

# Save dataset (bhi-prep)
readr::write_csv(
  chla_unique, 
  here::here("data", "CW", "eutrophication", version_year, "intermediate", "chla_rawdata.csv")
)
```
<br/>

**Nutrients data**
```{r}
nutrients <- nutrient %>% 
  rename(no3 = NO3N,  no2 = NO2N, nh4 = NH4N, po4 = PO4P, date = OBSDATE, 
                lat = LATITUDE, lon = LONGITUDE, 
                cruise = SHIP, id = ID, depth = OBSDEP) %>%
  select(-OBSTIME, -NO23N, -TOTN) %>% 
  mutate(date =  as.Date(date), year = format(date, "%Y"), 
         date =  as.Date(date), month = format(date, "%m"))

## Check for duplicates 
nutrients_duplicates <- nutrients %>%
    group_by(id, cruise, date, year, month, lat,
             lon, no3, no2, nh4, po4, depth) %>%
    summarise(n = n()) %>%
    filter(n > 1) %>%
    ungroup() #no duplicates

```


### 2.3 Initial Data Exploration

#### 2.3.1 Compare versus Previous Years Data

#### 2.3.2 Timeseries Plots

#### 2.3.3 Map
